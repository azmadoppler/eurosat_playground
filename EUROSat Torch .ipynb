{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb5a19a-3a86-408f-830d-f2dc80747164",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm, trange\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EuroSAT, random_split\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mState\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Keep some global state here (ex best accuracy on val)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'predict'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from dataset import EuroSAT, random_split\n",
    "from predict import predict\n",
    "\n",
    "\n",
    "class State:\n",
    "    # Keep some global state here (ex best accuracy on val)\n",
    "    best_acc = 0\n",
    "    writer: SummaryWriter = None\n",
    "    normalization = None\n",
    "\n",
    "\n",
    "def calc_normalization(train_dl: torch.utils.data.DataLoader):\n",
    "    \"Calculate the mean and std of each channel on images from `train_dl`\"\n",
    "    mean = torch.zeros(3)\n",
    "    m2 = torch.zeros(3)\n",
    "    n = len(train_dl)\n",
    "    for images, labels in tqdm(train_dl, \"Compute normalization\"):\n",
    "        mean += images.mean([0, 2, 3]) / n\n",
    "        m2 += (images ** 2).mean([0, 2, 3]) / n\n",
    "    var = m2 - mean ** 2\n",
    "    return mean, var.sqrt()\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    dataset = EuroSAT(\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    trainval, test_ds = random_split(dataset, 0.9, random_state=42)\n",
    "    train_ds, val_ds = random_split(trainval, 0.9, random_state=7)\n",
    "\n",
    "    # load train dataset with computed normalization\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    mean, std = calc_normalization(train_dl)\n",
    "    dataset.transform.transforms.append(transforms.Normalize(mean, std))\n",
    "    State.normalization = {'mean': mean, 'std': std}\n",
    "\n",
    "    # load val dataset\n",
    "    val_dl = torch.utils.data.DataLoader(\n",
    "        val_ds, batch_size=args.batch_size, num_workers=args.workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # create/load model, changing the head for our number of classes\n",
    "    model = models.resnet50(pretrained=args.pretrained)\n",
    "    if args.pretrained:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))\n",
    "    model = model.to(args.device)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    params = model.fc.parameters() if args.pretrained else model.parameters()\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.wd)\n",
    "\n",
    "    State.writer = SummaryWriter()\n",
    "    # display some examples in tensorboard\n",
    "    images, labels = next(iter(train_dl))\n",
    "    originals = images * std.view(3, 1, 1) + mean.view(3, 1, 1)\n",
    "    State.writer.add_images('images/original', originals, 0)\n",
    "    State.writer.add_images('images/normalized', images, 0)\n",
    "    # writer.add_graph(model, images)\n",
    "\n",
    "    for epoch in trange(args.epochs, desc=\"Epochs\"):\n",
    "        train_epoch(train_dl, model, loss, optimizer, epoch, args)\n",
    "        truth, preds = predict(model, val_dl)\n",
    "\n",
    "        torch.save(\n",
    "            {'normalization': State.normalization, 'model_state': model.state_dict()},\n",
    "            'weights/checkpoint.pt',\n",
    "        )\n",
    "\n",
    "        val_acc = (truth == preds).float().mean()\n",
    "        State.writer.add_scalar('acc/val', val_acc, epoch * len(train_dl))\n",
    "        if val_acc > State.best_acc:\n",
    "            print(f\"New best validation accuracy: {val_acc}\")\n",
    "            State.best_acc = val_acc\n",
    "            shutil.copy('weights/checkpoint.pt', 'weights/best.pt')\n",
    "\n",
    "\n",
    "def train_epoch(train_dl, model, loss, optimizer, epoch, args):\n",
    "    model.train()\n",
    "    train_dl = tqdm(train_dl, \"Train\", unit=\"batch\")\n",
    "    for i, (images, labels) in enumerate(train_dl):\n",
    "        images = images.to(args.device, non_blocking=True)\n",
    "        labels = labels.to(args.device, non_blocking=True)\n",
    "\n",
    "        preds = model(images)\n",
    "        _loss = loss(preds, labels)\n",
    "        acc = (labels == preds.argmax(1)).float().mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        _loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        State.writer.add_scalar('loss/train', _loss, epoch * len(train_dl) + i)\n",
    "        State.writer.add_scalar('acc/train', acc, epoch * len(train_dl) + i)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    def parse_bool(s: str):\n",
    "        if s.casefold() in ['1', 'true', 'yes']:\n",
    "            return True\n",
    "        if s.casefold() in ['0', 'false', 'no']:\n",
    "            return False\n",
    "        raise ValueError()\n",
    "\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument(\n",
    "        '-j',\n",
    "        '--workers',\n",
    "        default=4,\n",
    "        type=int,\n",
    "        metavar='N',\n",
    "        help=\"Number of workers for the DataLoader\",\n",
    "    )\n",
    "    parser.add_argument('--epochs', default=15, type=int, metavar='N', help=\"Epochs\")\n",
    "    parser.add_argument('-b', '--batch-size', default=32, type=int, metavar='N', help=\"Batch size\")\n",
    "    parser.add_argument(\n",
    "        '--lr', '--learning-rate', default=0.0001, type=float, metavar='LR', help=\"Learning rate\"\n",
    "    )\n",
    "    # parser.add_argument('--momentum', default=0.9, type=float, metavar='M')\n",
    "    parser.add_argument(\n",
    "        '--wd', '--weight-decay', default=0, type=float, metavar='WD', help=\"Weight decay\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--pretrained', default=True, type=parse_bool, help=\"Finetune a pre-trained model\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    os.makedirs('weights', exist_ok=True)\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
