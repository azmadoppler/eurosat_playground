{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ef2f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import pipeline\n",
    "from evaluate import evaluator\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf2e6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_positives = np.sum(confusion_matrix[:, i]) - true_positives\n",
    "        false_negatives = np.sum(confusion_matrix[i, :]) - true_positives\n",
    "        true_negatives = np.sum(confusion_matrix) - true_positives - false_positives - false_negatives\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        accuracy = (true_positives) / np.sum(confusion_matrix[i, :])\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    average_accuracy  = np.sum(np.diag(confusion_matrix)) / np.sum(confusion_matrix)\n",
    "\n",
    "    return precision_scores, recall_scores, f1_scores, accuracy_scores, average_precision, average_recall, average_f1, average_accuracy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_standard_deviation(numbers):\n",
    "    if len(numbers) <= 1:\n",
    "        return 0  # Standard deviation is undefined for a single value\n",
    "    \n",
    "    std_deviation = np.std(numbers)\n",
    "    return std_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7219eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_results.json  config.json\t\t    README.md\r\n",
      "checkpoint-12078  eval_results.json\t    trainer_state.json\r\n",
      "checkpoint-12200  preprocessor_config.json  training_args.bin\r\n",
      "checkpoint-854\t  pytorch_model.bin\t    train_results.json\r\n"
     ]
    }
   ],
   "source": [
    "!dir outputs_all/combine_pseudo_30%_Fold_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbc74004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fabb6bb98e84c199a39dca9f14b481d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset split not defined! Automatically evaluating with split: TRAIN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaa0ce3f1294f8497f222d2f3b96859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/original-df25743c9d86cc29/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    }
   ],
   "source": [
    "#'outputs_all/outputs_swin/checkpoint-16900/'\n",
    "#ConvNext Model vit_output\n",
    "#conv_model_path = 'outputs_all/outputs_convnext/checkpoint-16900/'\n",
    "\n",
    "\n",
    "#model_path='outputs_all/resnet_full_benchmark/checkpoint-16900/'\n",
    "model_path = 'outputs_all/combine_pseudo_50%_Fold_0/checkpoint-13300/'\n",
    "test_folder_path = 'test/original'\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"image-classification\",\n",
    "    model=model_path, \n",
    "    device=0\n",
    ")\n",
    "\n",
    "metrics = evaluate.combine(['precision', 'recall'])\n",
    "\n",
    "\n",
    "task_evaluator = evaluator(\"image-classification\")\n",
    "eval_results = task_evaluator.compute(\n",
    "    model_or_pipeline=pipe,\n",
    "    data=test_folder_path,\n",
    "    metric=\"BucketHeadP65/confusion_matrix\",\n",
    "    #metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "    #metric=metrics.compute([\"accuracy\", \"recall\", \"precision\", \"f1\"],average='micro'),\n",
    "#     confidence_level=0.95,\n",
    "#     n_resamples=9999,\n",
    "    label_mapping=pipe.model.config.label2id,\n",
    "    #strategy=\"bootstrap\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e959aa1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[ 30,  10,   8,   9],\n",
       "        [  1,  70,  24,  24],\n",
       "        [  1,   4, 163,   5],\n",
       "        [  2,  16,  20, 268]]),\n",
       " 'total_time_in_seconds': 7.208243483037222,\n",
       " 'samples_per_second': 90.8681846751399,\n",
       " 'latency_in_seconds': 0.011004951882499576}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cec8fd49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  10,   8,   9],\n",
       "       [  1,  70,  24,  24],\n",
       "       [  1,   4, 163,   5],\n",
       "       [  2,  16,  20, 268]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results['confusion_matrix'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdfec737",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results['confusion_matrix'] = np.array([\n",
    "    [45, 4, 5, 3],\n",
    "    [1, 93, 11, 14],\n",
    "    [0, 5, 163, 5],\n",
    "    [2, 12, 10, 282]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb678c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 45,   4,   5,   3],\n",
       "       [  1,  93,  11,  14],\n",
       "       [  0,   5, 163,   5],\n",
       "       [  2,  12,  10, 282]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results['confusion_matrix'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68e1c7e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confusion_matrix': array([[ 38,   8,   6,   5],\n",
       "        [  1,  80,  18,  20],\n",
       "        [  1,   8, 160,   4],\n",
       "        [  0,  10,  10, 286]]),\n",
       " 'total_time_in_seconds': 8.806073516025208,\n",
       " 'samples_per_second': 74.38048283472052,\n",
       " 'latency_in_seconds': 0.013444387047366729}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e27b0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class 0:\n",
      "Precision: 0.8823529411764706\n",
      "Recall: 0.5263157894736842\n",
      "F1 Score: 0.6593406593406594\n",
      "\n",
      "Metrics for class 1:\n",
      "Precision: 0.7\n",
      "Recall: 0.5882352941176471\n",
      "F1 Score: 0.6392694063926941\n",
      "\n",
      "Metrics for class 2:\n",
      "Precision: 0.7581395348837209\n",
      "Recall: 0.9421965317919075\n",
      "F1 Score: 0.8402061855670102\n",
      "\n",
      "Metrics for class 3:\n",
      "Precision: 0.8758169934640523\n",
      "Recall: 0.8758169934640523\n",
      "F1 Score: 0.8758169934640523\n",
      "\n",
      "Average Precision: 0.804077367381061\n",
      "Average Recall: 0.7331411522118227\n",
      "Average F1 Score: 0.753658311191104\n",
      "Accuracy: 0.8106870229007633\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "precision_scores, recall_scores, f1_scores, accuracy_scores ,average_precision, average_recall, average_f1, accuracy = calculate_metrics(eval_results['confusion_matrix'])\n",
    "\n",
    "#precision_scores, recall_scores, f1_scores, accuracy_scores, average_precision, average_recall, average_f1, average_accuracy\n",
    "\n",
    "for i in range(len(precision_scores)):\n",
    "    print(f\"Metrics for class {i}:\")\n",
    "    print(f\"Precision: {precision_scores[i]}\")\n",
    "    print(f\"Recall: {recall_scores[i]}\")\n",
    "    print(f\"F1 Score: {f1_scores[i]}\\n\")\n",
    "\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d8b82a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Atypical': '0', 'Indeterminate': '1', 'Negative': '2', 'Typical': '3'},)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.config.label2id,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = pd.DataFrame(columns=[\"img_name\", \"conv_results\", \"swin_results\",\"original_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6e888a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_results.json  config.json\t\t    README.md\r\n",
      "checkpoint-12078  eval_results.json\t    trainer_state.json\r\n",
      "checkpoint-12200  preprocessor_config.json  training_args.bin\r\n",
      "checkpoint-854\t  pytorch_model.bin\t    train_results.json\r\n"
     ]
    }
   ],
   "source": [
    "!dir outputs_all/combine_pseudo_30%_Fold_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c14f2ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_test/30%_CV/30%_Fold_0/test/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6007498e94a87a0c230d16d137502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset split not defined! Automatically evaluating with split: TRAIN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02939743bc2e479f80d542d87e8a7802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/test-f213f178c42092f6/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_test/30%_CV/30%_Fold_1/test/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a6d9f1733444c297d99f5cb87b384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset split not defined! Automatically evaluating with split: TRAIN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed61b06cdf94b06a3e843afa43eef16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/test-94d7ab9bc9ebfb74/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_test/30%_CV/30%_Fold_2/test/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837bd753c48441c0b5001c244caea998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset split not defined! Automatically evaluating with split: TRAIN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace5b4fd3ed3498ca3e4fced63f6270f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/test-3934a1f2b703992c/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_test/30%_CV/30%_Fold_3/test/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9568b068514f11979919ae37569ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset split not defined! Automatically evaluating with split: TRAIN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcad9629e6784d8e860613e668099c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/test-d8aeeed0f1b4a8f9/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_test/30%_CV/30%_Fold_4/test/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66946a9eef483d8e9c5f55785db48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset split not defined! Automatically evaluating with split: TRAIN\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549fab4874e7464da07040bfcfcd61bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/test-f304e748aea59a59/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    }
   ],
   "source": [
    "#result = pd.DataFrame(columns=[\"img_name\", \"conv_results\", \"swin_results\",\"original_label\"])\n",
    "\n",
    "total_recall = []\n",
    "total_acc = []\n",
    "total_f1 = []\n",
    "total_prec = []\n",
    "class_0_prec = []\n",
    "class_0_recall = []\n",
    "class_0_f1 = []\n",
    "class_0_acc= []\n",
    "\n",
    "class_2_prec= []\n",
    "class_2_recall= []\n",
    "class_2_f1= []\n",
    "class_2_acc= []\n",
    "\n",
    "class_3_prec= []\n",
    "class_3_recall= []\n",
    "class_3_f1= []\n",
    "class_3_acc= []\n",
    "\n",
    "class_1_prec= []\n",
    "class_1_recall= []\n",
    "class_1_f1= []\n",
    "class_1_acc= []\n",
    "for fold_counter in range(0,5):\n",
    "    #print()\n",
    "    model_path='outputs_all/combine_pseudo_30%_Fold_'+str(fold_counter)+ '/checkpoint-12200'\n",
    "    #model_path='outputs_all/conv_output_50%_Fold_'+str(fold_counter)+ '/checkpoint-4300'\n",
    "    test_folder_path = 'cross_val_test/30%_CV/30%_Fold_'+ str(fold_counter)+'/test/'\n",
    "    print(test_folder_path)\n",
    "    \n",
    "    pipe = pipeline(\n",
    "        task=\"image-classification\",\n",
    "        model=model_path, \n",
    "        device=0\n",
    "    )\n",
    "\n",
    "    \n",
    "    metrics = evaluate.combine(['precision', 'recall'])\n",
    "\n",
    "\n",
    "    task_evaluator = evaluator(\"image-classification\")\n",
    "    eval_results = task_evaluator.compute(\n",
    "        model_or_pipeline=pipe,\n",
    "        data=test_folder_path,\n",
    "        metric=\"BucketHeadP65/confusion_matrix\",\n",
    "        #metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "        #metric=metrics.compute([\"accuracy\", \"recall\", \"precision\", \"f1\"],average='micro'),\n",
    "    #     confidence_level=0.95,\n",
    "    #     n_resamples=9999,\n",
    "        label_mapping=pipe.model.config.label2id,\n",
    "    )\n",
    "    \n",
    "    precision_scores, recall_scores, f1_scores, accuracy_scores, average_precision, average_recall, average_f1, average_accuracy = calculate_metrics(eval_results['confusion_matrix'])\n",
    "\n",
    "#     for i in range(len(precision_scores)):\n",
    "#         print(f\"Metrics for class {i}:\")\n",
    "#         print(f\"Precision: {precision_scores[i]}\")\n",
    "#         print(f\"Recall: {recall_scores[i]}\")\n",
    "#         print(f\"Recall: {accuracy_scores[i]}\")\n",
    "#         print(f\"F1 Score: {f1_scores[i]}\\n\")\n",
    "\n",
    "#     print(f\"Average Precision: {average_precision}\")\n",
    "#     print(f\"Average Recall: {average_recall}\")\n",
    "#     print(f\"Average F1 Score: {average_f1}\")\n",
    "#     print(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    class_0_prec.append(precision_scores[0])\n",
    "    class_0_recall.append(recall_scores[0])\n",
    "    class_0_f1.append(f1_scores[0])\n",
    "    class_0_acc.append(accuracy_scores[0])\n",
    "    \n",
    "    class_1_prec.append(precision_scores[1])\n",
    "    class_1_recall.append(recall_scores[1])\n",
    "    class_1_f1.append(f1_scores[1])\n",
    "    class_1_acc.append(accuracy_scores[1])\n",
    "    \n",
    "    class_2_prec.append(precision_scores[2])\n",
    "    class_2_recall.append(recall_scores[2])\n",
    "    class_2_f1.append(f1_scores[2])\n",
    "    class_2_acc.append(accuracy_scores[2])\n",
    "    \n",
    "    class_3_prec.append(precision_scores[3])\n",
    "    class_3_recall.append(recall_scores[3])\n",
    "    class_3_f1.append(f1_scores[3])\n",
    "    class_3_acc.append(accuracy_scores[3])\n",
    "\n",
    "\n",
    "    total_acc.append(average_accuracy)\n",
    "    total_f1.append(average_f1)\n",
    "    total_recall.append(average_recall)\n",
    "    total_prec.append(average_precision)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c5c7f247",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5090446371233048,\n",
       " 0.49923575910378937,\n",
       " 0.4817603975557257,\n",
       " 0.5163317837011635,\n",
       " 0.5347631675621068]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9919afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c0_total_acc = sum(class_0_acc) / len(class_0_acc)\n",
    "c0_total_f1= sum(class_0_f1) / len(class_0_f1)\n",
    "c0_total_recall=sum(class_0_recall) / len(class_0_recall)\n",
    "c0_total_prec = sum(class_0_prec) / len(class_0_prec)\n",
    "\n",
    "c1_total_acc = sum(class_1_acc) / len(class_1_acc)\n",
    "c1_total_f1= sum(class_1_f1) / len(class_1_f1)\n",
    "c1_total_recall=sum(class_1_recall) / len(class_1_recall)\n",
    "c1_total_prec = sum(class_1_prec) / len(class_1_prec)\n",
    "\n",
    "c2_total_acc = sum(class_2_acc) / len(class_2_acc)\n",
    "c2_total_f1= sum(class_2_f1) / len(class_2_f1)\n",
    "c2_total_recall=sum(class_2_recall) / len(class_2_recall)\n",
    "c2_total_prec = sum(class_2_prec) / len(class_2_prec)\n",
    "\n",
    "c3_total_acc = sum(class_3_acc) / len(class_3_acc)\n",
    "c3_total_f1= sum(class_3_f1) / len(class_3_f1)\n",
    "c3_total_recall=sum(class_3_recall) / len(class_3_recall)\n",
    "c3_total_prec = sum(class_3_prec) / len(class_3_prec)\n",
    "\n",
    "c0_std_acc = calculate_standard_deviation(class_0_acc)\n",
    "c0_std_f1 = calculate_standard_deviation(class_0_f1)\n",
    "c0_std_recall = calculate_standard_deviation(class_0_recall)\n",
    "c0_std_prec = calculate_standard_deviation(class_0_prec)\n",
    "\n",
    "\n",
    "c1_std_acc = calculate_standard_deviation(class_1_acc)\n",
    "c1_std_f1 = calculate_standard_deviation(class_1_f1)\n",
    "c1_std_recall = calculate_standard_deviation(class_1_recall)\n",
    "c1_std_prec = calculate_standard_deviation(class_1_prec)\n",
    "\n",
    "\n",
    "c2_std_acc = calculate_standard_deviation(class_2_acc)\n",
    "c2_std_f1 = calculate_standard_deviation(class_2_f1)\n",
    "c2_std_recall = calculate_standard_deviation(class_2_recall)\n",
    "c2_std_prec = calculate_standard_deviation(class_2_prec)\n",
    "\n",
    "\n",
    "c3_std_acc = calculate_standard_deviation(class_3_acc)\n",
    "c3_std_f1 = calculate_standard_deviation(class_3_f1)\n",
    "c3_std_recall = calculate_standard_deviation(class_3_recall)\n",
    "c3_std_prec = calculate_standard_deviation(class_3_prec)\n",
    "\n",
    "\n",
    "avg_total_acc = sum(total_acc) / len(total_acc)\n",
    "avg_total_f1= sum(total_f1) / len(total_f1)\n",
    "avg_total_recall=sum(total_recall) / len(total_recall)\n",
    "avg_total_prec = sum(total_prec) / len(total_prec)\n",
    "\n",
    "\n",
    "avg_std_acc = calculate_standard_deviation(total_acc)\n",
    "avg_std_f1 = calculate_standard_deviation(total_f1)\n",
    "avg_std_recall = calculate_standard_deviation(total_recall)\n",
    "avg_std_prec = calculate_standard_deviation(total_prec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6b8adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atypical': '0', 'Indeterminate': '1', 'Negative': '2', 'Typical': '3'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f191ea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642883062755032"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf6e3b18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atypical\n",
      "0.30503671775223495\n",
      "0.08271369024499396\n",
      "-----\n",
      "0.16011904761904763\n",
      "0.03848726254879268\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(\"Atypical\")\n",
    "print(c0_total_prec)\n",
    "print(c0_std_prec)\n",
    "print(\"-----\")\n",
    "print(c0_total_recall)\n",
    "print(c0_std_recall)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc400050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14545454545454545,\n",
       " 0.2545454545454545,\n",
       " 0.21621621621621623,\n",
       " 0.17117117117117117,\n",
       " 0.24324324324324326]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a56e7b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28195271164021163"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(class_0_prec[1]+class_0_prec[1]+class_0_prec[2]+class_0_prec[3]) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b46d480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interdeterminiate\n",
      "0.31743794412260684\n",
      "0.05783891756034666\n",
      "-----\n",
      "0.2061261261261261\n",
      "0.04177753282036113\n"
     ]
    }
   ],
   "source": [
    "print(\"Interdeterminiate\")\n",
    "print(c1_total_prec)\n",
    "print(c1_std_prec)\n",
    "print(\"-----\")\n",
    "print(c1_total_recall)\n",
    "print(c1_std_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ddf048f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n",
      "0.64589932628678\n",
      "0.036960976224884604\n",
      "-----\n",
      "0.7961132150687662\n",
      "0.020145401844011035\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative\")\n",
    "print(c2_total_prec)\n",
    "print(c2_std_prec)\n",
    "print(\"-----\")\n",
    "print(c2_total_recall)\n",
    "print(c2_std_recall)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6e169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typical\n",
      "0.7205127964953116\n",
      "0.01735564573521816\n",
      "-----\n",
      "0.7690985603543743\n",
      "0.028456066604522243\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(\"Typical\")\n",
    "print(c3_total_prec)\n",
    "print(c3_std_prec)\n",
    "print(\"-----\")\n",
    "print(c3_total_recall)\n",
    "print(c3_std_recall)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "409bf999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49722169616423334\n",
      "0.03564237764484426\n",
      "-----\n",
      "0.4828642372920785\n",
      "0.019473547065627386\n",
      "-----\n",
      "0.6314845826522081\n",
      "0.020350761624497386\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(avg_total_prec)\n",
    "print(avg_std_prec)\n",
    "print(\"-----\")\n",
    "print(avg_total_recall)\n",
    "print(avg_std_recall)\n",
    "print(\"-----\")\n",
    "print(avg_total_acc)\n",
    "print(avg_std_acc)\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e7e0169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.662992125984252"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e7eb1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atypical': '0', 'Indeterminate': '1', 'Negative': '2', 'Typical': '3'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.config.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a37e59ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20614551916556126"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " avg_std_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ffbaac2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20614551916556126"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_std_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfc7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6beaa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation: 24.546498981420914\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example list of numbers\n",
    "data = [23, 45, 67, 89, 12, 34, 56]\n",
    "\n",
    "std_dev = calculate_standard_deviation(data)\n",
    "print(\"Standard Deviation:\", std_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68859cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb2946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path='outputs_all/conv_output_30%_Fold_0/checkpoint-2600'\n",
    "test_folder_path = 'test/original'\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"image-classification\",\n",
    "    model=model_path, \n",
    "    device=0\n",
    ")\n",
    "\n",
    "metrics = evaluate.combine(['precision', 'recall'])\n",
    "\n",
    "\n",
    "task_evaluator = evaluator(\"image-classification\")\n",
    "eval_results = task_evaluator.compute(\n",
    "    model_or_pipeline=pipe,\n",
    "    data=test_folder_path,\n",
    "    metric=\"BucketHeadP65/confusion_matrix\",\n",
    "    #metric=evaluate.combine([\"accuracy\", \"recall\", \"precision\", \"f1\"]),\n",
    "    #metric=metrics.compute([\"accuracy\", \"recall\", \"precision\", \"f1\"],average='micro'),\n",
    "#     confidence_level=0.95,\n",
    "#     n_resamples=9999,\n",
    "    label_mapping=pipe.model.config.label2id,\n",
    "    #strategy=\"bootstrap\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "precision_scores, recall_scores, f1_scores, average_precision, average_recall, average_f1, accuracy = calculate_metrics(eval_results['confusion_matrix'])\n",
    "\n",
    "for i in range(len(precision_scores)):\n",
    "    print(f\"Metrics for class {i}:\")\n",
    "    print(f\"Precision: {precision_scores[i]}\")\n",
    "    print(f\"Recall: {recall_scores[i]}\")\n",
    "    print(f\"F1 Score: {f1_scores[i]}\\n\")\n",
    "\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c43c95e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'function' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m precision_scores, recall_scores, f1_scores, accuracy_scores, average_precision, average_recall, average_f1, average_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfusion_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(precision_scores)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics for class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(confusion_matrix)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_metrics\u001b[39m(confusion_matrix):\n\u001b[0;32m----> 5\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfusion_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     precision_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m     recall_scores \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'function' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "precision_scores, recall_scores, f1_scores, accuracy_scores, average_precision, average_recall, average_f1, average_accuracy = calculate_metrics(confusion_matrix)\n",
    "\n",
    "for i in range(len(precision_scores)):\n",
    "    print(f\"Metrics for class {i}:\")\n",
    "    print(f\"Precision: {precision_scores[i]}\")\n",
    "    print(f\"Recall: {recall_scores[i]}\")\n",
    "    print(f\"F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Accuracy per class: {accuracy_scores[i]}\\n\")\n",
    "\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")\n",
    "print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44535ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class 0:\n",
      "Precision: 0.7692307692307693\n",
      "Recall: 0.7692307692307693\n",
      "F1 Score: 0.7692307692307693\n",
      "\n",
      "Metrics for class 1:\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.7894736842105263\n",
      "F1 Score: 0.8108108108108109\n",
      "\n",
      "Metrics for class 2:\n",
      "Precision: 0.8\n",
      "Recall: 0.8571428571428571\n",
      "F1 Score: 0.8275862068965518\n",
      "\n",
      "Average Precision: 0.800854700854701\n",
      "Average Recall: 0.8052824368613843\n",
      "Average F1 Score: 0.802542595646044\n",
      "Accuracy: 0.8043478260869565\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics_v2(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    accuracies = [] \n",
    "    for i in range(num_classes):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_positives = np.sum(confusion_matrix[:, i]) - true_positives\n",
    "        false_negatives = np.sum(confusion_matrix[i, :]) - true_positives\n",
    "        total_samples = np.sum(confusion_matrix[i, :])\n",
    "        \n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        class_accuracy = true_positives/total_samples\n",
    "        \n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    accuracy = np.sum(np.diag(confusion_matrix)) / np.sum(confusion_matrix)\n",
    "\n",
    "    return precision_scores, recall_scores, f1_scores, average_precision, average_recall, average_f1, accuracy\n",
    "\n",
    "# Example usage\n",
    "confusion_matrix = np.array([[10, 1, 2],\n",
    "                             [3, 15, 1],\n",
    "                             [0, 2, 12]])\n",
    "\n",
    "precision_scores, recall_scores, f1_scores, average_precision, average_recall, average_f1, accuracy = calculate_metrics_v2(confusion_matrix)\n",
    "\n",
    "for i in range(len(precision_scores)):\n",
    "    print(f\"Metrics for class {i}:\")\n",
    "    print(f\"Precision: {precision_scores[i]}\")\n",
    "    print(f\"Recall: {recall_scores[i]}\")\n",
    "    print(f\"F1 Score: {f1_scores[i]}\\n\")\n",
    "\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04871a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores, recall_scores, f1_scores, accuracy_scores ,average_precision, average_recall, average_f1, accuracy = calculate_metrics(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "eeca1fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Accuracy=0.78, Recall=0.89, Precision=0.87\n",
      "Class 1: Accuracy=0.85, Recall=0.85, Precision=1.00\n",
      "Class 2: Accuracy=0.82, Recall=0.72, Precision=1.21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def class_accuracy_recall_precision(confusion_matrix):\n",
    "    num_classes = confusion_matrix.shape[0]\n",
    "    accuracies = np.zeros(num_classes)\n",
    "    recalls = np.zeros(num_classes)\n",
    "    precisions = np.zeros(num_classes)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        total_samples = np.sum(confusion_matrix[i, :])\n",
    "        actual_positives = np.sum(confusion_matrix[:, i])\n",
    "        \n",
    "        if total_samples > 0:\n",
    "            accuracies[i] = true_positives / total_samples\n",
    "        \n",
    "        if actual_positives > 0:\n",
    "            recalls[i] = true_positives / actual_positives\n",
    "        \n",
    "        if true_positives + total_samples - actual_positives > 0:\n",
    "            precisions[i] = true_positives / (true_positives + total_samples - actual_positives)\n",
    "    \n",
    "    return accuracies, recalls, precisions\n",
    "\n",
    "# Example confusion matrix (replace this with your own confusion matrix)\n",
    "confusion_matrix = np.array([[90, 5, 20],\n",
    "                             [3, 85, 12],\n",
    "                             [8, 10, 82]])\n",
    "\n",
    "class_accuracies, class_recalls, class_precisions = class_accuracy_recall_precision(confusion_matrix)\n",
    "\n",
    "for i, (accuracy, recall, precision) in enumerate(zip(class_accuracies, class_recalls, class_precisions)):\n",
    "    print(f\"Class {i}: Accuracy={accuracy:.2f}, Recall={recall:.2f}, Precision={precision:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "65088d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores, recall_scores, f1_scores, accuracy_scores ,average_precision, average_recall, average_f1, accuracy = calculate_metrics(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c199cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8158730158730159"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d5dd6cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8910891089108911, 0.85, 0.7192982456140351]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4af6dbb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.782608695652174, 0.85, 0.82]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9a1851b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for each class: [0.89108911 0.85       0.82828283]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_precision(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    precision = np.zeros(num_classes)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        true_positive = confusion_matrix[i, i]\n",
    "        false_positive = np.sum(confusion_matrix[:, i]) - true_positive\n",
    "        \n",
    "        if true_positive + false_positive == 0:\n",
    "            precision[i] = 0.0\n",
    "        else:\n",
    "            precision[i] = true_positive / (true_positive + false_positive)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "# # Example confusion matrix for 3 classes: [[C00, C01, C02], [C10, C11, C12], [C20, C21, C22]]\n",
    "# confusion_matrix = np.array([[50, 5, 5],\n",
    "#                              [10, 80, 10],\n",
    "#                              [5, 5, 50]])\n",
    "\n",
    "precision = calculate_precision(confusion_matrix)\n",
    "print(\"Precision for each class:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "480d3f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for each class: [0.89108911 0.85       0.82828283]\n",
      "Recall for each class: [0.9  0.85 0.82]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_precision_recall(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        true_positive = confusion_matrix[i, i]\n",
    "        false_positive = np.sum(confusion_matrix[:, i]) - true_positive\n",
    "        false_negative = np.sum(confusion_matrix[i, :]) - true_positive\n",
    "        \n",
    "        if true_positive + false_positive == 0:\n",
    "            precision[i] = 0.0\n",
    "        else:\n",
    "            precision[i] = true_positive / (true_positive + false_positive)\n",
    "        \n",
    "        if true_positive + false_negative == 0:\n",
    "            recall[i] = 0.0\n",
    "        else:\n",
    "            recall[i] = true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# # Example confusion matrix for 3 classes: [[C00, C01, C02], [C10, C11, C12], [C20, C21, C22]]\n",
    "# confusion_matrix = np.array([[50, 5, 5],\n",
    "#                              [10, 80, 10],\n",
    "#                              [5, 10, 85]])\n",
    "\n",
    "precision, recall = calculate_precision_recall(confusion_matrix)\n",
    "print(\"Precision for each class:\", precision)\n",
    "print(\"Recall for each class:\", recall)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
