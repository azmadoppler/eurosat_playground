{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730de7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SwinForImageClassification\n",
    "from torchinfo import summary\n",
    "\n",
    "# Load the Swin Transformer model\n",
    "model = SwinForImageClassification.from_pretrained('microsoft/swin-tiny-patch4-window7-224')\n",
    "\n",
    "# Get the summary of the model\n",
    "model_summary = summary(model, input_size=(1, 3, 224, 224), verbose=0)\n",
    "\n",
    "model_summary_str = str(model_summary)\n",
    "#model_summary_str[:2000]  # Displaying the first 2000 characters for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2dc792",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SwinForImageClassification                                        [1, 1000]                 --\n",
       "├─SwinModel: 1-1                                                  [1, 768]                  --\n",
       "│    └─SwinEmbeddings: 2-1                                        [1, 3136, 96]             --\n",
       "│    │    └─SwinPatchEmbeddings: 3-1                              [1, 3136, 96]             4,704\n",
       "│    │    └─LayerNorm: 3-2                                        [1, 3136, 96]             192\n",
       "│    │    └─Dropout: 3-3                                          [1, 3136, 96]             --\n",
       "│    └─SwinEncoder: 2-2                                           [1, 49, 768]              --\n",
       "│    │    └─ModuleList: 3-4                                       --                        27,512,922\n",
       "│    └─LayerNorm: 2-3                                             [1, 49, 768]              1,536\n",
       "│    └─AdaptiveAvgPool1d: 2-4                                     [1, 768, 1]               --\n",
       "├─Linear: 1-2                                                     [1, 1000]                 769,000\n",
       "===================================================================================================================\n",
       "Total params: 28,288,354\n",
       "Trainable params: 28,288,354\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 62.80\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 137.29\n",
       "Params size (MB): 113.06\n",
       "Estimated Total Size (MB): 250.95\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6268ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ConvNextForImageClassification                               [1, 1000]                 --\n",
       "├─ConvNextModel: 1-1                                         [1, 768]                  --\n",
       "│    └─ConvNextEmbeddings: 2-1                               [1, 96, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-1                                      [1, 96, 56, 56]           4,704\n",
       "│    │    └─ConvNextLayerNorm: 3-2                           [1, 96, 56, 56]           192\n",
       "│    └─ConvNextEncoder: 2-2                                  [1, 768, 7, 7]            --\n",
       "│    │    └─ModuleList: 3-3                                  --                        27,813,696\n",
       "│    └─LayerNorm: 2-3                                        [1, 768]                  1,536\n",
       "├─Linear: 1-2                                                [1, 1000]                 769,000\n",
       "==============================================================================================================\n",
       "Total params: 28,589,128\n",
       "Trainable params: 28,589,128\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 395.23\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 131.27\n",
       "Params size (MB): 114.33\n",
       "Estimated Total Size (MB): 246.21\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import ConvNextForImageClassification\n",
    "\n",
    "model = ConvNextForImageClassification.from_pretrained('facebook/convnext-tiny-224')\n",
    "#Summary with torchinfo: Use torchinfo to get a detailed summary of the model:\n",
    "\n",
    "\n",
    "summary(model, input_size=(1, 3, 224, 224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
