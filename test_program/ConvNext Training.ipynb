{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dacecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random \n",
    "import os \n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8878aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform stuff to test\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize the images to 64x64\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62693a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root='datasets',transform=data_transform)\n",
    "test_data = datasets.ImageFolder(root='test',transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f67ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atypical': 0, 'Indeterminate': 1, 'Negative': 2, 'Typical': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get class names\n",
    "class_names = train_data.classes\n",
    "class_names\n",
    "#Get class dict\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "080eef5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#setup dataloader \n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = os.cpu_count()-4\n",
    "\n",
    "train_dataloader_simple = DataLoader(train_data, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=NUM_WORKERS)\n",
    "\n",
    "test_dataloader_simple = DataLoader(test_data, \n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    shuffle=False, \n",
    "                                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b47163f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=40960, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*64*64,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # <- leverage the benefits of operator fusion\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=10, \n",
    "                  output_shape=len(train_data.classes)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f47774f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single image shape: torch.Size([1, 3, 256, 256])\n",
      "\n",
      "Output logits:\n",
      "tensor([[0.0329, 0.0068, 0.0042, 0.0352]], device='cuda:0')\n",
      "\n",
      "Output prediction probabilities:\n",
      "tensor([[0.2533, 0.2467, 0.2461, 0.2539]], device='cuda:0')\n",
      "\n",
      "Output prediction label:\n",
      "tensor([3], device='cuda:0')\n",
      "\n",
      "Actual label:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1. Get a batch of images and labels from the DataLoader\n",
    "img_batch, label_batch = next(iter(train_dataloader_simple))\n",
    "\n",
    "# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n",
    "img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n",
    "print(f\"Single image shape: {img_single.shape}\\n\")\n",
    "\n",
    "# 3. Perform a forward pass on a single image\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model_0(img_single.to(device))\n",
    "    \n",
    "# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6894373",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output prediction label:\n",
      "tensor([3], device='cuda:0')\n",
      "\n",
      "Actual label:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(f\"Output logits:\\n{pred}\\n\")\n",
    "#print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n",
    "print(f\"Actual label:\\n{label_single}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ba6c780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [1, 4]                    --\n",
       "├─Sequential: 1-1                        [1, 10, 128, 128]         --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 256, 256]         280\n",
       "│    └─ReLU: 2-2                         [1, 10, 256, 256]         --\n",
       "│    └─Conv2d: 2-3                       [1, 10, 256, 256]         910\n",
       "│    └─ReLU: 2-4                         [1, 10, 256, 256]         --\n",
       "│    └─MaxPool2d: 2-5                    [1, 10, 128, 128]         --\n",
       "├─Sequential: 1-2                        [1, 10, 64, 64]           --\n",
       "│    └─Conv2d: 2-6                       [1, 10, 128, 128]         910\n",
       "│    └─ReLU: 2-7                         [1, 10, 128, 128]         --\n",
       "│    └─Conv2d: 2-8                       [1, 10, 128, 128]         910\n",
       "│    └─ReLU: 2-9                         [1, 10, 128, 128]         --\n",
       "│    └─MaxPool2d: 2-10                   [1, 10, 64, 64]           --\n",
       "├─Sequential: 1-3                        [1, 4]                    --\n",
       "│    └─Flatten: 2-11                     [1, 40960]                --\n",
       "│    └─Linear: 2-12                      [1, 4]                    163,844\n",
       "==========================================================================================\n",
       "Total params: 166,854\n",
       "Trainable params: 166,854\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 107.97\n",
       "==========================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 13.11\n",
       "Params size (MB): 0.67\n",
       "Estimated Total Size (MB): 14.56\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary \n",
    "summary(model_0, input_size=[1, 3, 256, 256]) # do a test pass through of an example input size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ea88580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\thanawit\\.conda\\envs\\twin-pseudo\n",
      "\n",
      "  added / updated specs:\n",
      "    - torchinfo\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.5.7   |       h56e8100_0         145 KB  conda-forge\n",
      "    certifi-2023.5.7           |     pyhd8ed1ab_0         149 KB  conda-forge\n",
      "    torchinfo-1.8.0            |     pyhd8ed1ab_0          25 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         318 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  torchinfo          conda-forge/noarch::torchinfo-1.8.0-pyhd8ed1ab_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.01.10~ --> conda-forge::ca-certificates-2023.5.7-h56e8100_0\n",
      "  certifi            pkgs/main/win-64::certifi-2022.12.7-p~ --> conda-forge/noarch::certifi-2023.5.7-pyhd8ed1ab_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "ca-certificates-2023 | 145 KB    |            |   0% \n",
      "ca-certificates-2023 | 145 KB    | #1         |  11% \n",
      "ca-certificates-2023 | 145 KB    | ########## | 100% \n",
      "ca-certificates-2023 | 145 KB    | ########## | 100% \n",
      "\n",
      "torchinfo-1.8.0      | 25 KB     |            |   0% \n",
      "torchinfo-1.8.0      | 25 KB     | ########## | 100% \n",
      "torchinfo-1.8.0      | 25 KB     | ########## | 100% \n",
      "\n",
      "certifi-2023.5.7     | 149 KB    |            |   0% \n",
      "certifi-2023.5.7     | 149 KB    | ########## | 100% \n",
      "certifi-2023.5.7     | 149 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.1\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge torchinfo -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d001582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\thanawit/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 1000]                 --\n",
       "├─Conv2d: 1-1                            [1, 64, 128, 128]         9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 128, 128]         128\n",
       "├─ReLU: 1-3                              [1, 64, 128, 128]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 64, 64]           --\n",
       "├─Sequential: 1-5                        [1, 64, 64, 64]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 64, 64]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 64, 64]           128\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 64, 64]           --\n",
       "├─Sequential: 1-6                        [1, 128, 32, 32]          --\n",
       "│    └─BasicBlock: 2-3                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-13                 [1, 128, 32, 32]          73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-15                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-16                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 128, 32, 32]          256\n",
       "│    │    └─Sequential: 3-18             [1, 128, 32, 32]          8,448\n",
       "│    │    └─ReLU: 3-19                   [1, 128, 32, 32]          --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-20                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-22                   [1, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-23                 [1, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [1, 128, 32, 32]          256\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 32, 32]          --\n",
       "├─Sequential: 1-7                        [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-5                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-26                 [1, 256, 16, 16]          294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 256, 16, 16]          512\n",
       "│    │    └─Sequential: 3-31             [1, 256, 16, 16]          33,280\n",
       "│    │    └─ReLU: 3-32                   [1, 256, 16, 16]          --\n",
       "│    └─BasicBlock: 2-6                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-33                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-35                   [1, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-36                 [1, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [1, 256, 16, 16]          512\n",
       "│    │    └─ReLU: 3-38                   [1, 256, 16, 16]          --\n",
       "├─Sequential: 1-8                        [1, 512, 8, 8]            --\n",
       "│    └─BasicBlock: 2-7                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-39                 [1, 512, 8, 8]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-41                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-42                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [1, 512, 8, 8]            1,024\n",
       "│    │    └─Sequential: 3-44             [1, 512, 8, 8]            132,096\n",
       "│    │    └─ReLU: 3-45                   [1, 512, 8, 8]            --\n",
       "│    └─BasicBlock: 2-8                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-46                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-48                   [1, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-49                 [1, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU: 3-51                   [1, 512, 8, 8]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
       "├─Linear: 1-10                           [1, 1000]                 513,000\n",
       "==========================================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.37\n",
       "==========================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 51.91\n",
       "Params size (MB): 46.76\n",
       "Estimated Total Size (MB): 99.46\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "summary(model, input_size=[1, 3, 256, 256]) # do a test pass through of an example input size\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
