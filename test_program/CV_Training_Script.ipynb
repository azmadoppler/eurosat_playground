{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382cc282",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIT : google/vit-base-patch16-224-in21k\n",
    "SWIN : microsoft/swin-tiny-patch4-window7-224 OR microsoft/swin-base-patch4-window7-224-in22k \n",
    "ConvNext : facebook/convnextv2-tiny-1k-224  OR facebook/convnext-base-224\n",
    "ResNet : microsoft/resnet-50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8bbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1c9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'facebook/convnextv2-tiny-1k-224'\n",
    "model_name = 'microsoft/swin-tiny-patch4-window7-224'\n",
    "dataset_dir = 'cross_val_test/30%_CV/30%_Fold_'\n",
    "output_dir = 'outputs_all/conv_output_30%_Fold_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cae248bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_dir = 'cross_val_test/30%_CV/30%_Fold_'+'0'+'/combine_pseudo_labeled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7c8902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cross_val_test/30%_CV/30%_Fold_0/combine_pseudo_labeled'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b69007",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "--dataset_name 'cross_val_test/50%_CV/50%_Fold_0/combine_pseudo_labeled' \\\n",
    "--model_name_or_path 'microsoft/swin-tiny-patch4-window7-224' \\\n",
    "--output_dir 'outputs_all/combine_pseudo_50%_Fold_0' \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b1cb9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/05/2023 09:41:53 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: False\n",
      "10/05/2023 09:41:53 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=2,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs_all/swin_combine_pseudo_30%_Fold_5/runs/Oct05_09-41-53_thanawit-Z690-Pro-RS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=100.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=outputs_all/swin_combine_pseudo_30%_Fold_5,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs_all/swin_combine_pseudo_30%_Fold_5,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "Resolving data files: 100%|██████████████| 4553/4553 [00:00<00:00, 10135.61it/s]\n",
      "10/05/2023 09:41:55 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-054afc0cc8913b06/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 104.80it/s]\n",
      "10/05/2023 09:41:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-054afc0cc8913b06/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-5e533dc4c9020080.arrow\n",
      "10/05/2023 09:41:55 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-054afc0cc8913b06/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-d6ae5c8f90664041.arrow and /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-054afc0cc8913b06/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-cac2147f117d2490.arrow\n",
      "[INFO|configuration_utils.py:669] 2023-10-05 09:41:57,970 >> loading configuration file config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-10-05 09:41:57,973 >> Model config SwinConfig {\n",
      "  \"_name_or_path\": \"microsoft/swin-tiny-patch4-window7-224\",\n",
      "  \"architectures\": [\n",
      "    \"SwinForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    6,\n",
      "    2\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"embed_dim\": 96,\n",
      "  \"encoder_stride\": 32,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Atypical\",\n",
      "    \"1\": \"Indeterminate\",\n",
      "    \"2\": \"Negative\",\n",
      "    \"3\": \"Typical\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Atypical\": \"0\",\n",
      "    \"Indeterminate\": \"1\",\n",
      "    \"Negative\": \"2\",\n",
      "    \"Typical\": \"3\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mlp_ratio\": 4.0,\n",
      "  \"model_type\": \"swin\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_heads\": [\n",
      "    3,\n",
      "    6,\n",
      "    12,\n",
      "    24\n",
      "  ],\n",
      "  \"num_layers\": 4,\n",
      "  \"out_features\": [\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"out_indices\": [\n",
      "    4\n",
      "  ],\n",
      "  \"patch_size\": 4,\n",
      "  \"path_norm\": true,\n",
      "  \"qkv_bias\": true,\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0.dev0\",\n",
      "  \"use_absolute_embeddings\": false,\n",
      "  \"window_size\": 7\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2575] 2023-10-05 09:41:57,984 >> loading weights file model.safetensors from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/model.safetensors\n",
      "[INFO|modeling_utils.py:3283] 2023-10-05 09:41:58,149 >> All model checkpoint weights were used when initializing SwinForImageClassification.\n",
      "\n",
      "[WARNING|modeling_utils.py:3304] 2023-10-05 09:41:58,149 >> Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-10-05 09:41:58,645 >> loading configuration file preprocessor_config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/preprocessor_config.json\n",
      "[WARNING|image_processing_auto.py:331] 2023-10-05 09:41:58,646 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "[INFO|image_processing_utils.py:542] 2023-10-05 09:41:58,656 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "[INFO|image_processing_utils.py:359] 2023-10-05 09:41:58,656 >> Image processor ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:1680] 2023-10-05 09:41:59,423 >> ***** Running training *****\n",
      "[INFO|trainer.py:1681] 2023-10-05 09:41:59,423 >>   Num examples = 3,870\n",
      "[INFO|trainer.py:1682] 2023-10-05 09:41:59,423 >>   Num Epochs = 100\n",
      "[INFO|trainer.py:1683] 2023-10-05 09:41:59,423 >>   Instantaneous batch size per device = 64\n",
      "[INFO|trainer.py:1684] 2023-10-05 09:41:59,423 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1685] 2023-10-05 09:41:59,423 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1686] 2023-10-05 09:41:59,423 >>   Total optimization steps = 6,100\n",
      "[INFO|trainer.py:1687] 2023-10-05 09:41:59,423 >>   Number of trainable parameters = 27,522,430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/6100 [00:00<?, ?it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 1.1338, 'learning_rate': 1.99672131147541e-05, 'epoch': 0.16}          \n",
      "{'loss': 0.9433, 'learning_rate': 1.99344262295082e-05, 'epoch': 0.33}          \n",
      "{'loss': 0.9456, 'learning_rate': 1.9901639344262297e-05, 'epoch': 0.49}        \n",
      "{'loss': 0.8555, 'learning_rate': 1.9868852459016394e-05, 'epoch': 0.66}        \n",
      "{'loss': 0.7997, 'learning_rate': 1.9836065573770492e-05, 'epoch': 0.82}        \n",
      "{'loss': 0.809, 'learning_rate': 1.9803278688524592e-05, 'epoch': 0.98}         \n",
      "  1%|▍                                        | 61/6100 [00:37<44:34,  2.26it/s][INFO|trainer.py:3074] 2023-10-05 09:42:37,011 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:42:37,012 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:42:37,012 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.25it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  2.96it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.53it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.37it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.23it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.18it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.11it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.08it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8043155670166016, 'eval_accuracy': 0.7320644216691069, 'eval_runtime': 5.156, 'eval_samples_per_second': 132.466, 'eval_steps_per_second': 2.133, 'epoch': 1.0}\n",
      "  1%|▍                                        | 61/6100 [00:42<44:34,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.22it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:42:42,168 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-61\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:42:42,169 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-61/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:42:42,277 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-61/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:42:42,278 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-61/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7953, 'learning_rate': 1.977049180327869e-05, 'epoch': 1.15}         \n",
      "{'loss': 0.79, 'learning_rate': 1.973770491803279e-05, 'epoch': 1.31}           \n",
      "{'loss': 0.7843, 'learning_rate': 1.9704918032786884e-05, 'epoch': 1.48}        \n",
      "{'loss': 0.772, 'learning_rate': 1.9672131147540985e-05, 'epoch': 1.64}         \n",
      "{'loss': 0.7818, 'learning_rate': 1.9639344262295083e-05, 'epoch': 1.8}         \n",
      "{'loss': 0.7738, 'learning_rate': 1.9606557377049183e-05, 'epoch': 1.97}        \n",
      "  2%|▊                                       | 122/6100 [01:15<40:41,  2.45it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:43:15,109 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:43:15,109 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:43:15,109 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.72it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.00it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7301954030990601, 'eval_accuracy': 0.746705710102489, 'eval_runtime': 4.4708, 'eval_samples_per_second': 152.767, 'eval_steps_per_second': 2.46, 'epoch': 2.0}\n",
      "  2%|▊                                       | 122/6100 [01:20<40:41,  2.45it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:43:19,580 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-122\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:43:19,581 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-122/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:43:19,689 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-122/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:43:19,689 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-122/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7507, 'learning_rate': 1.957377049180328e-05, 'epoch': 2.13}         \n",
      "{'loss': 0.7568, 'learning_rate': 1.9540983606557378e-05, 'epoch': 2.3}         \n",
      "{'loss': 0.7156, 'learning_rate': 1.9508196721311475e-05, 'epoch': 2.46}        \n",
      "{'loss': 0.7838, 'learning_rate': 1.9475409836065576e-05, 'epoch': 2.62}        \n",
      "{'loss': 0.7236, 'learning_rate': 1.9442622950819673e-05, 'epoch': 2.79}        \n",
      "{'loss': 0.7483, 'learning_rate': 1.9409836065573774e-05, 'epoch': 2.95}        \n",
      "  3%|█▏                                      | 183/6100 [01:53<40:01,  2.46it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:43:52,877 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:43:52,877 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:43:52,877 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.98it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.66it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7081710696220398, 'eval_accuracy': 0.7525622254758418, 'eval_runtime': 4.457, 'eval_samples_per_second': 153.243, 'eval_steps_per_second': 2.468, 'epoch': 3.0}\n",
      "  3%|█▏                                      | 183/6100 [01:57<40:01,  2.46it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:43:57,335 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-183\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:43:57,336 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-183/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:43:57,448 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-183/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:43:57,449 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-183/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7286, 'learning_rate': 1.937704918032787e-05, 'epoch': 3.11}         \n",
      "{'loss': 0.7262, 'learning_rate': 1.934426229508197e-05, 'epoch': 3.28}         \n",
      "{'loss': 0.7015, 'learning_rate': 1.9311475409836066e-05, 'epoch': 3.44}        \n",
      "{'loss': 0.7367, 'learning_rate': 1.9278688524590167e-05, 'epoch': 3.61}        \n",
      "{'loss': 0.7474, 'learning_rate': 1.9245901639344264e-05, 'epoch': 3.77}        \n",
      "{'loss': 0.7555, 'learning_rate': 1.921311475409836e-05, 'epoch': 3.93}         \n",
      "  4%|█▌                                      | 244/6100 [02:31<40:15,  2.42it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:44:30,629 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:44:30,629 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:44:30,629 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6816449761390686, 'eval_accuracy': 0.7613469985358712, 'eval_runtime': 4.4332, 'eval_samples_per_second': 154.065, 'eval_steps_per_second': 2.481, 'epoch': 4.0}\n",
      "  4%|█▌                                      | 244/6100 [02:35<40:15,  2.42it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.66it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:44:35,063 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-244\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:44:35,064 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-244/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:44:35,181 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-244/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:44:35,182 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-244/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:44:35,357 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-61] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7054, 'learning_rate': 1.918032786885246e-05, 'epoch': 4.1}          \n",
      "{'loss': 0.718, 'learning_rate': 1.914754098360656e-05, 'epoch': 4.26}          \n",
      "{'loss': 0.7056, 'learning_rate': 1.9114754098360657e-05, 'epoch': 4.43}        \n",
      "{'loss': 0.7372, 'learning_rate': 1.9081967213114754e-05, 'epoch': 4.59}        \n",
      "{'loss': 0.7655, 'learning_rate': 1.9049180327868855e-05, 'epoch': 4.75}        \n",
      "{'loss': 0.7563, 'learning_rate': 1.9016393442622952e-05, 'epoch': 4.92}        \n",
      "  5%|██                                      | 305/6100 [03:09<40:28,  2.39it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:45:08,834 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:45:08,834 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:45:08,834 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.26it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.65it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6631075739860535, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.496, 'eval_samples_per_second': 151.911, 'eval_steps_per_second': 2.447, 'epoch': 5.0}\n",
      "  5%|██                                      | 305/6100 [03:13<40:28,  2.39it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:45:13,331 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-305\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:45:13,332 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-305/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:45:13,440 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-305/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:45:13,441 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-305/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:45:13,614 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-122] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6609, 'learning_rate': 1.898360655737705e-05, 'epoch': 5.08}         \n",
      "{'loss': 0.7061, 'learning_rate': 1.895081967213115e-05, 'epoch': 5.25}         \n",
      "{'loss': 0.7234, 'learning_rate': 1.8918032786885248e-05, 'epoch': 5.41}        \n",
      "{'loss': 0.6878, 'learning_rate': 1.8885245901639345e-05, 'epoch': 5.57}        \n",
      "{'loss': 0.6562, 'learning_rate': 1.8852459016393446e-05, 'epoch': 5.74}        \n",
      "{'loss': 0.6826, 'learning_rate': 1.8819672131147543e-05, 'epoch': 5.9}         \n",
      "  6%|██▍                                     | 366/6100 [03:47<39:21,  2.43it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:45:47,407 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:45:47,407 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:45:47,407 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.62it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6642453670501709, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 4.4716, 'eval_samples_per_second': 152.742, 'eval_steps_per_second': 2.46, 'epoch': 6.0}\n",
      "  6%|██▍                                     | 366/6100 [03:52<39:21,  2.43it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.33it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:45:51,879 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-366\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:45:51,880 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-366/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:45:51,989 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-366/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:45:51,990 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-366/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:45:52,158 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-183] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7203, 'learning_rate': 1.878688524590164e-05, 'epoch': 6.07}         \n",
      "{'loss': 0.7092, 'learning_rate': 1.8754098360655738e-05, 'epoch': 6.23}        \n",
      "{'loss': 0.6722, 'learning_rate': 1.872131147540984e-05, 'epoch': 6.39}         \n",
      "{'loss': 0.6923, 'learning_rate': 1.8688524590163936e-05, 'epoch': 6.56}        \n",
      "{'loss': 0.6937, 'learning_rate': 1.8655737704918033e-05, 'epoch': 6.72}        \n",
      "{'loss': 0.6908, 'learning_rate': 1.862295081967213e-05, 'epoch': 6.89}         \n",
      "  7%|██▊                                     | 427/6100 [04:26<41:30,  2.28it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:46:25,792 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:46:25,792 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:46:25,792 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.75it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.00it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6426006555557251, 'eval_accuracy': 0.7730600292825769, 'eval_runtime': 4.5214, 'eval_samples_per_second': 151.059, 'eval_steps_per_second': 2.433, 'epoch': 7.0}\n",
      "  7%|██▊                                     | 427/6100 [04:30<41:30,  2.28it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:46:30,313 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-427\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:46:30,314 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-427/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:46:30,422 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-427/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:46:30,423 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-427/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:46:30,602 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-244] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6861, 'learning_rate': 1.859016393442623e-05, 'epoch': 7.05}         \n",
      "{'loss': 0.687, 'learning_rate': 1.855737704918033e-05, 'epoch': 7.21}          \n",
      "{'loss': 0.6259, 'learning_rate': 1.852459016393443e-05, 'epoch': 7.38}         \n",
      "{'loss': 0.6862, 'learning_rate': 1.8491803278688527e-05, 'epoch': 7.54}        \n",
      "{'loss': 0.6261, 'learning_rate': 1.8459016393442624e-05, 'epoch': 7.7}         \n",
      "{'loss': 0.6623, 'learning_rate': 1.842622950819672e-05, 'epoch': 7.87}         \n",
      "  8%|███▏                                    | 488/6100 [05:04<38:19,  2.44it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:47:04,185 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:47:04,185 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:47:04,185 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.82it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.75it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.58it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.45it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.645414412021637, 'eval_accuracy': 0.7715959004392386, 'eval_runtime': 4.5772, 'eval_samples_per_second': 149.218, 'eval_steps_per_second': 2.403, 'epoch': 8.0}\n",
      "  8%|███▏                                    | 488/6100 [05:09<38:19,  2.44it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:47:08,766 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-488\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:47:08,767 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-488/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:47:08,883 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-488/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:47:08,884 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-488/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:47:09,054 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-305] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6956, 'learning_rate': 1.8393442622950822e-05, 'epoch': 8.03}        \n",
      "{'loss': 0.6384, 'learning_rate': 1.836065573770492e-05, 'epoch': 8.2}          \n",
      "{'loss': 0.6347, 'learning_rate': 1.832786885245902e-05, 'epoch': 8.36}         \n",
      "{'loss': 0.7004, 'learning_rate': 1.8295081967213114e-05, 'epoch': 8.52}        \n",
      "{'loss': 0.6708, 'learning_rate': 1.8262295081967215e-05, 'epoch': 8.69}        \n",
      "{'loss': 0.7014, 'learning_rate': 1.8229508196721312e-05, 'epoch': 8.85}        \n",
      "  9%|███▌                                    | 549/6100 [05:43<38:34,  2.40it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:47:42,847 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:47:42,847 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:47:42,847 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.75it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.64it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6592214107513428, 'eval_accuracy': 0.7715959004392386, 'eval_runtime': 4.4251, 'eval_samples_per_second': 154.348, 'eval_steps_per_second': 2.486, 'epoch': 9.0}\n",
      "  9%|███▌                                    | 549/6100 [05:47<38:34,  2.40it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.30it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:47:47,273 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-549\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:47:47,273 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-549/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:47:47,385 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-549/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:47:47,385 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-549/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:47:47,556 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-366] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6728, 'learning_rate': 1.8196721311475413e-05, 'epoch': 9.02}        \n",
      "{'loss': 0.6571, 'learning_rate': 1.816393442622951e-05, 'epoch': 9.18}         \n",
      "{'loss': 0.6885, 'learning_rate': 1.8131147540983608e-05, 'epoch': 9.34}        \n",
      "{'loss': 0.6275, 'learning_rate': 1.8098360655737705e-05, 'epoch': 9.51}        \n",
      "{'loss': 0.6716, 'learning_rate': 1.8065573770491806e-05, 'epoch': 9.67}        \n",
      "{'loss': 0.6307, 'learning_rate': 1.8032786885245903e-05, 'epoch': 9.84}        \n",
      "{'loss': 0.6748, 'learning_rate': 1.8e-05, 'epoch': 10.0}                       \n",
      " 10%|████                                    | 610/6100 [06:22<39:19,  2.33it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:48:22,070 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:48:22,070 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:48:22,070 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.58it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6706007719039917, 'eval_accuracy': 0.7613469985358712, 'eval_runtime': 4.4923, 'eval_samples_per_second': 152.039, 'eval_steps_per_second': 2.449, 'epoch': 10.0}\n",
      " 10%|████                                    | 610/6100 [06:27<39:19,  2.33it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:48:26,563 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-610\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:48:26,564 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-610/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:48:26,674 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-610/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:48:26,675 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-610/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:48:26,845 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-488] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6022, 'learning_rate': 1.79672131147541e-05, 'epoch': 10.16}         \n",
      "{'loss': 0.6744, 'learning_rate': 1.79344262295082e-05, 'epoch': 10.33}         \n",
      "{'loss': 0.6638, 'learning_rate': 1.7901639344262296e-05, 'epoch': 10.49}       \n",
      "{'loss': 0.5994, 'learning_rate': 1.7868852459016393e-05, 'epoch': 10.66}       \n",
      "{'loss': 0.6689, 'learning_rate': 1.7836065573770494e-05, 'epoch': 10.82}       \n",
      "{'loss': 0.6687, 'learning_rate': 1.780327868852459e-05, 'epoch': 10.98}        \n",
      " 11%|████▍                                   | 671/6100 [07:01<38:23,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:49:00,891 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:49:00,891 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:49:00,891 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.10it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.04it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:01,  2.14it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.22it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.30it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.654583752155304, 'eval_accuracy': 0.7789165446559297, 'eval_runtime': 5.2901, 'eval_samples_per_second': 129.108, 'eval_steps_per_second': 2.079, 'epoch': 11.0}\n",
      " 11%|████▍                                   | 671/6100 [07:06<38:23,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:49:06,182 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-671\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:49:06,182 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-671/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:49:06,290 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-671/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:49:06,291 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-671/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:49:06,463 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-549] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6075, 'learning_rate': 1.7770491803278692e-05, 'epoch': 11.15}       \n",
      "{'loss': 0.6382, 'learning_rate': 1.7737704918032786e-05, 'epoch': 11.31}       \n",
      "{'loss': 0.6307, 'learning_rate': 1.7704918032786887e-05, 'epoch': 11.48}       \n",
      "{'loss': 0.6443, 'learning_rate': 1.7672131147540984e-05, 'epoch': 11.64}       \n",
      "{'loss': 0.6841, 'learning_rate': 1.7639344262295085e-05, 'epoch': 11.8}        \n",
      "{'loss': 0.6664, 'learning_rate': 1.7606557377049182e-05, 'epoch': 11.97}       \n",
      " 12%|████▊                                   | 732/6100 [07:40<37:07,  2.41it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:49:40,398 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:49:40,399 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:49:40,399 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.85it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.62it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.30it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6328350305557251, 'eval_accuracy': 0.7774524158125915, 'eval_runtime': 4.5772, 'eval_samples_per_second': 149.219, 'eval_steps_per_second': 2.403, 'epoch': 12.0}\n",
      " 12%|████▊                                   | 732/6100 [07:45<37:07,  2.41it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:49:44,976 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-732\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:49:44,977 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-732/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:49:45,137 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-732/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:49:45,138 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-732/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:49:45,308 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-427] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6192, 'learning_rate': 1.757377049180328e-05, 'epoch': 12.13}        \n",
      "{'loss': 0.6324, 'learning_rate': 1.7540983606557377e-05, 'epoch': 12.3}        \n",
      "{'loss': 0.7174, 'learning_rate': 1.7508196721311478e-05, 'epoch': 12.46}       \n",
      "{'loss': 0.6063, 'learning_rate': 1.7475409836065575e-05, 'epoch': 12.62}       \n",
      "{'loss': 0.6641, 'learning_rate': 1.7442622950819676e-05, 'epoch': 12.79}       \n",
      "{'loss': 0.6072, 'learning_rate': 1.740983606557377e-05, 'epoch': 12.95}        \n",
      " 13%|█████▏                                  | 793/6100 [08:20<36:50,  2.40it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:50:20,278 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:50:20,278 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:50:20,278 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.79it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.60it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6358870267868042, 'eval_accuracy': 0.7818448023426061, 'eval_runtime': 4.4831, 'eval_samples_per_second': 152.349, 'eval_steps_per_second': 2.454, 'epoch': 13.0}\n",
      " 13%|█████▏                                  | 793/6100 [08:25<36:50,  2.40it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:50:24,761 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-793\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:50:24,764 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-793/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:50:24,876 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-793/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:50:24,877 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-793/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:50:25,046 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-610] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5956, 'learning_rate': 1.737704918032787e-05, 'epoch': 13.11}        \n",
      "{'loss': 0.6443, 'learning_rate': 1.7344262295081968e-05, 'epoch': 13.28}       \n",
      "{'loss': 0.6231, 'learning_rate': 1.731147540983607e-05, 'epoch': 13.44}        \n",
      "{'loss': 0.578, 'learning_rate': 1.7278688524590166e-05, 'epoch': 13.61}        \n",
      "{'loss': 0.5893, 'learning_rate': 1.7245901639344263e-05, 'epoch': 13.77}       \n",
      "{'loss': 0.6245, 'learning_rate': 1.721311475409836e-05, 'epoch': 13.93}        \n",
      " 14%|█████▌                                  | 854/6100 [09:00<37:31,  2.33it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:50:59,748 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:50:59,748 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:50:59,748 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.48it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.78it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6535177826881409, 'eval_accuracy': 0.7598828696925329, 'eval_runtime': 6.1589, 'eval_samples_per_second': 110.896, 'eval_steps_per_second': 1.786, 'epoch': 14.0}\n",
      " 14%|█████▌                                  | 854/6100 [09:06<37:31,  2.33it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:51:05,907 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-854\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:51:05,908 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-854/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:51:06,056 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-854/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:51:06,057 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-854/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:51:06,292 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-671] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6465, 'learning_rate': 1.718032786885246e-05, 'epoch': 14.1}         \n",
      "{'loss': 0.6134, 'learning_rate': 1.714754098360656e-05, 'epoch': 14.26}        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6594, 'learning_rate': 1.711475409836066e-05, 'epoch': 14.43}        \n",
      "{'loss': 0.596, 'learning_rate': 1.7081967213114757e-05, 'epoch': 14.59}        \n",
      "{'loss': 0.6391, 'learning_rate': 1.7049180327868854e-05, 'epoch': 14.75}       \n",
      "{'loss': 0.667, 'learning_rate': 1.701639344262295e-05, 'epoch': 14.92}         \n",
      " 15%|██████                                  | 915/6100 [09:41<36:13,  2.39it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:51:40,903 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:51:40,903 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:51:40,903 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.43it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.84it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.72it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.64it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.746557354927063, 'eval_accuracy': 0.7364568081991215, 'eval_runtime': 4.4751, 'eval_samples_per_second': 152.622, 'eval_steps_per_second': 2.458, 'epoch': 15.0}\n",
      " 15%|██████                                  | 915/6100 [09:45<36:13,  2.39it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:51:45,379 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-915\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:51:45,379 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-915/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:51:45,486 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-915/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:51:45,487 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-915/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:51:45,658 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-793] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.601, 'learning_rate': 1.6983606557377052e-05, 'epoch': 15.08}        \n",
      "{'loss': 0.6104, 'learning_rate': 1.695081967213115e-05, 'epoch': 15.25}        \n",
      "{'loss': 0.5892, 'learning_rate': 1.6918032786885247e-05, 'epoch': 15.41}       \n",
      "{'loss': 0.6742, 'learning_rate': 1.6885245901639347e-05, 'epoch': 15.57}       \n",
      "{'loss': 0.6193, 'learning_rate': 1.6852459016393445e-05, 'epoch': 15.74}       \n",
      "{'loss': 0.5757, 'learning_rate': 1.6819672131147542e-05, 'epoch': 15.9}        \n",
      " 16%|██████▍                                 | 976/6100 [10:21<42:38,  2.00it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:52:21,310 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:52:21,310 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:52:21,310 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.44it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.81it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.94it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.08it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.18it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6485611796379089, 'eval_accuracy': 0.7745241581259151, 'eval_runtime': 5.6196, 'eval_samples_per_second': 121.54, 'eval_steps_per_second': 1.957, 'epoch': 16.0}\n",
      " 16%|██████▍                                 | 976/6100 [10:27<42:38,  2.00it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.10it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:52:26,930 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-976\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:52:26,931 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-976/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:52:27,039 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-976/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:52:27,040 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-976/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:52:27,214 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-854] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.669, 'learning_rate': 1.678688524590164e-05, 'epoch': 16.07}         \n",
      "{'loss': 0.5738, 'learning_rate': 1.675409836065574e-05, 'epoch': 16.23}        \n",
      "{'loss': 0.5432, 'learning_rate': 1.6721311475409837e-05, 'epoch': 16.39}       \n",
      "{'loss': 0.6313, 'learning_rate': 1.6688524590163935e-05, 'epoch': 16.56}       \n",
      "{'loss': 0.6427, 'learning_rate': 1.6655737704918032e-05, 'epoch': 16.72}       \n",
      "{'loss': 0.5918, 'learning_rate': 1.6622950819672133e-05, 'epoch': 16.89}       \n",
      " 17%|██████▋                                | 1037/6100 [11:02<35:09,  2.40it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:53:01,914 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:53:01,915 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:53:01,915 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.56it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.26it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6451940536499023, 'eval_accuracy': 0.7715959004392386, 'eval_runtime': 4.5522, 'eval_samples_per_second': 150.039, 'eval_steps_per_second': 2.416, 'epoch': 17.0}\n",
      " 17%|██████▋                                | 1037/6100 [11:07<35:09,  2.40it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:53:06,470 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1037\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:53:06,471 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1037/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:53:06,588 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1037/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:53:06,589 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1037/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:53:06,760 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-915] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5787, 'learning_rate': 1.659016393442623e-05, 'epoch': 17.05}        \n",
      "{'loss': 0.5856, 'learning_rate': 1.655737704918033e-05, 'epoch': 17.21}        \n",
      "{'loss': 0.5584, 'learning_rate': 1.6524590163934428e-05, 'epoch': 17.38}       \n",
      "{'loss': 0.6339, 'learning_rate': 1.6491803278688526e-05, 'epoch': 17.54}       \n",
      "{'loss': 0.6407, 'learning_rate': 1.6459016393442623e-05, 'epoch': 17.7}        \n",
      "{'loss': 0.6584, 'learning_rate': 1.6426229508196724e-05, 'epoch': 17.87}       \n",
      " 18%|███████                                | 1098/6100 [11:43<43:40,  1.91it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:53:43,241 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:53:43,241 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:53:43,241 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.38it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.42it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.40it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.37it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6365063190460205, 'eval_accuracy': 0.7862371888726208, 'eval_runtime': 5.0848, 'eval_samples_per_second': 134.323, 'eval_steps_per_second': 2.163, 'epoch': 18.0}\n",
      " 18%|███████                                | 1098/6100 [11:48<43:40,  1.91it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:53:48,326 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1098\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:53:48,326 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1098/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:53:48,436 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1098/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:53:48,436 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1098/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:53:48,608 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-976] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5939, 'learning_rate': 1.639344262295082e-05, 'epoch': 18.03}        \n",
      "{'loss': 0.5674, 'learning_rate': 1.6360655737704922e-05, 'epoch': 18.2}        \n",
      "{'loss': 0.588, 'learning_rate': 1.6327868852459016e-05, 'epoch': 18.36}        \n",
      "{'loss': 0.5633, 'learning_rate': 1.6295081967213116e-05, 'epoch': 18.52}       \n",
      "{'loss': 0.5935, 'learning_rate': 1.6262295081967214e-05, 'epoch': 18.69}       \n",
      "{'loss': 0.5565, 'learning_rate': 1.6229508196721314e-05, 'epoch': 18.85}       \n",
      " 19%|███████▍                               | 1159/6100 [12:24<34:39,  2.38it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:54:24,011 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:54:24,011 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:54:24,011 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.68it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.60it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.32it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6499653458595276, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.5324, 'eval_samples_per_second': 150.691, 'eval_steps_per_second': 2.427, 'epoch': 19.0}\n",
      " 19%|███████▍                               | 1159/6100 [12:29<34:39,  2.38it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:54:28,544 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1159\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:54:28,544 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1159/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:54:28,645 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1159/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:54:28,646 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1159/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:54:28,817 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1037] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6204, 'learning_rate': 1.6196721311475412e-05, 'epoch': 19.02}       \n",
      "{'loss': 0.6325, 'learning_rate': 1.616393442622951e-05, 'epoch': 19.18}        \n",
      "{'loss': 0.6239, 'learning_rate': 1.6131147540983607e-05, 'epoch': 19.34}       \n",
      "{'loss': 0.6051, 'learning_rate': 1.6098360655737707e-05, 'epoch': 19.51}       \n",
      "{'loss': 0.5798, 'learning_rate': 1.6065573770491805e-05, 'epoch': 19.67}       \n",
      "{'loss': 0.5853, 'learning_rate': 1.6032786885245902e-05, 'epoch': 19.84}       \n",
      "{'loss': 0.598, 'learning_rate': 1.6000000000000003e-05, 'epoch': 20.0}         \n",
      " 20%|███████▊                               | 1220/6100 [13:05<36:13,  2.25it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:55:04,709 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:55:04,709 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:55:04,709 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.09it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.95it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6315969228744507, 'eval_accuracy': 0.780380673499268, 'eval_runtime': 5.8746, 'eval_samples_per_second': 116.263, 'eval_steps_per_second': 1.872, 'epoch': 20.0}\n",
      " 20%|███████▊                               | 1220/6100 [13:11<36:13,  2.25it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.17it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:55:10,584 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1220\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:55:10,584 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1220/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:55:10,679 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1220/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:55:10,680 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1220/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:55:10,851 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-732] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5381, 'learning_rate': 1.59672131147541e-05, 'epoch': 20.16}         \n",
      "{'loss': 0.5572, 'learning_rate': 1.5934426229508197e-05, 'epoch': 20.33}       \n",
      "{'loss': 0.5778, 'learning_rate': 1.5901639344262295e-05, 'epoch': 20.49}       \n",
      "{'loss': 0.6293, 'learning_rate': 1.5868852459016395e-05, 'epoch': 20.66}       \n",
      "{'loss': 0.5745, 'learning_rate': 1.5836065573770493e-05, 'epoch': 20.82}       \n",
      "{'loss': 0.5707, 'learning_rate': 1.580327868852459e-05, 'epoch': 20.98}        \n",
      " 21%|████████▏                              | 1281/6100 [13:47<33:22,  2.41it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:55:46,677 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:55:46,677 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:55:46,677 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6491104960441589, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.4579, 'eval_samples_per_second': 153.211, 'eval_steps_per_second': 2.468, 'epoch': 21.0}\n",
      " 21%|████████▏                              | 1281/6100 [13:51<33:22,  2.41it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:55:51,135 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1281\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:55:51,136 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1281/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:55:51,249 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1281/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:55:51,249 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1281/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:55:51,423 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1098] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5312, 'learning_rate': 1.5770491803278687e-05, 'epoch': 21.15}       \n",
      "{'loss': 0.5119, 'learning_rate': 1.5737704918032788e-05, 'epoch': 21.31}       \n",
      "{'loss': 0.5553, 'learning_rate': 1.5704918032786886e-05, 'epoch': 21.48}       \n",
      "{'loss': 0.6379, 'learning_rate': 1.5672131147540986e-05, 'epoch': 21.64}       \n",
      "{'loss': 0.611, 'learning_rate': 1.5639344262295084e-05, 'epoch': 21.8}         \n",
      "{'loss': 0.5422, 'learning_rate': 1.560655737704918e-05, 'epoch': 21.97}        \n",
      " 22%|████████▌                              | 1342/6100 [14:27<33:34,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:56:27,039 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:56:27,039 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:56:27,039 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6988811492919922, 'eval_accuracy': 0.7525622254758418, 'eval_runtime': 5.9376, 'eval_samples_per_second': 115.03, 'eval_steps_per_second': 1.853, 'epoch': 22.0}\n",
      " 22%|████████▌                              | 1342/6100 [14:33<33:34,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:56:32,977 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1342\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:56:32,978 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1342/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:56:33,146 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1342/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:56:33,147 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1342/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:56:33,387 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1159] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5428, 'learning_rate': 1.5573770491803278e-05, 'epoch': 22.13}       \n",
      "{'loss': 0.5497, 'learning_rate': 1.554098360655738e-05, 'epoch': 22.3}         \n",
      "{'loss': 0.582, 'learning_rate': 1.5508196721311476e-05, 'epoch': 22.46}        \n",
      "{'loss': 0.6159, 'learning_rate': 1.5475409836065577e-05, 'epoch': 22.62}       \n",
      "{'loss': 0.5724, 'learning_rate': 1.544262295081967e-05, 'epoch': 22.79}        \n",
      "{'loss': 0.4968, 'learning_rate': 1.5409836065573772e-05, 'epoch': 22.95}       \n",
      " 23%|████████▉                              | 1403/6100 [15:10<34:35,  2.26it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:57:10,262 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:57:10,262 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:57:10,262 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6432023048400879, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.5385, 'eval_samples_per_second': 150.491, 'eval_steps_per_second': 2.424, 'epoch': 23.0}\n",
      " 23%|████████▉                              | 1403/6100 [15:15<34:35,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:57:14,804 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1403\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:57:14,805 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1403/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:57:14,915 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1403/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:57:14,915 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1403/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:57:15,084 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1281] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5552, 'learning_rate': 1.537704918032787e-05, 'epoch': 23.11}        \n",
      "{'loss': 0.54, 'learning_rate': 1.534426229508197e-05, 'epoch': 23.28}          \n",
      "{'loss': 0.5217, 'learning_rate': 1.5311475409836067e-05, 'epoch': 23.44}       \n",
      "{'loss': 0.6017, 'learning_rate': 1.5278688524590165e-05, 'epoch': 23.61}       \n",
      "{'loss': 0.5322, 'learning_rate': 1.5245901639344264e-05, 'epoch': 23.77}       \n",
      "{'loss': 0.6155, 'learning_rate': 1.5213114754098361e-05, 'epoch': 23.93}       \n",
      " 24%|█████████▎                             | 1464/6100 [15:51<31:56,  2.42it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:57:50,512 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:57:50,512 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:57:50,512 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.78it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.74it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.57it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.59it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6824960112571716, 'eval_accuracy': 0.7569546120058566, 'eval_runtime': 4.5446, 'eval_samples_per_second': 150.289, 'eval_steps_per_second': 2.42, 'epoch': 24.0}\n",
      " 24%|█████████▎                             | 1464/6100 [15:55<31:56,  2.42it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.34it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:57:55,057 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1464\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:57:55,058 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1464/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:57:55,170 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1464/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:57:55,170 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1464/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:57:55,346 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1342] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.501, 'learning_rate': 1.518032786885246e-05, 'epoch': 24.1}          \n",
      "{'loss': 0.5292, 'learning_rate': 1.5147540983606559e-05, 'epoch': 24.26}       \n",
      "{'loss': 0.5634, 'learning_rate': 1.5114754098360658e-05, 'epoch': 24.43}       \n",
      "{'loss': 0.5624, 'learning_rate': 1.5081967213114754e-05, 'epoch': 24.59}       \n",
      "{'loss': 0.5249, 'learning_rate': 1.5049180327868853e-05, 'epoch': 24.75}       \n",
      "{'loss': 0.5357, 'learning_rate': 1.5016393442622952e-05, 'epoch': 24.92}       \n",
      " 25%|█████████▊                             | 1525/6100 [16:33<38:03,  2.00it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:58:32,521 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:58:32,521 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:58:32,521 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.34it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.05it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.84it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6452742218971252, 'eval_accuracy': 0.7730600292825769, 'eval_runtime': 6.1967, 'eval_samples_per_second': 110.22, 'eval_steps_per_second': 1.775, 'epoch': 25.0}\n",
      " 25%|█████████▊                             | 1525/6100 [16:39<38:03,  2.00it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:58:38,718 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1525\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:58:38,719 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1525/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:58:38,869 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1525/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:58:38,869 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1525/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:58:39,109 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1403] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5172, 'learning_rate': 1.498360655737705e-05, 'epoch': 25.08}        \n",
      "{'loss': 0.5264, 'learning_rate': 1.495081967213115e-05, 'epoch': 25.25}        \n",
      "{'loss': 0.5306, 'learning_rate': 1.4918032786885249e-05, 'epoch': 25.41}       \n",
      "{'loss': 0.5875, 'learning_rate': 1.4885245901639344e-05, 'epoch': 25.57}       \n",
      "{'loss': 0.5333, 'learning_rate': 1.4852459016393443e-05, 'epoch': 25.74}       \n",
      "{'loss': 0.4897, 'learning_rate': 1.4819672131147543e-05, 'epoch': 25.9}        \n",
      " 26%|██████████▏                            | 1586/6100 [17:15<31:48,  2.37it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:59:15,196 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:59:15,196 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:59:15,196 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.76it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6833707690238953, 'eval_accuracy': 0.7569546120058566, 'eval_runtime': 4.5065, 'eval_samples_per_second': 151.558, 'eval_steps_per_second': 2.441, 'epoch': 26.0}\n",
      " 26%|██████████▏                            | 1586/6100 [17:20<31:48,  2.37it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 09:59:19,704 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1586\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 09:59:19,704 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1586/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 09:59:19,808 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1586/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 09:59:19,809 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1586/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 09:59:19,977 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1464] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5379, 'learning_rate': 1.4786885245901642e-05, 'epoch': 26.07}       \n",
      "{'loss': 0.5585, 'learning_rate': 1.4754098360655739e-05, 'epoch': 26.23}       \n",
      "{'loss': 0.4901, 'learning_rate': 1.4721311475409836e-05, 'epoch': 26.39}       \n",
      "{'loss': 0.513, 'learning_rate': 1.4688524590163935e-05, 'epoch': 26.56}        \n",
      "{'loss': 0.488, 'learning_rate': 1.4655737704918034e-05, 'epoch': 26.72}        \n",
      "{'loss': 0.5309, 'learning_rate': 1.4622950819672133e-05, 'epoch': 26.89}       \n",
      " 27%|██████████▌                            | 1647/6100 [17:56<31:03,  2.39it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 09:59:56,095 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 09:59:56,095 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 09:59:56,095 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.88it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.638415515422821, 'eval_accuracy': 0.7920937042459737, 'eval_runtime': 4.576, 'eval_samples_per_second': 149.256, 'eval_steps_per_second': 2.404, 'epoch': 27.0}\n",
      " 27%|██████████▌                            | 1647/6100 [18:01<31:03,  2.39it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:00:00,672 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1647\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:00:00,672 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1647/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:00:00,780 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1647/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:00:00,781 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1647/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:00:01,022 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1525] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5432, 'learning_rate': 1.459016393442623e-05, 'epoch': 27.05}        \n",
      "{'loss': 0.4671, 'learning_rate': 1.455737704918033e-05, 'epoch': 27.21}        \n",
      "{'loss': 0.5654, 'learning_rate': 1.4524590163934427e-05, 'epoch': 27.38}       \n",
      "{'loss': 0.4723, 'learning_rate': 1.4491803278688526e-05, 'epoch': 27.54}       \n",
      "{'loss': 0.4889, 'learning_rate': 1.4459016393442623e-05, 'epoch': 27.7}        \n",
      "{'loss': 0.5458, 'learning_rate': 1.4426229508196722e-05, 'epoch': 27.87}       \n",
      " 28%|██████████▉                            | 1708/6100 [18:39<37:23,  1.96it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:00:38,687 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:00:38,687 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:00:38,687 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.69it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6404941082000732, 'eval_accuracy': 0.7745241581259151, 'eval_runtime': 6.2461, 'eval_samples_per_second': 109.348, 'eval_steps_per_second': 1.761, 'epoch': 28.0}\n",
      " 28%|██████████▉                            | 1708/6100 [18:45<37:23,  1.96it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:00:44,934 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1708\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:00:44,935 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1708/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:00:45,083 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1708/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:00:45,084 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1708/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2887] 2023-10-05 10:00:45,324 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1586] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4835, 'learning_rate': 1.4393442622950822e-05, 'epoch': 28.03}       \n",
      "{'loss': 0.4626, 'learning_rate': 1.4360655737704919e-05, 'epoch': 28.2}        \n",
      "{'loss': 0.583, 'learning_rate': 1.4327868852459016e-05, 'epoch': 28.36}        \n",
      "{'loss': 0.5027, 'learning_rate': 1.4295081967213115e-05, 'epoch': 28.52}       \n",
      "{'loss': 0.5454, 'learning_rate': 1.4262295081967214e-05, 'epoch': 28.69}       \n",
      "{'loss': 0.5004, 'learning_rate': 1.4229508196721313e-05, 'epoch': 28.85}       \n",
      " 29%|███████████▎                           | 1769/6100 [19:21<30:19,  2.38it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:01:21,414 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:01:21,414 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:01:21,414 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.97it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6545004844665527, 'eval_accuracy': 0.7847730600292826, 'eval_runtime': 4.5286, 'eval_samples_per_second': 150.818, 'eval_steps_per_second': 2.429, 'epoch': 29.0}\n",
      " 29%|███████████▎                           | 1769/6100 [19:26<30:19,  2.38it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:01:25,943 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1769\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:01:25,944 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1769/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:01:26,060 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1769/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:01:26,060 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1769/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:01:26,233 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1647] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5419, 'learning_rate': 1.4196721311475412e-05, 'epoch': 29.02}       \n",
      "{'loss': 0.523, 'learning_rate': 1.4163934426229508e-05, 'epoch': 29.18}        \n",
      "{'loss': 0.5559, 'learning_rate': 1.4131147540983607e-05, 'epoch': 29.34}       \n",
      "{'loss': 0.5122, 'learning_rate': 1.4098360655737706e-05, 'epoch': 29.51}       \n",
      "{'loss': 0.4699, 'learning_rate': 1.4065573770491805e-05, 'epoch': 29.67}       \n",
      "{'loss': 0.5004, 'learning_rate': 1.4032786885245904e-05, 'epoch': 29.84}       \n",
      "{'loss': 0.5178, 'learning_rate': 1.4e-05, 'epoch': 30.0}                       \n",
      " 30%|███████████▋                           | 1830/6100 [20:03<29:35,  2.40it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:02:03,077 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:02:03,077 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:02:03,077 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6617401838302612, 'eval_accuracy': 0.7759882869692533, 'eval_runtime': 4.5774, 'eval_samples_per_second': 149.212, 'eval_steps_per_second': 2.403, 'epoch': 30.0}\n",
      " 30%|███████████▋                           | 1830/6100 [20:08<29:35,  2.40it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:02:07,655 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1830\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:02:07,656 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1830/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:02:07,758 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1830/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:02:07,759 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1830/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:02:07,935 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1708] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4787, 'learning_rate': 1.3967213114754099e-05, 'epoch': 30.16}       \n",
      "{'loss': 0.5307, 'learning_rate': 1.3934426229508198e-05, 'epoch': 30.33}       \n",
      "{'loss': 0.497, 'learning_rate': 1.3901639344262297e-05, 'epoch': 30.49}        \n",
      "{'loss': 0.5101, 'learning_rate': 1.3868852459016396e-05, 'epoch': 30.66}       \n",
      "{'loss': 0.482, 'learning_rate': 1.3836065573770492e-05, 'epoch': 30.82}        \n",
      "{'loss': 0.5368, 'learning_rate': 1.380327868852459e-05, 'epoch': 30.98}        \n",
      " 31%|████████████                           | 1891/6100 [20:45<29:32,  2.37it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:02:44,937 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:02:44,937 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:02:44,937 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.35it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.22it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.06it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.95it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.88it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.85it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6564513444900513, 'eval_accuracy': 0.7745241581259151, 'eval_runtime': 5.6177, 'eval_samples_per_second': 121.58, 'eval_steps_per_second': 1.958, 'epoch': 31.0}\n",
      " 31%|████████████                           | 1891/6100 [20:51<29:32,  2.37it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.59it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:02:50,559 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1891\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:02:50,561 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1891/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:02:50,718 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1891/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:02:50,719 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1891/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:02:50,959 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1769] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.506, 'learning_rate': 1.377049180327869e-05, 'epoch': 31.15}         \n",
      "{'loss': 0.4692, 'learning_rate': 1.3737704918032789e-05, 'epoch': 31.31}       \n",
      "{'loss': 0.4698, 'learning_rate': 1.3704918032786888e-05, 'epoch': 31.48}       \n",
      "{'loss': 0.4728, 'learning_rate': 1.3672131147540985e-05, 'epoch': 31.64}       \n",
      "{'loss': 0.5021, 'learning_rate': 1.3639344262295082e-05, 'epoch': 31.8}        \n",
      "{'loss': 0.5048, 'learning_rate': 1.3606557377049181e-05, 'epoch': 31.97}       \n",
      " 32%|████████████▍                          | 1952/6100 [21:28<32:11,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:03:28,212 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:03:28,212 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:03:28,212 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6595507860183716, 'eval_accuracy': 0.7774524158125915, 'eval_runtime': 4.5232, 'eval_samples_per_second': 150.999, 'eval_steps_per_second': 2.432, 'epoch': 32.0}\n",
      " 32%|████████████▍                          | 1952/6100 [21:33<32:11,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:03:32,736 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1952\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:03:32,736 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1952/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:03:32,850 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1952/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:03:32,850 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1952/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:03:33,024 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1830] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4789, 'learning_rate': 1.357377049180328e-05, 'epoch': 32.13}        \n",
      "{'loss': 0.448, 'learning_rate': 1.3540983606557378e-05, 'epoch': 32.3}         \n",
      "{'loss': 0.4861, 'learning_rate': 1.3508196721311477e-05, 'epoch': 32.46}       \n",
      "{'loss': 0.5109, 'learning_rate': 1.3475409836065574e-05, 'epoch': 32.62}       \n",
      "{'loss': 0.4623, 'learning_rate': 1.3442622950819673e-05, 'epoch': 32.79}       \n",
      "{'loss': 0.4913, 'learning_rate': 1.340983606557377e-05, 'epoch': 32.95}        \n",
      " 33%|████████████▊                          | 2013/6100 [22:11<28:40,  2.37it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:04:11,058 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:04:11,058 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:04:11,058 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.73it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.72it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6797499656677246, 'eval_accuracy': 0.7715959004392386, 'eval_runtime': 4.4678, 'eval_samples_per_second': 152.871, 'eval_steps_per_second': 2.462, 'epoch': 33.0}\n",
      " 33%|████████████▊                          | 2013/6100 [22:16<28:40,  2.37it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:04:15,526 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2013\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:04:15,527 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2013/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:04:15,646 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2013/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:04:15,646 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2013/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:04:15,824 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1891] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4844, 'learning_rate': 1.337704918032787e-05, 'epoch': 33.11}        \n",
      "{'loss': 0.4595, 'learning_rate': 1.3344262295081969e-05, 'epoch': 33.28}       \n",
      "{'loss': 0.4748, 'learning_rate': 1.3311475409836068e-05, 'epoch': 33.44}       \n",
      "{'loss': 0.5237, 'learning_rate': 1.3278688524590165e-05, 'epoch': 33.61}       \n",
      "{'loss': 0.4382, 'learning_rate': 1.3245901639344262e-05, 'epoch': 33.77}       \n",
      "{'loss': 0.4985, 'learning_rate': 1.3213114754098361e-05, 'epoch': 33.93}       \n",
      " 34%|█████████████▎                         | 2074/6100 [22:52<28:13,  2.38it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:04:52,039 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:04:52,039 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:04:52,039 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.78it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.34it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.701888382434845, 'eval_accuracy': 0.7701317715959004, 'eval_runtime': 4.5585, 'eval_samples_per_second': 149.83, 'eval_steps_per_second': 2.413, 'epoch': 34.0}\n",
      " 34%|█████████████▎                         | 2074/6100 [22:57<28:13,  2.38it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.24it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:04:56,598 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2074\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:04:56,599 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2074/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:04:56,710 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2074/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:04:56,711 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2074/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:04:56,887 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1952] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4528, 'learning_rate': 1.318032786885246e-05, 'epoch': 34.1}         \n",
      "{'loss': 0.4542, 'learning_rate': 1.314754098360656e-05, 'epoch': 34.26}        \n",
      "{'loss': 0.4743, 'learning_rate': 1.3114754098360655e-05, 'epoch': 34.43}       \n",
      "{'loss': 0.4945, 'learning_rate': 1.3081967213114754e-05, 'epoch': 34.59}       \n",
      "{'loss': 0.4314, 'learning_rate': 1.3049180327868853e-05, 'epoch': 34.75}       \n",
      "{'loss': 0.4493, 'learning_rate': 1.3016393442622952e-05, 'epoch': 34.92}       \n",
      " 35%|█████████████▋                         | 2135/6100 [23:35<32:24,  2.04it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:05:34,486 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:05:34,486 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:05:34,486 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.05it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.93it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7523383498191833, 'eval_accuracy': 0.739385065885798, 'eval_runtime': 6.1365, 'eval_samples_per_second': 111.302, 'eval_steps_per_second': 1.793, 'epoch': 35.0}\n",
      " 35%|█████████████▋                         | 2135/6100 [23:41<32:24,  2.04it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:05:40,623 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2135\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:05:40,625 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2135/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:05:40,783 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2135/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:05:40,783 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2135/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:05:41,022 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2013] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5002, 'learning_rate': 1.2983606557377051e-05, 'epoch': 35.08}       \n",
      "{'loss': 0.4408, 'learning_rate': 1.295081967213115e-05, 'epoch': 35.25}        \n",
      "{'loss': 0.4692, 'learning_rate': 1.2918032786885246e-05, 'epoch': 35.41}       \n",
      "{'loss': 0.4217, 'learning_rate': 1.2885245901639345e-05, 'epoch': 35.57}       \n",
      "{'loss': 0.4714, 'learning_rate': 1.2852459016393444e-05, 'epoch': 35.74}       \n",
      "{'loss': 0.4822, 'learning_rate': 1.2819672131147543e-05, 'epoch': 35.9}        \n",
      " 36%|██████████████                         | 2196/6100 [24:18<32:57,  1.97it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:06:18,339 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:06:18,340 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:06:18,340 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:01,  2.03it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.12it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.15it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7203977108001709, 'eval_accuracy': 0.7525622254758418, 'eval_runtime': 5.566, 'eval_samples_per_second': 122.71, 'eval_steps_per_second': 1.976, 'epoch': 36.0}\n",
      " 36%|██████████████                         | 2196/6100 [24:24<32:57,  1.97it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.33it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:06:23,906 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2196\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:06:23,906 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2196/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:06:24,018 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2196/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:06:24,018 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2196/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:06:24,189 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2074] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4698, 'learning_rate': 1.2786885245901642e-05, 'epoch': 36.07}       \n",
      "{'loss': 0.4818, 'learning_rate': 1.2754098360655738e-05, 'epoch': 36.23}       \n",
      "{'loss': 0.4691, 'learning_rate': 1.2721311475409837e-05, 'epoch': 36.39}       \n",
      "{'loss': 0.4509, 'learning_rate': 1.2688524590163936e-05, 'epoch': 36.56}       \n",
      "{'loss': 0.478, 'learning_rate': 1.2655737704918035e-05, 'epoch': 36.72}        \n",
      "{'loss': 0.4584, 'learning_rate': 1.2622950819672132e-05, 'epoch': 36.89}       \n",
      " 37%|██████████████▍                        | 2257/6100 [25:01<27:07,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:07:00,868 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:07:00,868 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:07:00,868 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.96it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.61it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7015315890312195, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.4922, 'eval_samples_per_second': 152.043, 'eval_steps_per_second': 2.449, 'epoch': 37.0}\n",
      " 37%|██████████████▍                        | 2257/6100 [25:05<27:07,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:07:05,361 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2257\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:07:05,362 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2257/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:07:05,471 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2257/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:07:05,472 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2257/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:07:05,647 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2135] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4707, 'learning_rate': 1.2590163934426231e-05, 'epoch': 37.05}       \n",
      "{'loss': 0.5295, 'learning_rate': 1.2557377049180329e-05, 'epoch': 37.21}       \n",
      "{'loss': 0.4251, 'learning_rate': 1.2524590163934428e-05, 'epoch': 37.38}       \n",
      "{'loss': 0.4355, 'learning_rate': 1.2491803278688525e-05, 'epoch': 37.54}       \n",
      "{'loss': 0.438, 'learning_rate': 1.2459016393442624e-05, 'epoch': 37.7}         \n",
      "{'loss': 0.4451, 'learning_rate': 1.2426229508196723e-05, 'epoch': 37.87}       \n",
      " 38%|██████████████▊                        | 2318/6100 [25:43<26:27,  2.38it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:07:42,498 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:07:42,498 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:07:42,498 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.06it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.59it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.84it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.60it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6879651546478271, 'eval_accuracy': 0.7730600292825769, 'eval_runtime': 4.4519, 'eval_samples_per_second': 153.419, 'eval_steps_per_second': 2.471, 'epoch': 38.0}\n",
      " 38%|██████████████▊                        | 2318/6100 [25:47<26:27,  2.38it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:07:46,950 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2318\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:07:46,951 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2318/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:07:47,069 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2318/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:07:47,069 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2318/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:07:47,247 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2196] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4151, 'learning_rate': 1.239344262295082e-05, 'epoch': 38.03}        \n",
      "{'loss': 0.387, 'learning_rate': 1.236065573770492e-05, 'epoch': 38.2}          \n",
      "{'loss': 0.408, 'learning_rate': 1.2327868852459017e-05, 'epoch': 38.36}        \n",
      "{'loss': 0.4831, 'learning_rate': 1.2295081967213116e-05, 'epoch': 38.52}       \n",
      "{'loss': 0.4293, 'learning_rate': 1.2262295081967215e-05, 'epoch': 38.69}       \n",
      "{'loss': 0.43, 'learning_rate': 1.2229508196721312e-05, 'epoch': 38.85}         \n",
      " 39%|███████████████▏                       | 2379/6100 [26:24<27:39,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:08:24,021 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:08:24,021 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:08:24,022 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.47it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7133259177207947, 'eval_accuracy': 0.7613469985358712, 'eval_runtime': 6.1727, 'eval_samples_per_second': 110.648, 'eval_steps_per_second': 1.782, 'epoch': 39.0}\n",
      " 39%|███████████████▏                       | 2379/6100 [26:30<27:39,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:08:30,194 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2379\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:08:30,195 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2379/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:08:30,324 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2379/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:08:30,325 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2379/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:08:30,574 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2257] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4519, 'learning_rate': 1.219672131147541e-05, 'epoch': 39.02}        \n",
      "{'loss': 0.4646, 'learning_rate': 1.2163934426229509e-05, 'epoch': 39.18}       \n",
      "{'loss': 0.4304, 'learning_rate': 1.2131147540983608e-05, 'epoch': 39.34}       \n",
      "{'loss': 0.4454, 'learning_rate': 1.2098360655737707e-05, 'epoch': 39.51}       \n",
      "{'loss': 0.4617, 'learning_rate': 1.2065573770491806e-05, 'epoch': 39.67}       \n",
      "{'loss': 0.4511, 'learning_rate': 1.2032786885245901e-05, 'epoch': 39.84}       \n",
      "{'loss': 0.4858, 'learning_rate': 1.2e-05, 'epoch': 40.0}                       \n",
      " 40%|███████████████▌                       | 2440/6100 [27:08<30:46,  1.98it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:09:08,092 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:09:08,092 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:09:08,092 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.05it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7149244546890259, 'eval_accuracy': 0.7642752562225475, 'eval_runtime': 6.2526, 'eval_samples_per_second': 109.234, 'eval_steps_per_second': 1.759, 'epoch': 40.0}\n",
      " 40%|███████████████▌                       | 2440/6100 [27:14<30:46,  1.98it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:09:14,345 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2440\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:09:14,346 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2440/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:09:14,505 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2440/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:09:14,506 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2440/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:09:14,746 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2318] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4202, 'learning_rate': 1.19672131147541e-05, 'epoch': 40.16}         \n",
      "{'loss': 0.3841, 'learning_rate': 1.1934426229508198e-05, 'epoch': 40.33}       \n",
      "{'loss': 0.4234, 'learning_rate': 1.1901639344262297e-05, 'epoch': 40.49}       \n",
      "{'loss': 0.4189, 'learning_rate': 1.1868852459016393e-05, 'epoch': 40.66}       \n",
      "{'loss': 0.3871, 'learning_rate': 1.1836065573770492e-05, 'epoch': 40.82}       \n",
      "{'loss': 0.4884, 'learning_rate': 1.1803278688524591e-05, 'epoch': 40.98}       \n",
      " 41%|███████████████▉                       | 2501/6100 [27:52<27:52,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:09:51,923 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:09:51,923 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:09:51,923 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7269538640975952, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.5149, 'eval_samples_per_second': 151.276, 'eval_steps_per_second': 2.436, 'epoch': 41.0}\n",
      " 41%|███████████████▉                       | 2501/6100 [27:57<27:52,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:09:56,439 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2501\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:09:56,439 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2501/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:09:56,548 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2501/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:09:56,549 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2501/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:09:56,723 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2379] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3932, 'learning_rate': 1.177049180327869e-05, 'epoch': 41.15}        \n",
      "{'loss': 0.4832, 'learning_rate': 1.173770491803279e-05, 'epoch': 41.31}        \n",
      "{'loss': 0.3903, 'learning_rate': 1.1704918032786887e-05, 'epoch': 41.48}       \n",
      "{'loss': 0.4649, 'learning_rate': 1.1672131147540984e-05, 'epoch': 41.64}       \n",
      "{'loss': 0.3936, 'learning_rate': 1.1639344262295083e-05, 'epoch': 41.8}        \n",
      "{'loss': 0.477, 'learning_rate': 1.1606557377049182e-05, 'epoch': 41.97}        \n",
      " 42%|████████████████▍                      | 2562/6100 [28:34<24:56,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:10:33,767 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:10:33,767 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:10:33,767 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.26it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.76it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.700856626033783, 'eval_accuracy': 0.7701317715959004, 'eval_runtime': 4.4984, 'eval_samples_per_second': 151.83, 'eval_steps_per_second': 2.445, 'epoch': 42.0}\n",
      " 42%|████████████████▍                      | 2562/6100 [28:38<24:56,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.61it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:10:38,266 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2562\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:10:38,266 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2562/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:10:38,380 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2562/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:10:38,380 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2562/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:10:38,556 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2440] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3969, 'learning_rate': 1.157377049180328e-05, 'epoch': 42.13}        \n",
      "{'loss': 0.376, 'learning_rate': 1.1540983606557378e-05, 'epoch': 42.3}         \n",
      "{'loss': 0.4279, 'learning_rate': 1.1508196721311476e-05, 'epoch': 42.46}       \n",
      "{'loss': 0.4562, 'learning_rate': 1.1475409836065575e-05, 'epoch': 42.62}       \n",
      "{'loss': 0.4368, 'learning_rate': 1.1442622950819672e-05, 'epoch': 42.79}       \n",
      "{'loss': 0.3857, 'learning_rate': 1.1409836065573771e-05, 'epoch': 42.95}       \n",
      " 43%|████████████████▊                      | 2623/6100 [29:15<24:35,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:11:15,162 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:11:15,162 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:11:15,162 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.80it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.26it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.21it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:02,  2.00it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.90it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7196948528289795, 'eval_accuracy': 0.7628111273792094, 'eval_runtime': 5.2889, 'eval_samples_per_second': 129.138, 'eval_steps_per_second': 2.08, 'epoch': 43.0}\n",
      " 43%|████████████████▊                      | 2623/6100 [29:21<24:35,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.94it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:11:20,451 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2623\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:11:20,452 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2623/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:11:20,614 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2623/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:11:20,614 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2623/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:11:20,862 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2501] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3855, 'learning_rate': 1.137704918032787e-05, 'epoch': 43.11}        \n",
      "{'loss': 0.4145, 'learning_rate': 1.134426229508197e-05, 'epoch': 43.28}        \n",
      "{'loss': 0.3787, 'learning_rate': 1.1311475409836066e-05, 'epoch': 43.44}       \n",
      "{'loss': 0.3958, 'learning_rate': 1.1278688524590164e-05, 'epoch': 43.61}       \n",
      "{'loss': 0.4494, 'learning_rate': 1.1245901639344263e-05, 'epoch': 43.77}       \n",
      "{'loss': 0.4552, 'learning_rate': 1.1213114754098362e-05, 'epoch': 43.93}       \n",
      " 44%|█████████████████▏                     | 2684/6100 [29:58<25:06,  2.27it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:11:58,314 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:11:58,314 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:11:58,314 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7134038805961609, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 6.1848, 'eval_samples_per_second': 110.432, 'eval_steps_per_second': 1.779, 'epoch': 44.0}\n",
      " 44%|█████████████████▏                     | 2684/6100 [30:05<25:06,  2.27it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:12:04,499 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2684\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:12:04,500 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2684/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:12:04,662 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2684/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:12:04,662 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2684/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:12:04,903 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2562] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4359, 'learning_rate': 1.1180327868852461e-05, 'epoch': 44.1}        \n",
      "{'loss': 0.4117, 'learning_rate': 1.1147540983606557e-05, 'epoch': 44.26}       \n",
      "{'loss': 0.4011, 'learning_rate': 1.1114754098360656e-05, 'epoch': 44.43}       \n",
      "{'loss': 0.3833, 'learning_rate': 1.1081967213114755e-05, 'epoch': 44.59}       \n",
      "{'loss': 0.4147, 'learning_rate': 1.1049180327868854e-05, 'epoch': 44.75}       \n",
      "{'loss': 0.3452, 'learning_rate': 1.1016393442622953e-05, 'epoch': 44.92}       \n",
      " 45%|█████████████████▌                     | 2745/6100 [30:42<28:35,  1.96it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:12:42,380 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:12:42,381 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:12:42,381 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.56it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7632548213005066, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 6.1693, 'eval_samples_per_second': 110.71, 'eval_steps_per_second': 1.783, 'epoch': 45.0}\n",
      " 45%|█████████████████▌                     | 2745/6100 [30:49<28:35,  1.96it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:12:48,550 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2745\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:12:48,551 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2745/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:12:48,709 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2745/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:12:48,710 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2745/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:12:48,950 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2623] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4178, 'learning_rate': 1.0983606557377052e-05, 'epoch': 45.08}       \n",
      "{'loss': 0.3865, 'learning_rate': 1.0950819672131147e-05, 'epoch': 45.25}       \n",
      "{'loss': 0.346, 'learning_rate': 1.0918032786885246e-05, 'epoch': 45.41}        \n",
      "{'loss': 0.4455, 'learning_rate': 1.0885245901639345e-05, 'epoch': 45.57}       \n",
      "{'loss': 0.3901, 'learning_rate': 1.0852459016393445e-05, 'epoch': 45.74}       \n",
      "{'loss': 0.4368, 'learning_rate': 1.0819672131147544e-05, 'epoch': 45.9}        \n",
      " 46%|█████████████████▉                     | 2806/6100 [31:26<25:39,  2.14it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:13:26,076 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:13:26,076 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:13:26,076 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.74it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7380980849266052, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.4859, 'eval_samples_per_second': 152.255, 'eval_steps_per_second': 2.452, 'epoch': 46.0}\n",
      " 46%|█████████████████▉                     | 2806/6100 [31:31<25:39,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:13:30,562 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2806\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:13:30,562 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2806/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:13:30,664 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2806/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:13:30,665 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2806/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:13:30,835 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2684] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4065, 'learning_rate': 1.078688524590164e-05, 'epoch': 46.07}        \n",
      "{'loss': 0.4063, 'learning_rate': 1.0754098360655738e-05, 'epoch': 46.23}       \n",
      "{'loss': 0.4158, 'learning_rate': 1.0721311475409837e-05, 'epoch': 46.39}       \n",
      "{'loss': 0.3565, 'learning_rate': 1.0688524590163936e-05, 'epoch': 46.56}       \n",
      "{'loss': 0.415, 'learning_rate': 1.0655737704918034e-05, 'epoch': 46.72}        \n",
      "{'loss': 0.4083, 'learning_rate': 1.0622950819672131e-05, 'epoch': 46.89}       \n",
      " 47%|██████████████████▎                    | 2867/6100 [32:08<22:42,  2.37it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:14:07,953 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:14:07,953 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:14:07,953 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.78it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.93it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7206775546073914, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.5284, 'eval_samples_per_second': 150.826, 'eval_steps_per_second': 2.429, 'epoch': 47.0}\n",
      " 47%|██████████████████▎                    | 2867/6100 [32:13<22:42,  2.37it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.24it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:14:12,482 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2867\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:14:12,483 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2867/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:14:12,594 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2867/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:14:12,595 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2867/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:14:12,770 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2745] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3876, 'learning_rate': 1.059016393442623e-05, 'epoch': 47.05}        \n",
      "{'loss': 0.3643, 'learning_rate': 1.0557377049180329e-05, 'epoch': 47.21}       \n",
      "{'loss': 0.3669, 'learning_rate': 1.0524590163934426e-05, 'epoch': 47.38}       \n",
      "{'loss': 0.4021, 'learning_rate': 1.0491803278688525e-05, 'epoch': 47.54}       \n",
      "{'loss': 0.4647, 'learning_rate': 1.0459016393442624e-05, 'epoch': 47.7}        \n",
      "{'loss': 0.3771, 'learning_rate': 1.0426229508196722e-05, 'epoch': 47.87}       \n",
      " 48%|██████████████████▋                    | 2928/6100 [32:49<22:27,  2.35it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:14:49,082 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:14:49,083 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:14:49,083 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.48it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.15it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.00it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.91it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.85it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.95it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7381148338317871, 'eval_accuracy': 0.7789165446559297, 'eval_runtime': 5.4819, 'eval_samples_per_second': 124.591, 'eval_steps_per_second': 2.007, 'epoch': 48.0}\n",
      " 48%|██████████████████▋                    | 2928/6100 [32:55<22:27,  2.35it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.59it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:14:54,569 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2928\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:14:54,570 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2928/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:14:54,722 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2928/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:14:54,723 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2928/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:14:54,964 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2806] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3541, 'learning_rate': 1.0393442622950821e-05, 'epoch': 48.03}       \n",
      "{'loss': 0.3544, 'learning_rate': 1.0360655737704918e-05, 'epoch': 48.2}        \n",
      "{'loss': 0.3627, 'learning_rate': 1.0327868852459017e-05, 'epoch': 48.36}       \n",
      "{'loss': 0.3428, 'learning_rate': 1.0295081967213116e-05, 'epoch': 48.52}       \n",
      "{'loss': 0.4484, 'learning_rate': 1.0262295081967214e-05, 'epoch': 48.69}       \n",
      "{'loss': 0.383, 'learning_rate': 1.0229508196721311e-05, 'epoch': 48.85}        \n",
      " 49%|███████████████████                    | 2989/6100 [33:32<26:11,  1.98it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:15:32,382 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:15:32,382 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:15:32,382 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.51it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.53it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7242259979248047, 'eval_accuracy': 0.7701317715959004, 'eval_runtime': 6.1131, 'eval_samples_per_second': 111.727, 'eval_steps_per_second': 1.799, 'epoch': 49.0}\n",
      " 49%|███████████████████                    | 2989/6100 [33:39<26:11,  1.98it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:15:38,496 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2989\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:15:38,497 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2989/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:15:38,654 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2989/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:15:38,655 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2989/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:15:38,899 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2867] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3879, 'learning_rate': 1.019672131147541e-05, 'epoch': 49.02}        \n",
      "{'loss': 0.3809, 'learning_rate': 1.0163934426229509e-05, 'epoch': 49.18}       \n",
      "{'loss': 0.3855, 'learning_rate': 1.0131147540983608e-05, 'epoch': 49.34}       \n",
      "{'loss': 0.4058, 'learning_rate': 1.0098360655737707e-05, 'epoch': 49.51}       \n",
      "{'loss': 0.3916, 'learning_rate': 1.0065573770491803e-05, 'epoch': 49.67}       \n",
      "{'loss': 0.3761, 'learning_rate': 1.0032786885245902e-05, 'epoch': 49.84}       \n",
      "{'loss': 0.3542, 'learning_rate': 1e-05, 'epoch': 50.0}                         \n",
      " 50%|███████████████████▌                   | 3050/6100 [34:16<21:59,  2.31it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:16:15,596 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:16:15,596 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:16:15,596 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.58it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.84it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7462592720985413, 'eval_accuracy': 0.7642752562225475, 'eval_runtime': 4.5119, 'eval_samples_per_second': 151.378, 'eval_steps_per_second': 2.438, 'epoch': 50.0}\n",
      " 50%|███████████████████▌                   | 3050/6100 [34:20<21:59,  2.31it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:16:20,111 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3050\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:16:20,112 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3050/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:16:20,221 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3050/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:16:20,221 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3050/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:16:20,396 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2928] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3639, 'learning_rate': 9.9672131147541e-06, 'epoch': 50.16}          \n",
      "{'loss': 0.377, 'learning_rate': 9.934426229508197e-06, 'epoch': 50.33}         \n",
      "{'loss': 0.4205, 'learning_rate': 9.901639344262296e-06, 'epoch': 50.49}        \n",
      "{'loss': 0.3536, 'learning_rate': 9.868852459016395e-06, 'epoch': 50.66}        \n",
      "{'loss': 0.3839, 'learning_rate': 9.836065573770493e-06, 'epoch': 50.82}        \n",
      "{'loss': 0.3302, 'learning_rate': 9.803278688524592e-06, 'epoch': 50.98}        \n",
      " 51%|███████████████████▉                   | 3111/6100 [34:58<21:07,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:16:57,570 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:16:57,570 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:16:57,570 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.56it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.30it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7430614829063416, 'eval_accuracy': 0.7774524158125915, 'eval_runtime': 4.5862, 'eval_samples_per_second': 148.924, 'eval_steps_per_second': 2.398, 'epoch': 51.0}\n",
      " 51%|███████████████████▉                   | 3111/6100 [35:02<21:07,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:17:02,157 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3111\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:17:02,158 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3111/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:17:02,267 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3111/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:17:02,267 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3111/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2887] 2023-10-05 10:17:02,442 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-2989] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3299, 'learning_rate': 9.770491803278689e-06, 'epoch': 51.15}        \n",
      "{'loss': 0.371, 'learning_rate': 9.737704918032788e-06, 'epoch': 51.31}         \n",
      "{'loss': 0.3533, 'learning_rate': 9.704918032786887e-06, 'epoch': 51.48}        \n",
      "{'loss': 0.354, 'learning_rate': 9.672131147540984e-06, 'epoch': 51.64}         \n",
      "{'loss': 0.3691, 'learning_rate': 9.639344262295083e-06, 'epoch': 51.8}         \n",
      "{'loss': 0.3686, 'learning_rate': 9.60655737704918e-06, 'epoch': 51.97}         \n",
      " 52%|████████████████████▎                  | 3172/6100 [35:40<20:30,  2.38it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:17:39,452 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:17:39,452 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:17:39,452 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.23it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.37it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.30it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7641761302947998, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.6427, 'eval_samples_per_second': 147.113, 'eval_steps_per_second': 2.369, 'epoch': 52.0}\n",
      " 52%|████████████████████▎                  | 3172/6100 [35:44<20:30,  2.38it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:17:44,098 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3172\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:17:44,100 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3172/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:17:44,263 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3172/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:17:44,263 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3172/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:17:44,511 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3050] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3812, 'learning_rate': 9.57377049180328e-06, 'epoch': 52.13}         \n",
      "{'loss': 0.3641, 'learning_rate': 9.540983606557377e-06, 'epoch': 52.3}         \n",
      "{'loss': 0.3373, 'learning_rate': 9.508196721311476e-06, 'epoch': 52.46}        \n",
      "{'loss': 0.3627, 'learning_rate': 9.475409836065575e-06, 'epoch': 52.62}        \n",
      "{'loss': 0.3725, 'learning_rate': 9.442622950819673e-06, 'epoch': 52.79}        \n",
      "{'loss': 0.3602, 'learning_rate': 9.409836065573772e-06, 'epoch': 52.95}        \n",
      " 53%|████████████████████▋                  | 3233/6100 [36:22<24:14,  1.97it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:18:22,273 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:18:22,273 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:18:22,273 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.63it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.46it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.86it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.84it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.92it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7473905682563782, 'eval_accuracy': 0.7701317715959004, 'eval_runtime': 6.0647, 'eval_samples_per_second': 112.618, 'eval_steps_per_second': 1.814, 'epoch': 53.0}\n",
      " 53%|████████████████████▋                  | 3233/6100 [36:28<24:14,  1.97it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:18:28,338 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3233\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:18:28,340 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3233/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:18:28,495 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3233/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:18:28,495 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3233/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:18:28,744 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3111] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3452, 'learning_rate': 9.377049180327869e-06, 'epoch': 53.11}        \n",
      "{'loss': 0.3529, 'learning_rate': 9.344262295081968e-06, 'epoch': 53.28}        \n",
      "{'loss': 0.3735, 'learning_rate': 9.311475409836065e-06, 'epoch': 53.44}        \n",
      "{'loss': 0.3447, 'learning_rate': 9.278688524590164e-06, 'epoch': 53.61}        \n",
      "{'loss': 0.3663, 'learning_rate': 9.245901639344263e-06, 'epoch': 53.77}        \n",
      "{'loss': 0.364, 'learning_rate': 9.21311475409836e-06, 'epoch': 53.93}          \n",
      " 54%|█████████████████████                  | 3294/6100 [37:07<24:08,  1.94it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:19:06,447 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:19:06,447 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:19:06,447 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.95it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:01,  2.03it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.10it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7629182934761047, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 5.5752, 'eval_samples_per_second': 122.507, 'eval_steps_per_second': 1.973, 'epoch': 54.0}\n",
      " 54%|█████████████████████                  | 3294/6100 [37:12<24:08,  1.94it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:19:12,023 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3294\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:19:12,023 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3294/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:19:12,132 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3294/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:19:12,133 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3294/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:19:12,306 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3172] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3305, 'learning_rate': 9.18032786885246e-06, 'epoch': 54.1}          \n",
      "{'loss': 0.3742, 'learning_rate': 9.147540983606557e-06, 'epoch': 54.26}        \n",
      "{'loss': 0.3577, 'learning_rate': 9.114754098360656e-06, 'epoch': 54.43}        \n",
      "{'loss': 0.3431, 'learning_rate': 9.081967213114755e-06, 'epoch': 54.59}        \n",
      "{'loss': 0.3397, 'learning_rate': 9.049180327868853e-06, 'epoch': 54.75}        \n",
      "{'loss': 0.3637, 'learning_rate': 9.016393442622952e-06, 'epoch': 54.92}        \n",
      " 55%|█████████████████████▍                 | 3355/6100 [37:49<19:25,  2.35it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:19:48,651 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:19:48,651 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:19:48,651 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.03it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7816734313964844, 'eval_accuracy': 0.7613469985358712, 'eval_runtime': 4.5335, 'eval_samples_per_second': 150.655, 'eval_steps_per_second': 2.426, 'epoch': 55.0}\n",
      " 55%|█████████████████████▍                 | 3355/6100 [37:53<19:25,  2.35it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.29it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:19:53,185 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3355\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:19:53,185 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3355/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:19:53,295 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3355/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:19:53,296 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3355/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:19:53,470 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3233] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3691, 'learning_rate': 8.98360655737705e-06, 'epoch': 55.08}         \n",
      "{'loss': 0.3846, 'learning_rate': 8.950819672131148e-06, 'epoch': 55.25}        \n",
      "{'loss': 0.3268, 'learning_rate': 8.918032786885247e-06, 'epoch': 55.41}        \n",
      "{'loss': 0.3657, 'learning_rate': 8.885245901639346e-06, 'epoch': 55.57}        \n",
      "{'loss': 0.3723, 'learning_rate': 8.852459016393443e-06, 'epoch': 55.74}        \n",
      "{'loss': 0.306, 'learning_rate': 8.819672131147542e-06, 'epoch': 55.9}          \n",
      " 56%|█████████████████████▊                 | 3416/6100 [38:31<18:56,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:20:30,461 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:20:30,461 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:20:30,461 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7694714665412903, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.6206, 'eval_samples_per_second': 147.816, 'eval_steps_per_second': 2.381, 'epoch': 56.0}\n",
      " 56%|█████████████████████▊                 | 3416/6100 [38:35<18:56,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:20:35,083 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3416\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:20:35,084 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3416/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:20:35,242 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3416/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:20:35,242 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3416/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:20:35,483 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3294] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3362, 'learning_rate': 8.78688524590164e-06, 'epoch': 56.07}         \n",
      "{'loss': 0.3573, 'learning_rate': 8.754098360655739e-06, 'epoch': 56.23}        \n",
      "{'loss': 0.33, 'learning_rate': 8.721311475409838e-06, 'epoch': 56.39}          \n",
      "{'loss': 0.3098, 'learning_rate': 8.688524590163935e-06, 'epoch': 56.56}        \n",
      "{'loss': 0.3959, 'learning_rate': 8.655737704918034e-06, 'epoch': 56.72}        \n",
      "{'loss': 0.3696, 'learning_rate': 8.622950819672132e-06, 'epoch': 56.89}        \n",
      " 57%|██████████████████████▏                | 3477/6100 [39:13<20:35,  2.12it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:21:13,054 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:21:13,054 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:21:13,054 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.82it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.77it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.72it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.70it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7847955822944641, 'eval_accuracy': 0.7584187408491947, 'eval_runtime': 6.2781, 'eval_samples_per_second': 108.792, 'eval_steps_per_second': 1.752, 'epoch': 57.0}\n",
      " 57%|██████████████████████▏                | 3477/6100 [39:19<20:35,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:21:19,333 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3477\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:21:19,335 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3477/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:21:19,502 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3477/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:21:19,502 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3477/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:21:19,748 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3355] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3422, 'learning_rate': 8.59016393442623e-06, 'epoch': 57.05}         \n",
      "{'loss': 0.3193, 'learning_rate': 8.55737704918033e-06, 'epoch': 57.21}         \n",
      "{'loss': 0.3603, 'learning_rate': 8.524590163934427e-06, 'epoch': 57.38}        \n",
      "{'loss': 0.3864, 'learning_rate': 8.491803278688526e-06, 'epoch': 57.54}        \n",
      "{'loss': 0.3116, 'learning_rate': 8.459016393442623e-06, 'epoch': 57.7}         \n",
      "{'loss': 0.3371, 'learning_rate': 8.426229508196722e-06, 'epoch': 57.87}        \n",
      " 58%|██████████████████████▌                | 3538/6100 [39:57<21:42,  1.97it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:21:57,360 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:21:57,361 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:21:57,361 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.49it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.94it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7984086275100708, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 6.0975, 'eval_samples_per_second': 112.013, 'eval_steps_per_second': 1.804, 'epoch': 58.0}\n",
      " 58%|██████████████████████▌                | 3538/6100 [40:04<21:42,  1.97it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.58it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:22:03,459 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3538\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:22:03,460 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3538/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:22:03,623 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3538/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:22:03,623 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3538/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:22:03,874 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3416] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3436, 'learning_rate': 8.39344262295082e-06, 'epoch': 58.03}         \n",
      "{'loss': 0.3614, 'learning_rate': 8.360655737704919e-06, 'epoch': 58.2}         \n",
      "{'loss': 0.3179, 'learning_rate': 8.327868852459016e-06, 'epoch': 58.36}        \n",
      "{'loss': 0.3367, 'learning_rate': 8.295081967213115e-06, 'epoch': 58.52}        \n",
      "{'loss': 0.3089, 'learning_rate': 8.262295081967214e-06, 'epoch': 58.69}        \n",
      "{'loss': 0.3019, 'learning_rate': 8.229508196721311e-06, 'epoch': 58.85}        \n",
      " 59%|███████████████████████                | 3599/6100 [40:41<19:40,  2.12it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:22:41,358 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:22:41,358 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:22:41,358 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.79it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.74it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.65it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.60it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.793090283870697, 'eval_accuracy': 0.7554904831625183, 'eval_runtime': 4.4221, 'eval_samples_per_second': 154.452, 'eval_steps_per_second': 2.488, 'epoch': 59.0}\n",
      " 59%|███████████████████████                | 3599/6100 [40:46<19:40,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.62it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:22:45,780 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3599\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:22:45,781 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3599/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:22:45,886 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3599/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:22:45,887 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3599/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:22:46,064 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3477] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3664, 'learning_rate': 8.19672131147541e-06, 'epoch': 59.02}         \n",
      "{'loss': 0.331, 'learning_rate': 8.163934426229508e-06, 'epoch': 59.18}         \n",
      "{'loss': 0.3305, 'learning_rate': 8.131147540983607e-06, 'epoch': 59.34}        \n",
      "{'loss': 0.2957, 'learning_rate': 8.098360655737706e-06, 'epoch': 59.51}        \n",
      "{'loss': 0.3365, 'learning_rate': 8.065573770491803e-06, 'epoch': 59.67}        \n",
      "{'loss': 0.3711, 'learning_rate': 8.032786885245902e-06, 'epoch': 59.84}        \n",
      "{'loss': 0.3192, 'learning_rate': 8.000000000000001e-06, 'epoch': 60.0}         \n",
      " 60%|███████████████████████▍               | 3660/6100 [41:24<17:21,  2.34it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:23:24,207 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:23:24,207 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:23:24,207 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.02it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.76it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.60it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8255400061607361, 'eval_accuracy': 0.7642752562225475, 'eval_runtime': 4.4482, 'eval_samples_per_second': 153.547, 'eval_steps_per_second': 2.473, 'epoch': 60.0}\n",
      " 60%|███████████████████████▍               | 3660/6100 [41:29<17:21,  2.34it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.30it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:23:28,655 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3660\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:23:28,656 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3660/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:23:28,768 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3660/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:23:28,769 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3660/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:23:28,946 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3538] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3384, 'learning_rate': 7.967213114754099e-06, 'epoch': 60.16}        \n",
      "{'loss': 0.3059, 'learning_rate': 7.934426229508198e-06, 'epoch': 60.33}        \n",
      "{'loss': 0.3568, 'learning_rate': 7.901639344262295e-06, 'epoch': 60.49}        \n",
      "{'loss': 0.3988, 'learning_rate': 7.868852459016394e-06, 'epoch': 60.66}        \n",
      "{'loss': 0.3309, 'learning_rate': 7.836065573770493e-06, 'epoch': 60.82}        \n",
      "{'loss': 0.3342, 'learning_rate': 7.80327868852459e-06, 'epoch': 60.98}         \n",
      " 61%|███████████████████████▊               | 3721/6100 [42:07<16:36,  2.39it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:24:06,463 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:24:06,463 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:24:06,463 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.77it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7935721278190613, 'eval_accuracy': 0.7598828696925329, 'eval_runtime': 4.5106, 'eval_samples_per_second': 151.422, 'eval_steps_per_second': 2.439, 'epoch': 61.0}\n",
      " 61%|███████████████████████▊               | 3721/6100 [42:11<16:36,  2.39it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:24:10,974 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3721\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:24:10,975 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3721/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:24:11,087 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3721/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:24:11,088 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3721/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:24:11,266 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3599] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.284, 'learning_rate': 7.77049180327869e-06, 'epoch': 61.15}          \n",
      "{'loss': 0.3197, 'learning_rate': 7.737704918032789e-06, 'epoch': 61.31}        \n",
      "{'loss': 0.3011, 'learning_rate': 7.704918032786886e-06, 'epoch': 61.48}        \n",
      "{'loss': 0.357, 'learning_rate': 7.672131147540985e-06, 'epoch': 61.64}         \n",
      "{'loss': 0.3136, 'learning_rate': 7.639344262295082e-06, 'epoch': 61.8}         \n",
      "{'loss': 0.3729, 'learning_rate': 7.6065573770491804e-06, 'epoch': 61.97}       \n",
      " 62%|████████████████████████▏              | 3782/6100 [42:49<16:23,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:24:48,715 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:24:48,715 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:24:48,715 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.68it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.78it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7937721014022827, 'eval_accuracy': 0.7598828696925329, 'eval_runtime': 4.5715, 'eval_samples_per_second': 149.403, 'eval_steps_per_second': 2.406, 'epoch': 62.0}\n",
      " 62%|████████████████████████▏              | 3782/6100 [42:53<16:23,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.22it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:24:53,287 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3782\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:24:53,288 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3782/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:24:53,401 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3782/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:24:53,401 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3782/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:24:53,580 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3660] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.361, 'learning_rate': 7.5737704918032795e-06, 'epoch': 62.13}        \n",
      "{'loss': 0.3352, 'learning_rate': 7.540983606557377e-06, 'epoch': 62.3}         \n",
      "{'loss': 0.3048, 'learning_rate': 7.508196721311476e-06, 'epoch': 62.46}        \n",
      "{'loss': 0.3587, 'learning_rate': 7.475409836065575e-06, 'epoch': 62.62}        \n",
      "{'loss': 0.3662, 'learning_rate': 7.442622950819672e-06, 'epoch': 62.79}        \n",
      "{'loss': 0.3121, 'learning_rate': 7.409836065573771e-06, 'epoch': 62.95}        \n",
      " 63%|████████████████████████▌              | 3843/6100 [43:32<16:10,  2.33it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:25:31,687 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:25:31,687 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:25:31,687 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.56it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.20it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.89it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7761580944061279, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 5.5539, 'eval_samples_per_second': 122.978, 'eval_steps_per_second': 1.981, 'epoch': 63.0}\n",
      " 63%|████████████████████████▌              | 3843/6100 [43:37<16:10,  2.33it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:25:37,241 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3843\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:25:37,242 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3843/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:25:37,404 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3843/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:25:37,405 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3843/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:25:37,653 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3721] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3454, 'learning_rate': 7.3770491803278695e-06, 'epoch': 63.11}       \n",
      "{'loss': 0.3112, 'learning_rate': 7.344262295081968e-06, 'epoch': 63.28}        \n",
      "{'loss': 0.3322, 'learning_rate': 7.311475409836067e-06, 'epoch': 63.44}        \n",
      "{'loss': 0.3165, 'learning_rate': 7.278688524590165e-06, 'epoch': 63.61}        \n",
      "{'loss': 0.3302, 'learning_rate': 7.245901639344263e-06, 'epoch': 63.77}        \n",
      "{'loss': 0.3207, 'learning_rate': 7.213114754098361e-06, 'epoch': 63.93}        \n",
      " 64%|████████████████████████▉              | 3904/6100 [44:15<18:26,  1.98it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:26:15,328 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:26:15,328 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:26:15,328 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.51it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.47it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.17it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7790361046791077, 'eval_accuracy': 0.7584187408491947, 'eval_runtime': 6.1369, 'eval_samples_per_second': 111.293, 'eval_steps_per_second': 1.792, 'epoch': 64.0}\n",
      " 64%|████████████████████████▉              | 3904/6100 [44:22<18:26,  1.98it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:26:21,466 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3904\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:26:21,467 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3904/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:26:21,617 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3904/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:26:21,618 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3904/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:26:21,870 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3782] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3335, 'learning_rate': 7.1803278688524594e-06, 'epoch': 64.1}        \n",
      "{'loss': 0.3329, 'learning_rate': 7.147540983606558e-06, 'epoch': 64.26}        \n",
      "{'loss': 0.3336, 'learning_rate': 7.114754098360657e-06, 'epoch': 64.43}        \n",
      "{'loss': 0.3073, 'learning_rate': 7.081967213114754e-06, 'epoch': 64.59}        \n",
      "{'loss': 0.3013, 'learning_rate': 7.049180327868853e-06, 'epoch': 64.75}        \n",
      "{'loss': 0.288, 'learning_rate': 7.016393442622952e-06, 'epoch': 64.92}         \n",
      " 65%|█████████████████████████▎             | 3965/6100 [44:59<18:03,  1.97it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:26:59,333 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:26:59,333 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:26:59,333 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.70it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7981154322624207, 'eval_accuracy': 0.7745241581259151, 'eval_runtime': 6.1691, 'eval_samples_per_second': 110.713, 'eval_steps_per_second': 1.783, 'epoch': 65.0}\n",
      " 65%|█████████████████████████▎             | 3965/6100 [45:06<18:03,  1.97it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:27:05,504 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3965\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:27:05,504 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3965/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:27:05,660 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3965/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:27:05,661 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3965/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:27:05,907 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3843] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3284, 'learning_rate': 6.983606557377049e-06, 'epoch': 65.08}        \n",
      "{'loss': 0.2765, 'learning_rate': 6.9508196721311484e-06, 'epoch': 65.25}       \n",
      "{'loss': 0.3376, 'learning_rate': 6.918032786885246e-06, 'epoch': 65.41}        \n",
      "{'loss': 0.2928, 'learning_rate': 6.885245901639345e-06, 'epoch': 65.57}        \n",
      "{'loss': 0.324, 'learning_rate': 6.852459016393444e-06, 'epoch': 65.74}         \n",
      "{'loss': 0.2714, 'learning_rate': 6.819672131147541e-06, 'epoch': 65.9}         \n",
      " 66%|█████████████████████████▋             | 4026/6100 [45:44<16:34,  2.09it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:27:43,448 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:27:43,448 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:27:43,448 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.78it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.26it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.59it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8279288411140442, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.5754, 'eval_samples_per_second': 149.278, 'eval_steps_per_second': 2.404, 'epoch': 66.0}\n",
      " 66%|█████████████████████████▋             | 4026/6100 [45:48<16:34,  2.09it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:27:48,024 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4026\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:27:48,025 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4026/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:27:48,137 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4026/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:27:48,138 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4026/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:27:48,311 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3904] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3022, 'learning_rate': 6.78688524590164e-06, 'epoch': 66.07}         \n",
      "{'loss': 0.3077, 'learning_rate': 6.7540983606557384e-06, 'epoch': 66.23}       \n",
      "{'loss': 0.2876, 'learning_rate': 6.721311475409837e-06, 'epoch': 66.39}        \n",
      "{'loss': 0.3158, 'learning_rate': 6.688524590163935e-06, 'epoch': 66.56}        \n",
      "{'loss': 0.2928, 'learning_rate': 6.655737704918034e-06, 'epoch': 66.72}        \n",
      "{'loss': 0.2998, 'learning_rate': 6.622950819672131e-06, 'epoch': 66.89}        \n",
      " 67%|██████████████████████████▏            | 4087/6100 [46:26<14:20,  2.34it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:28:25,651 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:28:25,651 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:28:25,651 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.59it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.49it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8080200552940369, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.548, 'eval_samples_per_second': 150.176, 'eval_steps_per_second': 2.419, 'epoch': 67.0}\n",
      " 67%|██████████████████████████▏            | 4087/6100 [46:30<14:20,  2.34it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:28:30,203 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4087\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:28:30,203 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4087/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:28:30,313 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4087/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:28:30,314 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4087/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:28:30,489 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-3965] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2864, 'learning_rate': 6.59016393442623e-06, 'epoch': 67.05}         \n",
      "{'loss': 0.3078, 'learning_rate': 6.5573770491803276e-06, 'epoch': 67.21}       \n",
      "{'loss': 0.3282, 'learning_rate': 6.524590163934427e-06, 'epoch': 67.38}        \n",
      "{'loss': 0.3147, 'learning_rate': 6.491803278688526e-06, 'epoch': 67.54}        \n",
      "{'loss': 0.3017, 'learning_rate': 6.459016393442623e-06, 'epoch': 67.7}         \n",
      "{'loss': 0.2979, 'learning_rate': 6.426229508196722e-06, 'epoch': 67.87}        \n",
      " 68%|██████████████████████████▌            | 4148/6100 [47:08<13:43,  2.37it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:29:07,450 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:29:07,450 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:29:07,450 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.76it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.58it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.50it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8260013461112976, 'eval_accuracy': 0.7628111273792094, 'eval_runtime': 4.5539, 'eval_samples_per_second': 149.981, 'eval_steps_per_second': 2.416, 'epoch': 68.0}\n",
      " 68%|██████████████████████████▌            | 4148/6100 [47:12<13:43,  2.37it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:29:12,004 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4148\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:29:12,005 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4148/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:29:12,111 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4148/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:29:12,112 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4148/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:29:12,294 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4026] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2862, 'learning_rate': 6.393442622950821e-06, 'epoch': 68.03}        \n",
      "{'loss': 0.3524, 'learning_rate': 6.360655737704918e-06, 'epoch': 68.2}         \n",
      "{'loss': 0.2906, 'learning_rate': 6.327868852459017e-06, 'epoch': 68.36}        \n",
      "{'loss': 0.3265, 'learning_rate': 6.295081967213116e-06, 'epoch': 68.52}        \n",
      "{'loss': 0.2873, 'learning_rate': 6.262295081967214e-06, 'epoch': 68.69}        \n",
      "{'loss': 0.3285, 'learning_rate': 6.229508196721312e-06, 'epoch': 68.85}        \n",
      " 69%|██████████████████████████▉            | 4209/6100 [47:50<15:10,  2.08it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:29:49,809 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:29:49,810 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:29:49,810 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.52it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.843646764755249, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 6.135, 'eval_samples_per_second': 111.329, 'eval_steps_per_second': 1.793, 'epoch': 69.0}\n",
      " 69%|██████████████████████████▉            | 4209/6100 [47:56<15:10,  2.08it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:29:55,945 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4209\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:29:55,946 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4209/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:29:56,109 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4209/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:29:56,110 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4209/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:29:56,356 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4087] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3347, 'learning_rate': 6.19672131147541e-06, 'epoch': 69.02}         \n",
      "{'loss': 0.2911, 'learning_rate': 6.163934426229508e-06, 'epoch': 69.18}        \n",
      "{'loss': 0.275, 'learning_rate': 6.131147540983607e-06, 'epoch': 69.34}         \n",
      "{'loss': 0.2381, 'learning_rate': 6.098360655737705e-06, 'epoch': 69.51}        \n",
      "{'loss': 0.2949, 'learning_rate': 6.065573770491804e-06, 'epoch': 69.67}        \n",
      "{'loss': 0.2977, 'learning_rate': 6.032786885245903e-06, 'epoch': 69.84}        \n",
      "{'loss': 0.3108, 'learning_rate': 6e-06, 'epoch': 70.0}                         \n",
      " 70%|███████████████████████████▎           | 4270/6100 [48:34<15:47,  1.93it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:30:34,103 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:30:34,103 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:30:34,103 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.44it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.48it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.847963273525238, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 6.1863, 'eval_samples_per_second': 110.405, 'eval_steps_per_second': 1.778, 'epoch': 70.0}\n",
      " 70%|███████████████████████████▎           | 4270/6100 [48:40<15:47,  1.93it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:30:40,289 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4270\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:30:40,290 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4270/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:30:40,452 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4270/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:30:40,453 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4270/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:30:40,696 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4148] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2411, 'learning_rate': 5.967213114754099e-06, 'epoch': 70.16}        \n",
      "{'loss': 0.3148, 'learning_rate': 5.9344262295081965e-06, 'epoch': 70.33}       \n",
      "{'loss': 0.3086, 'learning_rate': 5.9016393442622956e-06, 'epoch': 70.49}       \n",
      "{'loss': 0.3248, 'learning_rate': 5.868852459016395e-06, 'epoch': 70.66}        \n",
      "{'loss': 0.2746, 'learning_rate': 5.836065573770492e-06, 'epoch': 70.82}        \n",
      "{'loss': 0.3227, 'learning_rate': 5.803278688524591e-06, 'epoch': 70.98}        \n",
      " 71%|███████████████████████████▋           | 4331/6100 [49:18<15:03,  1.96it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:31:18,256 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:31:18,256 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:31:18,256 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.52it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.06it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.839853048324585, 'eval_accuracy': 0.7437774524158126, 'eval_runtime': 5.9992, 'eval_samples_per_second': 113.849, 'eval_steps_per_second': 1.834, 'epoch': 71.0}\n",
      " 71%|███████████████████████████▋           | 4331/6100 [49:24<15:03,  1.96it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.71it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:31:24,256 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4331\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:31:24,257 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4331/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:31:24,373 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4331/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:31:24,374 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4331/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:31:24,549 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4209] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3308, 'learning_rate': 5.770491803278689e-06, 'epoch': 71.15}        \n",
      "{'loss': 0.2723, 'learning_rate': 5.737704918032787e-06, 'epoch': 71.31}        \n",
      "{'loss': 0.3327, 'learning_rate': 5.7049180327868855e-06, 'epoch': 71.48}       \n",
      "{'loss': 0.2748, 'learning_rate': 5.672131147540985e-06, 'epoch': 71.64}        \n",
      "{'loss': 0.3088, 'learning_rate': 5.639344262295082e-06, 'epoch': 71.8}         \n",
      "{'loss': 0.2748, 'learning_rate': 5.606557377049181e-06, 'epoch': 71.97}        \n",
      " 72%|████████████████████████████           | 4392/6100 [50:01<12:18,  2.31it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:32:01,389 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:32:01,389 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:32:01,389 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.14it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.64it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8431097865104675, 'eval_accuracy': 0.7584187408491947, 'eval_runtime': 4.4604, 'eval_samples_per_second': 153.124, 'eval_steps_per_second': 2.466, 'epoch': 72.0}\n",
      " 72%|████████████████████████████           | 4392/6100 [50:06<12:18,  2.31it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.30it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:32:05,850 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4392\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:32:05,850 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4392/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:32:05,963 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4392/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:32:05,963 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4392/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:32:06,140 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4270] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3054, 'learning_rate': 5.573770491803278e-06, 'epoch': 72.13}        \n",
      "{'loss': 0.2787, 'learning_rate': 5.540983606557377e-06, 'epoch': 72.3}         \n",
      "{'loss': 0.3163, 'learning_rate': 5.508196721311476e-06, 'epoch': 72.46}        \n",
      "{'loss': 0.2819, 'learning_rate': 5.475409836065574e-06, 'epoch': 72.62}        \n",
      "{'loss': 0.2988, 'learning_rate': 5.442622950819673e-06, 'epoch': 72.79}        \n",
      "{'loss': 0.2464, 'learning_rate': 5.409836065573772e-06, 'epoch': 72.95}        \n",
      " 73%|████████████████████████████▍          | 4453/6100 [50:46<13:59,  1.96it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:32:46,012 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:32:46,012 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:32:46,012 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:02,  2.76it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.49it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.42it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.37it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8272844552993774, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 5.0094, 'eval_samples_per_second': 136.342, 'eval_steps_per_second': 2.196, 'epoch': 73.0}\n",
      " 73%|████████████████████████████▍          | 4453/6100 [50:51<13:59,  1.96it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:32:51,022 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4453\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:32:51,022 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4453/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:32:51,132 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4453/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:32:51,133 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4453/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:32:51,305 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4331] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3159, 'learning_rate': 5.377049180327869e-06, 'epoch': 73.11}        \n",
      "{'loss': 0.3044, 'learning_rate': 5.344262295081968e-06, 'epoch': 73.28}        \n",
      "{'loss': 0.2908, 'learning_rate': 5.3114754098360655e-06, 'epoch': 73.44}       \n",
      "{'loss': 0.3462, 'learning_rate': 5.2786885245901645e-06, 'epoch': 73.61}       \n",
      "{'loss': 0.2659, 'learning_rate': 5.245901639344263e-06, 'epoch': 73.77}        \n",
      "{'loss': 0.2517, 'learning_rate': 5.213114754098361e-06, 'epoch': 73.93}        \n",
      " 74%|████████████████████████████▊          | 4514/6100 [51:28<11:13,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:33:27,912 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:33:27,912 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:33:27,912 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.63it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8579180240631104, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.5554, 'eval_samples_per_second': 149.932, 'eval_steps_per_second': 2.415, 'epoch': 74.0}\n",
      " 74%|████████████████████████████▊          | 4514/6100 [51:33<11:13,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:33:32,467 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4514\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:33:32,468 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4514/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:33:32,579 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4514/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:33:32,580 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4514/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:33:32,758 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4392] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2969, 'learning_rate': 5.180327868852459e-06, 'epoch': 74.1}         \n",
      "{'loss': 0.2785, 'learning_rate': 5.147540983606558e-06, 'epoch': 74.26}        \n",
      "{'loss': 0.2715, 'learning_rate': 5.1147540983606555e-06, 'epoch': 74.43}       \n",
      "{'loss': 0.2513, 'learning_rate': 5.0819672131147545e-06, 'epoch': 74.59}       \n",
      "{'loss': 0.3059, 'learning_rate': 5.0491803278688535e-06, 'epoch': 74.75}       \n",
      "{'loss': 0.2788, 'learning_rate': 5.016393442622951e-06, 'epoch': 74.92}        \n",
      " 75%|█████████████████████████████▎         | 4575/6100 [52:10<10:33,  2.41it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:34:10,386 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:34:10,386 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:34:10,386 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.60it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8479483723640442, 'eval_accuracy': 0.7569546120058566, 'eval_runtime': 4.4832, 'eval_samples_per_second': 152.348, 'eval_steps_per_second': 2.454, 'epoch': 75.0}\n",
      " 75%|█████████████████████████████▎         | 4575/6100 [52:15<10:33,  2.41it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.65it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:34:14,870 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4575\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:34:14,870 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4575/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:34:14,979 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4575/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:34:14,980 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4575/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:34:15,156 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4453] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2841, 'learning_rate': 4.98360655737705e-06, 'epoch': 75.08}         \n",
      "{'loss': 0.276, 'learning_rate': 4.950819672131148e-06, 'epoch': 75.25}         \n",
      "{'loss': 0.2848, 'learning_rate': 4.918032786885246e-06, 'epoch': 75.41}        \n",
      "{'loss': 0.3297, 'learning_rate': 4.8852459016393445e-06, 'epoch': 75.57}       \n",
      "{'loss': 0.2918, 'learning_rate': 4.8524590163934435e-06, 'epoch': 75.74}       \n",
      "{'loss': 0.2813, 'learning_rate': 4.819672131147542e-06, 'epoch': 75.9}         \n",
      " 76%|█████████████████████████████▋         | 4636/6100 [52:52<10:13,  2.39it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:34:52,262 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:34:52,262 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:34:52,262 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.43it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.17it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.99it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.91it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.84it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8439030647277832, 'eval_accuracy': 0.7759882869692533, 'eval_runtime': 5.5448, 'eval_samples_per_second': 123.178, 'eval_steps_per_second': 1.984, 'epoch': 76.0}\n",
      " 76%|█████████████████████████████▋         | 4636/6100 [52:58<10:13,  2.39it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.93it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:34:57,809 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4636\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:34:57,810 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4636/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:34:57,968 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4636/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:34:57,969 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4636/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:34:58,211 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4514] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.311, 'learning_rate': 4.78688524590164e-06, 'epoch': 76.07}          \n",
      "{'loss': 0.3009, 'learning_rate': 4.754098360655738e-06, 'epoch': 76.23}        \n",
      "{'loss': 0.318, 'learning_rate': 4.721311475409836e-06, 'epoch': 76.39}         \n",
      "{'loss': 0.2359, 'learning_rate': 4.6885245901639345e-06, 'epoch': 76.56}       \n",
      "{'loss': 0.3212, 'learning_rate': 4.655737704918033e-06, 'epoch': 76.72}        \n",
      "{'loss': 0.2605, 'learning_rate': 4.622950819672132e-06, 'epoch': 76.89}        \n",
      " 77%|██████████████████████████████         | 4697/6100 [53:36<10:56,  2.14it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:35:36,073 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:35:36,073 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:35:36,073 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8579667210578918, 'eval_accuracy': 0.7715959004392386, 'eval_runtime': 6.182, 'eval_samples_per_second': 110.481, 'eval_steps_per_second': 1.779, 'epoch': 77.0}\n",
      " 77%|██████████████████████████████         | 4697/6100 [53:42<10:56,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:35:42,255 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4697\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:35:42,256 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4697/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:35:42,409 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4697/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:35:42,410 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4697/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:35:42,660 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4575] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2622, 'learning_rate': 4.59016393442623e-06, 'epoch': 77.05}         \n",
      "{'loss': 0.3017, 'learning_rate': 4.557377049180328e-06, 'epoch': 77.21}        \n",
      "{'loss': 0.2664, 'learning_rate': 4.524590163934426e-06, 'epoch': 77.38}        \n",
      "{'loss': 0.3042, 'learning_rate': 4.491803278688525e-06, 'epoch': 77.54}        \n",
      "{'loss': 0.2503, 'learning_rate': 4.4590163934426235e-06, 'epoch': 77.7}        \n",
      "{'loss': 0.2856, 'learning_rate': 4.426229508196722e-06, 'epoch': 77.87}        \n",
      " 78%|██████████████████████████████▍        | 4758/6100 [54:20<11:25,  1.96it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:36:20,267 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:36:20,267 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:36:20,267 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8386711478233337, 'eval_accuracy': 0.7715959004392386, 'eval_runtime': 6.2027, 'eval_samples_per_second': 110.113, 'eval_steps_per_second': 1.773, 'epoch': 78.0}\n",
      " 78%|██████████████████████████████▍        | 4758/6100 [54:27<11:25,  1.96it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:36:26,471 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4758\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:36:26,472 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4758/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:36:26,630 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4758/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:36:26,630 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4758/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:36:26,882 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4636] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2506, 'learning_rate': 4.39344262295082e-06, 'epoch': 78.03}         \n",
      "{'loss': 0.2743, 'learning_rate': 4.360655737704919e-06, 'epoch': 78.2}         \n",
      "{'loss': 0.3044, 'learning_rate': 4.327868852459017e-06, 'epoch': 78.36}        \n",
      "{'loss': 0.2357, 'learning_rate': 4.295081967213115e-06, 'epoch': 78.52}        \n",
      "{'loss': 0.3139, 'learning_rate': 4.2622950819672135e-06, 'epoch': 78.69}       \n",
      "{'loss': 0.26, 'learning_rate': 4.229508196721312e-06, 'epoch': 78.85}          \n",
      " 79%|██████████████████████████████▊        | 4819/6100 [55:05<11:02,  1.93it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:37:04,629 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:37:04,629 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:37:04,629 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.60it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.94it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8433132171630859, 'eval_accuracy': 0.7701317715959004, 'eval_runtime': 4.6364, 'eval_samples_per_second': 147.314, 'eval_steps_per_second': 2.373, 'epoch': 79.0}\n",
      " 79%|██████████████████████████████▊        | 4819/6100 [55:09<11:02,  1.93it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:37:09,265 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4819\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:37:09,266 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4819/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:37:09,375 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4819/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:37:09,376 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4819/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:37:09,549 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4697] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2915, 'learning_rate': 4.19672131147541e-06, 'epoch': 79.02}         \n",
      "{'loss': 0.2915, 'learning_rate': 4.163934426229508e-06, 'epoch': 79.18}        \n",
      "{'loss': 0.2626, 'learning_rate': 4.131147540983607e-06, 'epoch': 79.34}        \n",
      "{'loss': 0.2619, 'learning_rate': 4.098360655737705e-06, 'epoch': 79.51}        \n",
      "{'loss': 0.2721, 'learning_rate': 4.0655737704918034e-06, 'epoch': 79.67}       \n",
      "{'loss': 0.2708, 'learning_rate': 4.032786885245902e-06, 'epoch': 79.84}        \n",
      "{'loss': 0.2816, 'learning_rate': 4.000000000000001e-06, 'epoch': 80.0}         \n",
      " 80%|███████████████████████████████▏       | 4880/6100 [55:47<08:39,  2.35it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:37:46,704 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:37:46,704 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:37:46,704 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.59it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.24it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.62it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.35it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8391131162643433, 'eval_accuracy': 0.7642752562225475, 'eval_runtime': 4.6042, 'eval_samples_per_second': 148.343, 'eval_steps_per_second': 2.389, 'epoch': 80.0}\n",
      " 80%|███████████████████████████████▏       | 4880/6100 [55:51<08:39,  2.35it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.28it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:37:51,308 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4880\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:37:51,309 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4880/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:37:51,419 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4880/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:37:51,419 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4880/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:37:51,594 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4758] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2592, 'learning_rate': 3.967213114754099e-06, 'epoch': 80.16}        \n",
      "{'loss': 0.2524, 'learning_rate': 3.934426229508197e-06, 'epoch': 80.33}        \n",
      "{'loss': 0.2879, 'learning_rate': 3.901639344262295e-06, 'epoch': 80.49}        \n",
      "{'loss': 0.272, 'learning_rate': 3.868852459016394e-06, 'epoch': 80.66}         \n",
      "{'loss': 0.3126, 'learning_rate': 3.8360655737704925e-06, 'epoch': 80.82}       \n",
      "{'loss': 0.2716, 'learning_rate': 3.8032786885245902e-06, 'epoch': 80.98}       \n",
      " 81%|███████████████████████████████▌       | 4941/6100 [56:29<08:12,  2.35it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:38:28,904 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:38:28,904 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:38:28,904 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.26it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.33it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.29it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8395874500274658, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.5885, 'eval_samples_per_second': 148.85, 'eval_steps_per_second': 2.397, 'epoch': 81.0}\n",
      " 81%|███████████████████████████████▌       | 4941/6100 [56:34<08:12,  2.35it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.25it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:38:33,493 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4941\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:38:33,494 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4941/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:38:33,590 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4941/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:38:33,591 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4941/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:38:33,770 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4819] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2853, 'learning_rate': 3.7704918032786884e-06, 'epoch': 81.15}       \n",
      "{'loss': 0.2595, 'learning_rate': 3.7377049180327874e-06, 'epoch': 81.31}       \n",
      "{'loss': 0.2536, 'learning_rate': 3.7049180327868856e-06, 'epoch': 81.48}       \n",
      "{'loss': 0.2701, 'learning_rate': 3.672131147540984e-06, 'epoch': 81.64}        \n",
      "{'loss': 0.2818, 'learning_rate': 3.6393442622950824e-06, 'epoch': 81.8}        \n",
      "{'loss': 0.2547, 'learning_rate': 3.6065573770491806e-06, 'epoch': 81.97}       \n",
      " 82%|███████████████████████████████▉       | 5002/6100 [57:12<07:45,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:39:11,601 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:39:11,601 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:39:11,601 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.52it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.80it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.27it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.04it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.96it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8353105187416077, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 5.2563, 'eval_samples_per_second': 129.939, 'eval_steps_per_second': 2.093, 'epoch': 82.0}\n",
      " 82%|███████████████████████████████▉       | 5002/6100 [57:17<07:45,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.95it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:39:16,863 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5002\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:39:16,864 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5002/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:39:17,021 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5002/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:39:17,021 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5002/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:39:17,271 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4880] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2933, 'learning_rate': 3.573770491803279e-06, 'epoch': 82.13}        \n",
      "{'loss': 0.2483, 'learning_rate': 3.540983606557377e-06, 'epoch': 82.3}         \n",
      "{'loss': 0.2327, 'learning_rate': 3.508196721311476e-06, 'epoch': 82.46}        \n",
      "{'loss': 0.3039, 'learning_rate': 3.4754098360655742e-06, 'epoch': 82.62}       \n",
      "{'loss': 0.2676, 'learning_rate': 3.4426229508196724e-06, 'epoch': 82.79}       \n",
      "{'loss': 0.2741, 'learning_rate': 3.4098360655737706e-06, 'epoch': 82.95}       \n",
      " 83%|████████████████████████████████▎      | 5063/6100 [57:55<07:21,  2.35it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:39:54,933 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:39:54,933 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:39:54,933 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8393881916999817, 'eval_accuracy': 0.7613469985358712, 'eval_runtime': 6.0118, 'eval_samples_per_second': 113.61, 'eval_steps_per_second': 1.83, 'epoch': 83.0}\n",
      " 83%|████████████████████████████████▎      | 5063/6100 [58:01<07:21,  2.35it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:40:00,945 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5063\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:40:00,946 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5063/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:40:01,106 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5063/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:40:01,107 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5063/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:40:01,351 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-4941] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.264, 'learning_rate': 3.3770491803278692e-06, 'epoch': 83.11}        \n",
      "{'loss': 0.2729, 'learning_rate': 3.3442622950819674e-06, 'epoch': 83.28}       \n",
      "{'loss': 0.2719, 'learning_rate': 3.3114754098360656e-06, 'epoch': 83.44}       \n",
      "{'loss': 0.239, 'learning_rate': 3.2786885245901638e-06, 'epoch': 83.61}        \n",
      "{'loss': 0.2834, 'learning_rate': 3.245901639344263e-06, 'epoch': 83.77}        \n",
      "{'loss': 0.2593, 'learning_rate': 3.213114754098361e-06, 'epoch': 83.93}        \n",
      " 84%|████████████████████████████████▊      | 5124/6100 [58:39<08:19,  1.95it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:40:38,950 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:40:38,950 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:40:38,950 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.40it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8477922677993774, 'eval_accuracy': 0.7569546120058566, 'eval_runtime': 6.161, 'eval_samples_per_second': 110.859, 'eval_steps_per_second': 1.785, 'epoch': 84.0}\n",
      " 84%|████████████████████████████████▊      | 5124/6100 [58:45<08:19,  1.95it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:40:45,115 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5124\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:40:45,116 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5124/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:40:45,273 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5124/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:40:45,273 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5124/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:40:45,519 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5002] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3519, 'learning_rate': 3.180327868852459e-06, 'epoch': 84.1}         \n",
      "{'loss': 0.2305, 'learning_rate': 3.147540983606558e-06, 'epoch': 84.26}        \n",
      "{'loss': 0.2549, 'learning_rate': 3.114754098360656e-06, 'epoch': 84.43}        \n",
      "{'loss': 0.2611, 'learning_rate': 3.081967213114754e-06, 'epoch': 84.59}        \n",
      "{'loss': 0.2762, 'learning_rate': 3.0491803278688524e-06, 'epoch': 84.75}       \n",
      "{'loss': 0.2718, 'learning_rate': 3.0163934426229514e-06, 'epoch': 84.92}       \n",
      " 85%|█████████████████████████████████▏     | 5185/6100 [59:23<07:55,  1.92it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:41:23,103 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:41:23,104 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:41:23,104 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.57it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8573300242424011, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.5555, 'eval_samples_per_second': 149.928, 'eval_steps_per_second': 2.415, 'epoch': 85.0}\n",
      " 85%|█████████████████████████████████▏     | 5185/6100 [59:28<07:55,  1.92it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:41:27,660 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5185\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:41:27,661 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5185/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:41:27,774 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5185/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:41:27,775 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5185/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:41:27,953 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5063] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2688, 'learning_rate': 2.9836065573770496e-06, 'epoch': 85.08}       \n",
      "{'loss': 0.255, 'learning_rate': 2.9508196721311478e-06, 'epoch': 85.25}        \n",
      "{'loss': 0.2948, 'learning_rate': 2.918032786885246e-06, 'epoch': 85.41}        \n",
      "{'loss': 0.3001, 'learning_rate': 2.8852459016393446e-06, 'epoch': 85.57}       \n",
      "{'loss': 0.261, 'learning_rate': 2.8524590163934428e-06, 'epoch': 85.74}        \n",
      "{'loss': 0.229, 'learning_rate': 2.819672131147541e-06, 'epoch': 85.9}          \n",
      " 86%|███████████████████████████████▊     | 5246/6100 [1:00:06<06:01,  2.37it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:42:05,701 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:42:05,701 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:42:05,701 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.58it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8443440794944763, 'eval_accuracy': 0.7745241581259151, 'eval_runtime': 4.4457, 'eval_samples_per_second': 153.631, 'eval_steps_per_second': 2.474, 'epoch': 86.0}\n",
      " 86%|███████████████████████████████▊     | 5246/6100 [1:00:10<06:01,  2.37it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.58it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:42:10,148 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5246\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:42:10,148 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5246/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:42:10,247 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5246/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:42:10,248 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5246/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:42:10,424 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5124] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2581, 'learning_rate': 2.786885245901639e-06, 'epoch': 86.07}        \n",
      "{'loss': 0.2581, 'learning_rate': 2.754098360655738e-06, 'epoch': 86.23}        \n",
      "{'loss': 0.2257, 'learning_rate': 2.7213114754098364e-06, 'epoch': 86.39}       \n",
      "{'loss': 0.2815, 'learning_rate': 2.6885245901639346e-06, 'epoch': 86.56}       \n",
      "{'loss': 0.2965, 'learning_rate': 2.6557377049180328e-06, 'epoch': 86.72}       \n",
      "{'loss': 0.2448, 'learning_rate': 2.6229508196721314e-06, 'epoch': 86.89}       \n",
      " 87%|████████████████████████████████▏    | 5307/6100 [1:00:48<05:33,  2.38it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:42:47,866 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:42:47,867 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:42:47,867 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.68it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.34it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8488151431083679, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 4.5509, 'eval_samples_per_second': 150.079, 'eval_steps_per_second': 2.417, 'epoch': 87.0}\n",
      " 87%|████████████████████████████████▏    | 5307/6100 [1:00:52<05:33,  2.38it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:42:52,418 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5307\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:42:52,419 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5307/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:42:52,531 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5307/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:42:52,532 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5307/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:42:52,709 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5185] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2668, 'learning_rate': 2.5901639344262296e-06, 'epoch': 87.05}       \n",
      "{'loss': 0.2514, 'learning_rate': 2.5573770491803277e-06, 'epoch': 87.21}       \n",
      "{'loss': 0.2839, 'learning_rate': 2.5245901639344268e-06, 'epoch': 87.38}       \n",
      "{'loss': 0.298, 'learning_rate': 2.491803278688525e-06, 'epoch': 87.54}         \n",
      "{'loss': 0.2836, 'learning_rate': 2.459016393442623e-06, 'epoch': 87.7}         \n",
      "{'loss': 0.2764, 'learning_rate': 2.4262295081967218e-06, 'epoch': 87.87}       \n",
      " 88%|████████████████████████████████▌    | 5368/6100 [1:01:32<05:15,  2.32it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:43:32,089 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:43:32,089 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:43:32,089 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.01it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8414624929428101, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.4648, 'eval_samples_per_second': 152.976, 'eval_steps_per_second': 2.464, 'epoch': 88.0}\n",
      " 88%|████████████████████████████████▌    | 5368/6100 [1:01:37<05:15,  2.32it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:43:36,557 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5368\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:43:36,558 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5368/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:43:36,669 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5368/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:43:36,669 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5368/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:43:36,848 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5246] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2642, 'learning_rate': 2.39344262295082e-06, 'epoch': 88.03}         \n",
      "{'loss': 0.2932, 'learning_rate': 2.360655737704918e-06, 'epoch': 88.2}         \n",
      "{'loss': 0.2549, 'learning_rate': 2.3278688524590163e-06, 'epoch': 88.36}       \n",
      "{'loss': 0.2574, 'learning_rate': 2.295081967213115e-06, 'epoch': 88.52}        \n",
      "{'loss': 0.2759, 'learning_rate': 2.262295081967213e-06, 'epoch': 88.69}        \n",
      "{'loss': 0.2403, 'learning_rate': 2.2295081967213117e-06, 'epoch': 88.85}       \n",
      " 89%|████████████████████████████████▉    | 5429/6100 [1:02:14<04:44,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:44:13,755 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:44:13,755 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:44:13,755 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.66it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.80it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.57it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.29it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.07it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.14it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8509761095046997, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.9061, 'eval_samples_per_second': 139.215, 'eval_steps_per_second': 2.242, 'epoch': 89.0}\n",
      " 89%|████████████████████████████████▉    | 5429/6100 [1:02:19<04:44,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:44:18,662 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5429\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:44:18,663 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5429/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:44:18,801 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5429/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:44:18,801 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5429/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:44:19,051 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5307] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2484, 'learning_rate': 2.19672131147541e-06, 'epoch': 89.02}         \n",
      "{'loss': 0.2359, 'learning_rate': 2.1639344262295085e-06, 'epoch': 89.18}       \n",
      "{'loss': 0.2655, 'learning_rate': 2.1311475409836067e-06, 'epoch': 89.34}       \n",
      "{'loss': 0.2651, 'learning_rate': 2.098360655737705e-06, 'epoch': 89.51}        \n",
      "{'loss': 0.2656, 'learning_rate': 2.0655737704918035e-06, 'epoch': 89.67}       \n",
      "{'loss': 0.2826, 'learning_rate': 2.0327868852459017e-06, 'epoch': 89.84}       \n",
      "{'loss': 0.2667, 'learning_rate': 2.0000000000000003e-06, 'epoch': 90.0}        \n",
      " 90%|█████████████████████████████████▎   | 5490/6100 [1:02:57<04:44,  2.14it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:44:56,890 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:44:56,890 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:44:56,890 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.69it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8550705313682556, 'eval_accuracy': 0.7613469985358712, 'eval_runtime': 6.1622, 'eval_samples_per_second': 110.837, 'eval_steps_per_second': 1.785, 'epoch': 90.0}\n",
      " 90%|█████████████████████████████████▎   | 5490/6100 [1:03:03<04:44,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:45:03,054 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5490\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:45:03,055 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5490/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:45:03,217 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5490/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:45:03,218 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5490/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:45:03,465 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5368] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.252, 'learning_rate': 1.9672131147540985e-06, 'epoch': 90.16}        \n",
      "{'loss': 0.2529, 'learning_rate': 1.934426229508197e-06, 'epoch': 90.33}        \n",
      "{'loss': 0.252, 'learning_rate': 1.9016393442622951e-06, 'epoch': 90.49}        \n",
      "{'loss': 0.2492, 'learning_rate': 1.8688524590163937e-06, 'epoch': 90.66}       \n",
      "{'loss': 0.2579, 'learning_rate': 1.836065573770492e-06, 'epoch': 90.82}        \n",
      "{'loss': 0.2557, 'learning_rate': 1.8032786885245903e-06, 'epoch': 90.98}       \n",
      " 91%|█████████████████████████████████▋   | 5551/6100 [1:03:41<04:34,  2.00it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:45:41,092 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:45:41,092 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:45:41,092 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.61it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.48it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8641077876091003, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 6.1347, 'eval_samples_per_second': 111.334, 'eval_steps_per_second': 1.793, 'epoch': 91.0}\n",
      " 91%|█████████████████████████████████▋   | 5551/6100 [1:03:47<04:34,  2.00it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:45:47,227 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5551\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:45:47,228 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5551/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:45:47,391 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5551/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:45:47,392 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5551/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:45:47,645 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5429] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2551, 'learning_rate': 1.7704918032786885e-06, 'epoch': 91.15}       \n",
      "{'loss': 0.2686, 'learning_rate': 1.7377049180327871e-06, 'epoch': 91.31}       \n",
      "{'loss': 0.2464, 'learning_rate': 1.7049180327868853e-06, 'epoch': 91.48}       \n",
      "{'loss': 0.2763, 'learning_rate': 1.6721311475409837e-06, 'epoch': 91.64}       \n",
      "{'loss': 0.2383, 'learning_rate': 1.6393442622950819e-06, 'epoch': 91.8}        \n",
      "{'loss': 0.2234, 'learning_rate': 1.6065573770491805e-06, 'epoch': 91.97}       \n",
      " 92%|██████████████████████████████████   | 5612/6100 [1:04:26<04:11,  1.94it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:46:25,434 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:46:25,434 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:46:25,434 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.48it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.46it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.856838583946228, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 6.1603, 'eval_samples_per_second': 110.87, 'eval_steps_per_second': 1.786, 'epoch': 92.0}\n",
      " 92%|██████████████████████████████████   | 5612/6100 [1:04:32<04:11,  1.94it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:46:31,600 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5612\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:46:31,601 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5612/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:46:31,757 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5612/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:46:31,757 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5612/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:46:32,003 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5490] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2559, 'learning_rate': 1.573770491803279e-06, 'epoch': 92.13}        \n",
      "{'loss': 0.2479, 'learning_rate': 1.540983606557377e-06, 'epoch': 92.3}         \n",
      "{'loss': 0.2521, 'learning_rate': 1.5081967213114757e-06, 'epoch': 92.46}       \n",
      "{'loss': 0.2494, 'learning_rate': 1.4754098360655739e-06, 'epoch': 92.62}       \n",
      "{'loss': 0.2317, 'learning_rate': 1.4426229508196723e-06, 'epoch': 92.79}       \n",
      "{'loss': 0.2821, 'learning_rate': 1.4098360655737705e-06, 'epoch': 92.95}       \n",
      " 93%|██████████████████████████████████▍  | 5673/6100 [1:05:10<03:41,  1.93it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:47:09,702 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:47:09,702 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:47:09,702 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.62it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.56it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.17it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.05it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.95it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8618971705436707, 'eval_accuracy': 0.7701317715959004, 'eval_runtime': 6.0416, 'eval_samples_per_second': 113.049, 'eval_steps_per_second': 1.821, 'epoch': 93.0}\n",
      " 93%|██████████████████████████████████▍  | 5673/6100 [1:05:16<03:41,  1.93it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:47:15,744 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5673\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:47:15,745 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5673/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:47:15,903 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5673/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:47:15,904 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5673/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:47:16,156 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5551] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2397, 'learning_rate': 1.377049180327869e-06, 'epoch': 93.11}        \n",
      "{'loss': 0.2668, 'learning_rate': 1.3442622950819673e-06, 'epoch': 93.28}       \n",
      "{'loss': 0.2392, 'learning_rate': 1.3114754098360657e-06, 'epoch': 93.44}       \n",
      "{'loss': 0.2666, 'learning_rate': 1.2786885245901639e-06, 'epoch': 93.61}       \n",
      "{'loss': 0.201, 'learning_rate': 1.2459016393442625e-06, 'epoch': 93.77}        \n",
      "{'loss': 0.2555, 'learning_rate': 1.2131147540983609e-06, 'epoch': 93.93}       \n",
      " 94%|██████████████████████████████████▊  | 5734/6100 [1:05:53<02:41,  2.27it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:47:53,215 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:47:53,216 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:47:53,216 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.79it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.49it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8567971587181091, 'eval_accuracy': 0.7701317715959004, 'eval_runtime': 4.5387, 'eval_samples_per_second': 150.482, 'eval_steps_per_second': 2.424, 'epoch': 94.0}\n",
      " 94%|██████████████████████████████████▊  | 5734/6100 [1:05:58<02:41,  2.27it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:47:57,755 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5734\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:47:57,755 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5734/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:47:57,867 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5734/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:47:57,867 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5734/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:47:58,046 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5612] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.26, 'learning_rate': 1.180327868852459e-06, 'epoch': 94.1}           \n",
      "{'loss': 0.2841, 'learning_rate': 1.1475409836065575e-06, 'epoch': 94.26}       \n",
      "{'loss': 0.2966, 'learning_rate': 1.1147540983606559e-06, 'epoch': 94.43}       \n",
      "{'loss': 0.2593, 'learning_rate': 1.0819672131147543e-06, 'epoch': 94.59}       \n",
      "{'loss': 0.2729, 'learning_rate': 1.0491803278688525e-06, 'epoch': 94.75}       \n",
      "{'loss': 0.285, 'learning_rate': 1.0163934426229509e-06, 'epoch': 94.92}        \n",
      " 95%|███████████████████████████████████▏ | 5795/6100 [1:06:37<02:13,  2.29it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:48:36,982 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:48:36,982 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:48:36,982 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.61it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.37it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.31it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8626590371131897, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 4.5914, 'eval_samples_per_second': 148.757, 'eval_steps_per_second': 2.396, 'epoch': 95.0}\n",
      " 95%|███████████████████████████████████▏ | 5795/6100 [1:06:42<02:13,  2.29it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.22it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:48:41,573 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5795\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:48:41,574 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5795/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:48:41,680 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5795/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:48:41,681 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5795/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:48:41,860 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5673] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2737, 'learning_rate': 9.836065573770493e-07, 'epoch': 95.08}        \n",
      "{'loss': 0.2393, 'learning_rate': 9.508196721311476e-07, 'epoch': 95.25}        \n",
      "{'loss': 0.2246, 'learning_rate': 9.18032786885246e-07, 'epoch': 95.41}         \n",
      "{'loss': 0.2885, 'learning_rate': 8.852459016393443e-07, 'epoch': 95.57}        \n",
      "{'loss': 0.2321, 'learning_rate': 8.524590163934427e-07, 'epoch': 95.74}        \n",
      "{'loss': 0.2755, 'learning_rate': 8.196721311475409e-07, 'epoch': 95.9}         \n",
      " 96%|███████████████████████████████████▌ | 5856/6100 [1:07:20<01:43,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:49:19,934 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:49:19,934 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:49:19,934 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.70it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.32it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.61it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.864021360874176, 'eval_accuracy': 0.7686676427525623, 'eval_runtime': 4.5803, 'eval_samples_per_second': 149.118, 'eval_steps_per_second': 2.402, 'epoch': 96.0}\n",
      " 96%|███████████████████████████████████▌ | 5856/6100 [1:07:25<01:43,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:49:24,515 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5856\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:49:24,516 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5856/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:49:24,631 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5856/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:49:24,632 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5856/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:49:24,813 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5734] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2567, 'learning_rate': 7.868852459016395e-07, 'epoch': 96.07}        \n",
      "{'loss': 0.2357, 'learning_rate': 7.540983606557379e-07, 'epoch': 96.23}        \n",
      "{'loss': 0.2437, 'learning_rate': 7.213114754098361e-07, 'epoch': 96.39}        \n",
      "{'loss': 0.2429, 'learning_rate': 6.885245901639345e-07, 'epoch': 96.56}        \n",
      "{'loss': 0.2374, 'learning_rate': 6.557377049180328e-07, 'epoch': 96.72}        \n",
      "{'loss': 0.2901, 'learning_rate': 6.229508196721312e-07, 'epoch': 96.89}        \n",
      " 97%|███████████████████████████████████▉ | 5917/6100 [1:08:01<01:17,  2.37it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:50:01,315 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:50:01,315 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:50:01,315 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.59it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.60it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.867293119430542, 'eval_accuracy': 0.7657393850658858, 'eval_runtime': 4.49, 'eval_samples_per_second': 152.114, 'eval_steps_per_second': 2.45, 'epoch': 97.0}\n",
      " 97%|███████████████████████████████████▉ | 5917/6100 [1:08:06<01:17,  2.37it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:50:05,806 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5917\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:50:05,806 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5917/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:50:05,943 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5917/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:50:05,943 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5917/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:50:06,192 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5795] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2258, 'learning_rate': 5.901639344262295e-07, 'epoch': 97.05}        \n",
      "{'loss': 0.2701, 'learning_rate': 5.573770491803279e-07, 'epoch': 97.21}        \n",
      "{'loss': 0.2373, 'learning_rate': 5.245901639344262e-07, 'epoch': 97.38}        \n",
      "{'loss': 0.2767, 'learning_rate': 4.918032786885246e-07, 'epoch': 97.54}        \n",
      "{'loss': 0.242, 'learning_rate': 4.59016393442623e-07, 'epoch': 97.7}           \n",
      "{'loss': 0.2498, 'learning_rate': 4.262295081967213e-07, 'epoch': 97.87}        \n",
      " 98%|████████████████████████████████████▎| 5978/6100 [1:08:45<00:51,  2.36it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:50:44,516 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:50:44,517 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:50:44,517 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.75it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.29it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.04it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.93it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:01,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8705562353134155, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 5.2248, 'eval_samples_per_second': 130.722, 'eval_steps_per_second': 2.105, 'epoch': 98.0}\n",
      " 98%|████████████████████████████████████▎| 5978/6100 [1:08:50<00:51,  2.36it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.97it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:50:49,743 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5978\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:50:49,744 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5978/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:50:49,904 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5978/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:50:49,905 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5978/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:50:50,152 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5856] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2157, 'learning_rate': 3.934426229508197e-07, 'epoch': 98.03}        \n",
      "{'loss': 0.2791, 'learning_rate': 3.6065573770491807e-07, 'epoch': 98.2}        \n",
      "{'loss': 0.2396, 'learning_rate': 3.278688524590164e-07, 'epoch': 98.36}        \n",
      "{'loss': 0.2226, 'learning_rate': 2.9508196721311477e-07, 'epoch': 98.52}       \n",
      "{'loss': 0.2333, 'learning_rate': 2.622950819672131e-07, 'epoch': 98.69}        \n",
      "{'loss': 0.2368, 'learning_rate': 2.295081967213115e-07, 'epoch': 98.85}        \n",
      " 99%|████████████████████████████████████▋| 6039/6100 [1:09:29<00:26,  2.33it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:51:28,763 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:51:28,763 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:51:28,763 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.29it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.07it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.97it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.89it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8688689470291138, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 5.3767, 'eval_samples_per_second': 127.029, 'eval_steps_per_second': 2.046, 'epoch': 99.0}\n",
      " 99%|████████████████████████████████████▋| 6039/6100 [1:09:34<00:26,  2.33it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.97it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:51:34,141 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6039\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:51:34,141 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6039/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:51:34,297 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6039/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:51:34,297 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6039/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:51:34,545 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5917] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.271, 'learning_rate': 1.9672131147540986e-07, 'epoch': 99.02}        \n",
      "{'loss': 0.246, 'learning_rate': 1.639344262295082e-07, 'epoch': 99.18}         \n",
      "{'loss': 0.2799, 'learning_rate': 1.3114754098360656e-07, 'epoch': 99.34}       \n",
      "{'loss': 0.2788, 'learning_rate': 9.836065573770493e-08, 'epoch': 99.51}        \n",
      "{'loss': 0.2263, 'learning_rate': 6.557377049180328e-08, 'epoch': 99.67}        \n",
      "{'loss': 0.2335, 'learning_rate': 3.278688524590164e-08, 'epoch': 99.84}        \n",
      "{'loss': 0.2512, 'learning_rate': 0.0, 'epoch': 100.0}                          \n",
      "100%|█████████████████████████████████████| 6100/6100 [1:10:12<00:00,  1.98it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:52:12,221 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:52:12,221 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:52:12,221 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.40it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.868538498878479, 'eval_accuracy': 0.767203513909224, 'eval_runtime': 6.2117, 'eval_samples_per_second': 109.954, 'eval_steps_per_second': 1.771, 'epoch': 100.0}\n",
      "100%|█████████████████████████████████████| 6100/6100 [1:10:19<00:00,  1.98it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:52:18,433 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6100\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:52:18,435 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:52:18,590 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6100/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:52:18,591 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-6100/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:52:18,842 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-5978] due to args.save_total_limit\n",
      "[INFO|trainer.py:1916] 2023-10-05 10:52:18,874 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2051] 2023-10-05 10:52:18,874 >> Loading best model from outputs_all/swin_combine_pseudo_30%_Fold_5/checkpoint-1220 (score: 0.6315969228744507).\n",
      "{'train_runtime': 4219.5121, 'train_samples_per_second': 91.717, 'train_steps_per_second': 1.446, 'train_loss': 0.4231966890272547, 'epoch': 100.0}\n",
      "100%|█████████████████████████████████████| 6100/6100 [1:10:19<00:00,  1.45it/s]\n",
      "[INFO|trainer.py:2800] 2023-10-05 10:52:18,936 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_5\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:52:18,937 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_5/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:52:19,062 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_5/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:52:19,063 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_5/preprocessor_config.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      100.0\n",
      "  train_loss               =     0.4232\n",
      "  train_runtime            = 1:10:19.51\n",
      "  train_samples_per_second =     91.717\n",
      "  train_steps_per_second   =      1.446\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:52:19,076 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:52:19,076 >>   Num examples = 683\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:52:19,076 >>   Batch size = 64\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.11it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =      100.0\n",
      "  eval_accuracy           =     0.7804\n",
      "  eval_loss               =     0.6316\n",
      "  eval_runtime            = 0:00:06.16\n",
      "  eval_samples_per_second =    110.702\n",
      "  eval_steps_per_second   =      1.783\n",
      "10/05/2023 10:52:29 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: False\n",
      "10/05/2023 10:52:29 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=2,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs_all/swin_combine_pseudo_30%_Fold_6/runs/Oct05_10-52-28_thanawit-Z690-Pro-RS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=100.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=outputs_all/swin_combine_pseudo_30%_Fold_6,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs_all/swin_combine_pseudo_30%_Fold_6,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "Resolving data files: 100%|███████████████| 4569/4569 [00:00<00:00, 9647.20it/s]\n",
      "10/05/2023 10:52:31 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-59a8f68a1814920d/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 108.13it/s]\n",
      "10/05/2023 10:52:31 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-59a8f68a1814920d/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-da502942d9407488.arrow\n",
      "10/05/2023 10:52:31 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-59a8f68a1814920d/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-1db507c7937dee74.arrow and /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-59a8f68a1814920d/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-cbd94bd73f393365.arrow\n",
      "[INFO|configuration_utils.py:669] 2023-10-05 10:52:32,922 >> loading configuration file config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-10-05 10:52:32,923 >> Model config SwinConfig {\n",
      "  \"_name_or_path\": \"microsoft/swin-tiny-patch4-window7-224\",\n",
      "  \"architectures\": [\n",
      "    \"SwinForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    6,\n",
      "    2\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"embed_dim\": 96,\n",
      "  \"encoder_stride\": 32,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Atypical\",\n",
      "    \"1\": \"Indeterminate\",\n",
      "    \"2\": \"Negative\",\n",
      "    \"3\": \"Typical\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Atypical\": \"0\",\n",
      "    \"Indeterminate\": \"1\",\n",
      "    \"Negative\": \"2\",\n",
      "    \"Typical\": \"3\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mlp_ratio\": 4.0,\n",
      "  \"model_type\": \"swin\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_heads\": [\n",
      "    3,\n",
      "    6,\n",
      "    12,\n",
      "    24\n",
      "  ],\n",
      "  \"num_layers\": 4,\n",
      "  \"out_features\": [\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"out_indices\": [\n",
      "    4\n",
      "  ],\n",
      "  \"patch_size\": 4,\n",
      "  \"path_norm\": true,\n",
      "  \"qkv_bias\": true,\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0.dev0\",\n",
      "  \"use_absolute_embeddings\": false,\n",
      "  \"window_size\": 7\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2575] 2023-10-05 10:52:32,926 >> loading weights file model.safetensors from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3283] 2023-10-05 10:52:33,092 >> All model checkpoint weights were used when initializing SwinForImageClassification.\n",
      "\n",
      "[WARNING|modeling_utils.py:3304] 2023-10-05 10:52:33,092 >> Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-10-05 10:52:33,586 >> loading configuration file preprocessor_config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/preprocessor_config.json\n",
      "[WARNING|image_processing_auto.py:331] 2023-10-05 10:52:33,586 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "[INFO|image_processing_utils.py:542] 2023-10-05 10:52:33,597 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "[INFO|image_processing_utils.py:359] 2023-10-05 10:52:33,597 >> Image processor ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:1680] 2023-10-05 10:52:34,352 >> ***** Running training *****\n",
      "[INFO|trainer.py:1681] 2023-10-05 10:52:34,352 >>   Num examples = 3,883\n",
      "[INFO|trainer.py:1682] 2023-10-05 10:52:34,352 >>   Num Epochs = 100\n",
      "[INFO|trainer.py:1683] 2023-10-05 10:52:34,352 >>   Instantaneous batch size per device = 64\n",
      "[INFO|trainer.py:1684] 2023-10-05 10:52:34,352 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1685] 2023-10-05 10:52:34,352 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1686] 2023-10-05 10:52:34,352 >>   Total optimization steps = 6,100\n",
      "[INFO|trainer.py:1687] 2023-10-05 10:52:34,353 >>   Number of trainable parameters = 27,522,430\n",
      "  0%|                                                  | 0/6100 [00:00<?, ?it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 1.1454, 'learning_rate': 1.99672131147541e-05, 'epoch': 0.16}          \n",
      "{'loss': 1.017, 'learning_rate': 1.99344262295082e-05, 'epoch': 0.33}           \n",
      "{'loss': 0.9008, 'learning_rate': 1.9901639344262297e-05, 'epoch': 0.49}        \n",
      "{'loss': 0.8718, 'learning_rate': 1.9868852459016394e-05, 'epoch': 0.66}        \n",
      "{'loss': 0.8758, 'learning_rate': 1.9836065573770492e-05, 'epoch': 0.82}        \n",
      "{'loss': 0.8843, 'learning_rate': 1.9803278688524592e-05, 'epoch': 0.98}        \n",
      "  1%|▍                                        | 61/6100 [00:40<47:20,  2.13it/s][INFO|trainer.py:3074] 2023-10-05 10:53:14,996 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:53:14,996 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:53:14,996 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.19it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.04it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.43it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.35it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.31it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.30it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.24it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8143963813781738, 'eval_accuracy': 0.7128279883381924, 'eval_runtime': 4.9075, 'eval_samples_per_second': 139.787, 'eval_steps_per_second': 2.241, 'epoch': 1.0}\n",
      "  1%|▍                                        | 61/6100 [00:45<47:20,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:53:19,904 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-61\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:53:19,904 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-61/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:53:20,023 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-61/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:53:20,024 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-61/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.8405, 'learning_rate': 1.977049180327869e-05, 'epoch': 1.15}         \n",
      "{'loss': 0.8065, 'learning_rate': 1.973770491803279e-05, 'epoch': 1.31}         \n",
      "{'loss': 0.7875, 'learning_rate': 1.9704918032786884e-05, 'epoch': 1.48}        \n",
      "{'loss': 0.861, 'learning_rate': 1.9672131147540985e-05, 'epoch': 1.64}         \n",
      "{'loss': 0.7484, 'learning_rate': 1.9639344262295083e-05, 'epoch': 1.8}         \n",
      "{'loss': 0.777, 'learning_rate': 1.9606557377049183e-05, 'epoch': 1.97}         \n",
      "  2%|▊                                       | 122/6100 [01:23<44:48,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:53:58,134 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:53:58,135 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:53:58,135 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.42it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.57it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.17it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.11it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7373355627059937, 'eval_accuracy': 0.7536443148688047, 'eval_runtime': 4.8838, 'eval_samples_per_second': 140.464, 'eval_steps_per_second': 2.252, 'epoch': 2.0}\n",
      "  2%|▊                                       | 122/6100 [01:28<44:48,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.78it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:54:03,019 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-122\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:54:03,020 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-122/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:54:03,179 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-122/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:54:03,179 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-122/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.823, 'learning_rate': 1.957377049180328e-05, 'epoch': 2.13}          \n",
      "{'loss': 0.7432, 'learning_rate': 1.9540983606557378e-05, 'epoch': 2.3}         \n",
      "{'loss': 0.7372, 'learning_rate': 1.9508196721311475e-05, 'epoch': 2.46}        \n",
      "{'loss': 0.8622, 'learning_rate': 1.9475409836065576e-05, 'epoch': 2.62}        \n",
      "{'loss': 0.7853, 'learning_rate': 1.9442622950819673e-05, 'epoch': 2.79}        \n",
      "{'loss': 0.7455, 'learning_rate': 1.9409836065573774e-05, 'epoch': 2.95}        \n",
      "  3%|█▏                                      | 183/6100 [02:07<44:49,  2.20it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:54:41,367 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:54:41,367 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:54:41,367 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.55it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.00it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7112398147583008, 'eval_accuracy': 0.7419825072886297, 'eval_runtime': 6.1467, 'eval_samples_per_second': 111.605, 'eval_steps_per_second': 1.79, 'epoch': 3.0}\n",
      "  3%|█▏                                      | 183/6100 [02:13<44:49,  2.20it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:54:47,515 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-183\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:54:47,516 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-183/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:54:47,676 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-183/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:54:47,677 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-183/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6964, 'learning_rate': 1.937704918032787e-05, 'epoch': 3.11}         \n",
      "{'loss': 0.7175, 'learning_rate': 1.934426229508197e-05, 'epoch': 3.28}         \n",
      "{'loss': 0.755, 'learning_rate': 1.9311475409836066e-05, 'epoch': 3.44}         \n",
      "{'loss': 0.7633, 'learning_rate': 1.9278688524590167e-05, 'epoch': 3.61}        \n",
      "{'loss': 0.817, 'learning_rate': 1.9245901639344264e-05, 'epoch': 3.77}         \n",
      "{'loss': 0.7374, 'learning_rate': 1.921311475409836e-05, 'epoch': 3.93}         \n",
      "  4%|█▌                                      | 244/6100 [02:51<52:33,  1.86it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:55:25,878 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:55:25,878 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:55:25,878 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6999315023422241, 'eval_accuracy': 0.760932944606414, 'eval_runtime': 6.1522, 'eval_samples_per_second': 111.505, 'eval_steps_per_second': 1.788, 'epoch': 4.0}\n",
      "  4%|█▌                                      | 244/6100 [02:57<52:33,  1.86it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:55:32,031 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-244\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:55:32,032 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-244/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:55:32,200 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-244/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:55:32,201 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-244/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:55:32,442 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-61] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.698, 'learning_rate': 1.918032786885246e-05, 'epoch': 4.1}           \n",
      "{'loss': 0.7157, 'learning_rate': 1.914754098360656e-05, 'epoch': 4.26}         \n",
      "{'loss': 0.6791, 'learning_rate': 1.9114754098360657e-05, 'epoch': 4.43}        \n",
      "{'loss': 0.7171, 'learning_rate': 1.9081967213114754e-05, 'epoch': 4.59}        \n",
      "{'loss': 0.7117, 'learning_rate': 1.9049180327868855e-05, 'epoch': 4.75}        \n",
      "{'loss': 0.7609, 'learning_rate': 1.9016393442622952e-05, 'epoch': 4.92}        \n",
      "  5%|██                                      | 305/6100 [03:35<52:13,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:56:10,094 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:56:10,094 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:56:10,094 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.97it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.12it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.22it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7399085760116577, 'eval_accuracy': 0.7536443148688047, 'eval_runtime': 5.6345, 'eval_samples_per_second': 121.751, 'eval_steps_per_second': 1.952, 'epoch': 5.0}\n",
      "  5%|██                                      | 305/6100 [03:41<52:13,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.33it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:56:15,729 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-305\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:56:15,730 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-305/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:56:15,842 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-305/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:56:15,843 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-305/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:56:16,014 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-122] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7771, 'learning_rate': 1.898360655737705e-05, 'epoch': 5.08}         \n",
      "{'loss': 0.679, 'learning_rate': 1.895081967213115e-05, 'epoch': 5.25}          \n",
      "{'loss': 0.7612, 'learning_rate': 1.8918032786885248e-05, 'epoch': 5.41}        \n",
      "{'loss': 0.7408, 'learning_rate': 1.8885245901639345e-05, 'epoch': 5.57}        \n",
      "{'loss': 0.6825, 'learning_rate': 1.8852459016393446e-05, 'epoch': 5.74}        \n",
      "{'loss': 0.7287, 'learning_rate': 1.8819672131147543e-05, 'epoch': 5.9}         \n",
      "  6%|██▍                                     | 366/6100 [04:19<45:32,  2.10it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:56:53,963 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:56:53,963 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:56:53,963 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7862948179244995, 'eval_accuracy': 0.7303206997084548, 'eval_runtime': 4.4841, 'eval_samples_per_second': 152.985, 'eval_steps_per_second': 2.453, 'epoch': 6.0}\n",
      "  6%|██▍                                     | 366/6100 [04:24<45:32,  2.10it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:56:58,447 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-366\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:56:58,448 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-366/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:56:58,557 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-366/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:56:58,557 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-366/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:56:58,730 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-183] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.8049, 'learning_rate': 1.878688524590164e-05, 'epoch': 6.07}         \n",
      "{'loss': 0.7412, 'learning_rate': 1.8754098360655738e-05, 'epoch': 6.23}        \n",
      "{'loss': 0.7062, 'learning_rate': 1.872131147540984e-05, 'epoch': 6.39}         \n",
      "{'loss': 0.6395, 'learning_rate': 1.8688524590163936e-05, 'epoch': 6.56}        \n",
      "{'loss': 0.7411, 'learning_rate': 1.8655737704918033e-05, 'epoch': 6.72}        \n",
      "{'loss': 0.6904, 'learning_rate': 1.862295081967213e-05, 'epoch': 6.89}         \n",
      "  7%|██▊                                     | 427/6100 [05:02<42:11,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:57:36,834 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:57:36,834 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:57:36,834 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.86it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6854416131973267, 'eval_accuracy': 0.7565597667638484, 'eval_runtime': 4.5136, 'eval_samples_per_second': 151.986, 'eval_steps_per_second': 2.437, 'epoch': 7.0}\n",
      "  7%|██▊                                     | 427/6100 [05:06<42:11,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:57:41,348 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-427\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:57:41,349 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-427/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:57:41,449 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-427/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:57:41,449 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-427/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:57:41,622 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-244] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6838, 'learning_rate': 1.859016393442623e-05, 'epoch': 7.05}         \n",
      "{'loss': 0.6719, 'learning_rate': 1.855737704918033e-05, 'epoch': 7.21}         \n",
      "{'loss': 0.6638, 'learning_rate': 1.852459016393443e-05, 'epoch': 7.38}         \n",
      "{'loss': 0.6892, 'learning_rate': 1.8491803278688527e-05, 'epoch': 7.54}        \n",
      "{'loss': 0.7475, 'learning_rate': 1.8459016393442624e-05, 'epoch': 7.7}         \n",
      "{'loss': 0.6778, 'learning_rate': 1.842622950819672e-05, 'epoch': 7.87}         \n",
      "  8%|███▏                                    | 488/6100 [05:46<41:17,  2.26it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:58:20,413 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:58:20,413 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:58:20,413 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7305585145950317, 'eval_accuracy': 0.7448979591836735, 'eval_runtime': 4.6274, 'eval_samples_per_second': 148.247, 'eval_steps_per_second': 2.377, 'epoch': 8.0}\n",
      "  8%|███▏                                    | 488/6100 [05:50<41:17,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.21it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:58:25,041 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-488\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:58:25,041 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-488/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:58:25,135 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-488/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:58:25,135 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-488/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:58:25,307 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-305] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6859, 'learning_rate': 1.8393442622950822e-05, 'epoch': 8.03}        \n",
      "{'loss': 0.6963, 'learning_rate': 1.836065573770492e-05, 'epoch': 8.2}          \n",
      "{'loss': 0.709, 'learning_rate': 1.832786885245902e-05, 'epoch': 8.36}          \n",
      "{'loss': 0.6761, 'learning_rate': 1.8295081967213114e-05, 'epoch': 8.52}        \n",
      "{'loss': 0.7133, 'learning_rate': 1.8262295081967215e-05, 'epoch': 8.69}        \n",
      "{'loss': 0.658, 'learning_rate': 1.8229508196721312e-05, 'epoch': 8.85}         \n",
      "  9%|███▌                                    | 549/6100 [06:30<41:24,  2.23it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:59:04,895 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:59:04,895 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:59:04,895 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7032317519187927, 'eval_accuracy': 0.7653061224489796, 'eval_runtime': 4.5617, 'eval_samples_per_second': 150.381, 'eval_steps_per_second': 2.411, 'epoch': 9.0}\n",
      "  9%|███▌                                    | 549/6100 [06:35<41:24,  2.23it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.26it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:59:09,457 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-549\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:59:09,458 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-549/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:59:09,572 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-549/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:59:09,573 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-549/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:59:09,744 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-366] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6425, 'learning_rate': 1.8196721311475413e-05, 'epoch': 9.02}        \n",
      "{'loss': 0.6712, 'learning_rate': 1.816393442622951e-05, 'epoch': 9.18}         \n",
      "{'loss': 0.6717, 'learning_rate': 1.8131147540983608e-05, 'epoch': 9.34}        \n",
      "{'loss': 0.6685, 'learning_rate': 1.8098360655737705e-05, 'epoch': 9.51}        \n",
      "{'loss': 0.6573, 'learning_rate': 1.8065573770491806e-05, 'epoch': 9.67}        \n",
      "{'loss': 0.7201, 'learning_rate': 1.8032786885245903e-05, 'epoch': 9.84}        \n",
      "{'loss': 0.6632, 'learning_rate': 1.8e-05, 'epoch': 10.0}                       \n",
      " 10%|████                                    | 610/6100 [07:12<40:22,  2.27it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 10:59:47,317 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 10:59:47,317 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 10:59:47,317 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.61it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6931466460227966, 'eval_accuracy': 0.750728862973761, 'eval_runtime': 4.5501, 'eval_samples_per_second': 150.765, 'eval_steps_per_second': 2.418, 'epoch': 10.0}\n",
      " 10%|████                                    | 610/6100 [07:17<40:22,  2.27it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 10:59:51,867 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-610\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 10:59:51,868 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-610/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 10:59:51,979 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-610/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 10:59:51,979 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-610/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 10:59:52,157 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-488] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6148, 'learning_rate': 1.79672131147541e-05, 'epoch': 10.16}         \n",
      "{'loss': 0.657, 'learning_rate': 1.79344262295082e-05, 'epoch': 10.33}          \n",
      "{'loss': 0.7044, 'learning_rate': 1.7901639344262296e-05, 'epoch': 10.49}       \n",
      "{'loss': 0.705, 'learning_rate': 1.7868852459016393e-05, 'epoch': 10.66}        \n",
      "{'loss': 0.6902, 'learning_rate': 1.7836065573770494e-05, 'epoch': 10.82}       \n",
      "{'loss': 0.5992, 'learning_rate': 1.780327868852459e-05, 'epoch': 10.98}        \n",
      " 11%|████▍                                   | 671/6100 [07:55<41:27,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:00:30,283 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:00:30,283 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:00:30,283 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.12it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  2.89it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.18it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.93it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.85it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6813398003578186, 'eval_accuracy': 0.7711370262390671, 'eval_runtime': 5.6431, 'eval_samples_per_second': 121.564, 'eval_steps_per_second': 1.949, 'epoch': 11.0}\n",
      " 11%|████▍                                   | 671/6100 [08:01<41:27,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:00:35,927 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-671\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:00:35,928 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-671/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:00:36,093 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-671/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:00:36,094 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-671/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:00:36,331 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-427] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6503, 'learning_rate': 1.7770491803278692e-05, 'epoch': 11.15}       \n",
      "{'loss': 0.6548, 'learning_rate': 1.7737704918032786e-05, 'epoch': 11.31}       \n",
      "{'loss': 0.6744, 'learning_rate': 1.7704918032786887e-05, 'epoch': 11.48}       \n",
      "{'loss': 0.6925, 'learning_rate': 1.7672131147540984e-05, 'epoch': 11.64}       \n",
      "{'loss': 0.6363, 'learning_rate': 1.7639344262295085e-05, 'epoch': 11.8}        \n",
      "{'loss': 0.6592, 'learning_rate': 1.7606557377049182e-05, 'epoch': 11.97}       \n",
      " 12%|████▊                                   | 732/6100 [08:39<42:38,  2.10it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:01:14,174 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:01:14,175 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:01:14,175 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.91it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7134054899215698, 'eval_accuracy': 0.7580174927113703, 'eval_runtime': 6.2485, 'eval_samples_per_second': 109.787, 'eval_steps_per_second': 1.76, 'epoch': 12.0}\n",
      " 12%|████▊                                   | 732/6100 [08:46<42:38,  2.10it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.82it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:01:20,423 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-732\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:01:20,424 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-732/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:01:20,581 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-732/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:01:20,581 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-732/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:01:20,820 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-549] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6432, 'learning_rate': 1.757377049180328e-05, 'epoch': 12.13}        \n",
      "{'loss': 0.6366, 'learning_rate': 1.7540983606557377e-05, 'epoch': 12.3}        \n",
      "{'loss': 0.5383, 'learning_rate': 1.7508196721311478e-05, 'epoch': 12.46}       \n",
      "{'loss': 0.7322, 'learning_rate': 1.7475409836065575e-05, 'epoch': 12.62}       \n",
      "{'loss': 0.6816, 'learning_rate': 1.7442622950819676e-05, 'epoch': 12.79}       \n",
      "{'loss': 0.644, 'learning_rate': 1.740983606557377e-05, 'epoch': 12.95}         \n",
      " 13%|█████▏                                  | 793/6100 [09:24<48:22,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:01:59,040 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:01:59,040 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:01:59,040 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.26it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.04it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.88it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.78it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.73it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.749139130115509, 'eval_accuracy': 0.7448979591836735, 'eval_runtime': 6.3614, 'eval_samples_per_second': 107.838, 'eval_steps_per_second': 1.729, 'epoch': 13.0}\n",
      " 13%|█████▏                                  | 793/6100 [09:31<48:22,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:02:05,402 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-793\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:02:05,403 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-793/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:02:05,573 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-793/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:02:05,573 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-793/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2887] 2023-10-05 11:02:05,815 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-610] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.645, 'learning_rate': 1.737704918032787e-05, 'epoch': 13.11}         \n",
      "{'loss': 0.7113, 'learning_rate': 1.7344262295081968e-05, 'epoch': 13.28}       \n",
      "{'loss': 0.639, 'learning_rate': 1.731147540983607e-05, 'epoch': 13.44}         \n",
      "{'loss': 0.6368, 'learning_rate': 1.7278688524590166e-05, 'epoch': 13.61}       \n",
      "{'loss': 0.6327, 'learning_rate': 1.7245901639344263e-05, 'epoch': 13.77}       \n",
      "{'loss': 0.6375, 'learning_rate': 1.721311475409836e-05, 'epoch': 13.93}        \n",
      " 14%|█████▌                                  | 854/6100 [10:09<47:37,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:02:43,893 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:02:43,893 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:02:43,893 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.32it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.98it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6627798080444336, 'eval_accuracy': 0.7755102040816326, 'eval_runtime': 6.1545, 'eval_samples_per_second': 111.464, 'eval_steps_per_second': 1.787, 'epoch': 14.0}\n",
      " 14%|█████▌                                  | 854/6100 [10:15<47:37,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.61it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:02:50,052 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-854\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:02:50,052 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-854/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:02:50,163 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-854/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:02:50,163 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-854/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:02:50,334 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-671] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6408, 'learning_rate': 1.718032786885246e-05, 'epoch': 14.1}         \n",
      "{'loss': 0.6163, 'learning_rate': 1.714754098360656e-05, 'epoch': 14.26}        \n",
      "{'loss': 0.6445, 'learning_rate': 1.711475409836066e-05, 'epoch': 14.43}        \n",
      "{'loss': 0.546, 'learning_rate': 1.7081967213114757e-05, 'epoch': 14.59}        \n",
      "{'loss': 0.6634, 'learning_rate': 1.7049180327868854e-05, 'epoch': 14.75}       \n",
      "{'loss': 0.6647, 'learning_rate': 1.701639344262295e-05, 'epoch': 14.92}        \n",
      " 15%|██████                                  | 915/6100 [10:53<47:19,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:03:28,312 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:03:28,312 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:03:28,312 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.48it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.51it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.91it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.03it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.12it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6642076969146729, 'eval_accuracy': 0.7653061224489796, 'eval_runtime': 5.6675, 'eval_samples_per_second': 121.041, 'eval_steps_per_second': 1.941, 'epoch': 15.0}\n",
      " 15%|██████                                  | 915/6100 [10:59<47:19,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.30it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:03:33,980 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-915\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:03:33,981 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-915/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:03:34,092 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-915/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:03:34,093 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-915/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:03:34,265 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-732] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6758, 'learning_rate': 1.6983606557377052e-05, 'epoch': 15.08}       \n",
      "{'loss': 0.6539, 'learning_rate': 1.695081967213115e-05, 'epoch': 15.25}        \n",
      "{'loss': 0.6676, 'learning_rate': 1.6918032786885247e-05, 'epoch': 15.41}       \n",
      "{'loss': 0.6727, 'learning_rate': 1.6885245901639347e-05, 'epoch': 15.57}       \n",
      "{'loss': 0.6073, 'learning_rate': 1.6852459016393445e-05, 'epoch': 15.74}       \n",
      "{'loss': 0.5287, 'learning_rate': 1.6819672131147542e-05, 'epoch': 15.9}        \n",
      " 16%|██████▍                                 | 976/6100 [11:38<46:28,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:04:12,647 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:04:12,647 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:04:12,647 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.34it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.95it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6936697363853455, 'eval_accuracy': 0.7594752186588921, 'eval_runtime': 5.9229, 'eval_samples_per_second': 115.822, 'eval_steps_per_second': 1.857, 'epoch': 16.0}\n",
      " 16%|██████▍                                 | 976/6100 [11:44<46:28,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.16it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:04:18,571 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-976\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:04:18,571 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-976/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:04:18,688 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-976/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:04:18,688 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-976/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:04:18,862 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-793] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6628, 'learning_rate': 1.678688524590164e-05, 'epoch': 16.07}        \n",
      "{'loss': 0.5829, 'learning_rate': 1.675409836065574e-05, 'epoch': 16.23}        \n",
      "{'loss': 0.6365, 'learning_rate': 1.6721311475409837e-05, 'epoch': 16.39}       \n",
      "{'loss': 0.5584, 'learning_rate': 1.6688524590163935e-05, 'epoch': 16.56}       \n",
      "{'loss': 0.599, 'learning_rate': 1.6655737704918032e-05, 'epoch': 16.72}        \n",
      "{'loss': 0.6539, 'learning_rate': 1.6622950819672133e-05, 'epoch': 16.89}       \n",
      " 17%|██████▋                                | 1037/6100 [12:21<39:17,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:04:56,338 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:04:56,338 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:04:56,338 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.02it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7726086378097534, 'eval_accuracy': 0.7274052478134111, 'eval_runtime': 4.5247, 'eval_samples_per_second': 151.612, 'eval_steps_per_second': 2.431, 'epoch': 17.0}\n",
      " 17%|██████▋                                | 1037/6100 [12:26<39:17,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.26it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:05:00,866 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1037\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:05:00,867 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1037/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:05:00,985 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1037/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:05:00,985 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1037/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:05:01,161 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-915] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7035, 'learning_rate': 1.659016393442623e-05, 'epoch': 17.05}        \n",
      "{'loss': 0.6077, 'learning_rate': 1.655737704918033e-05, 'epoch': 17.21}        \n",
      "{'loss': 0.5819, 'learning_rate': 1.6524590163934428e-05, 'epoch': 17.38}       \n",
      "{'loss': 0.6376, 'learning_rate': 1.6491803278688526e-05, 'epoch': 17.54}       \n",
      "{'loss': 0.5908, 'learning_rate': 1.6459016393442623e-05, 'epoch': 17.7}        \n",
      "{'loss': 0.646, 'learning_rate': 1.6426229508196724e-05, 'epoch': 17.87}        \n",
      " 18%|███████                                | 1098/6100 [13:05<36:57,  2.26it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:05:39,735 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:05:39,736 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:05:39,736 >>   Batch size = 64\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.87it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.99it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.72it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.67it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6681326627731323, 'eval_accuracy': 0.7623906705539358, 'eval_runtime': 4.4328, 'eval_samples_per_second': 154.754, 'eval_steps_per_second': 2.481, 'epoch': 18.0}\n",
      " 18%|███████                                | 1098/6100 [13:09<36:57,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.29it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:05:44,169 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1098\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:05:44,170 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1098/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:05:44,289 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1098/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:05:44,290 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1098/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:05:44,464 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-976] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6099, 'learning_rate': 1.639344262295082e-05, 'epoch': 18.03}        \n",
      "{'loss': 0.5724, 'learning_rate': 1.6360655737704922e-05, 'epoch': 18.2}        \n",
      "{'loss': 0.6181, 'learning_rate': 1.6327868852459016e-05, 'epoch': 18.36}       \n",
      "{'loss': 0.6081, 'learning_rate': 1.6295081967213116e-05, 'epoch': 18.52}       \n",
      "{'loss': 0.5945, 'learning_rate': 1.6262295081967214e-05, 'epoch': 18.69}       \n",
      "{'loss': 0.596, 'learning_rate': 1.6229508196721314e-05, 'epoch': 18.85}        \n",
      " 19%|███████▍                               | 1159/6100 [13:49<36:50,  2.23it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:06:23,505 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:06:23,505 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:06:23,505 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.61it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6835081577301025, 'eval_accuracy': 0.7682215743440233, 'eval_runtime': 4.5629, 'eval_samples_per_second': 150.342, 'eval_steps_per_second': 2.411, 'epoch': 19.0}\n",
      " 19%|███████▍                               | 1159/6100 [13:53<36:50,  2.23it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:06:28,068 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1159\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:06:28,069 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1159/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:06:28,184 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1159/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:06:28,184 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1159/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:06:28,357 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1037] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.579, 'learning_rate': 1.6196721311475412e-05, 'epoch': 19.02}        \n",
      "{'loss': 0.5579, 'learning_rate': 1.616393442622951e-05, 'epoch': 19.18}        \n",
      "{'loss': 0.5964, 'learning_rate': 1.6131147540983607e-05, 'epoch': 19.34}       \n",
      "{'loss': 0.5415, 'learning_rate': 1.6098360655737707e-05, 'epoch': 19.51}       \n",
      "{'loss': 0.5681, 'learning_rate': 1.6065573770491805e-05, 'epoch': 19.67}       \n",
      "{'loss': 0.6273, 'learning_rate': 1.6032786885245902e-05, 'epoch': 19.84}       \n",
      "{'loss': 0.6465, 'learning_rate': 1.6000000000000003e-05, 'epoch': 20.0}        \n",
      " 20%|███████▊                               | 1220/6100 [14:31<36:25,  2.23it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:07:06,089 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:07:06,089 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:07:06,089 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.61it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6684462428092957, 'eval_accuracy': 0.7638483965014577, 'eval_runtime': 4.4871, 'eval_samples_per_second': 152.881, 'eval_steps_per_second': 2.451, 'epoch': 20.0}\n",
      " 20%|███████▊                               | 1220/6100 [14:36<36:25,  2.23it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.26it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:07:10,576 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1220\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:07:10,577 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1220/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:07:10,681 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1220/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:07:10,682 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1220/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:07:10,862 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1098] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.568, 'learning_rate': 1.59672131147541e-05, 'epoch': 20.16}          \n",
      "{'loss': 0.5878, 'learning_rate': 1.5934426229508197e-05, 'epoch': 20.33}       \n",
      "{'loss': 0.583, 'learning_rate': 1.5901639344262295e-05, 'epoch': 20.49}        \n",
      "{'loss': 0.5904, 'learning_rate': 1.5868852459016395e-05, 'epoch': 20.66}       \n",
      "{'loss': 0.586, 'learning_rate': 1.5836065573770493e-05, 'epoch': 20.82}        \n",
      "{'loss': 0.6038, 'learning_rate': 1.580327868852459e-05, 'epoch': 20.98}        \n",
      " 21%|████████▏                              | 1281/6100 [15:16<36:00,  2.23it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:07:50,357 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:07:50,357 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:07:50,357 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6998137831687927, 'eval_accuracy': 0.7594752186588921, 'eval_runtime': 4.5792, 'eval_samples_per_second': 149.808, 'eval_steps_per_second': 2.402, 'epoch': 21.0}\n",
      " 21%|████████▏                              | 1281/6100 [15:20<36:00,  2.23it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:07:54,937 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1281\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:07:54,938 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1281/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:07:55,055 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1281/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:07:55,056 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1281/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:07:55,230 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1159] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5801, 'learning_rate': 1.5770491803278687e-05, 'epoch': 21.15}       \n",
      "{'loss': 0.5046, 'learning_rate': 1.5737704918032788e-05, 'epoch': 21.31}       \n",
      "{'loss': 0.571, 'learning_rate': 1.5704918032786886e-05, 'epoch': 21.48}        \n",
      "{'loss': 0.6188, 'learning_rate': 1.5672131147540986e-05, 'epoch': 21.64}       \n",
      "{'loss': 0.5636, 'learning_rate': 1.5639344262295084e-05, 'epoch': 21.8}        \n",
      "{'loss': 0.6216, 'learning_rate': 1.560655737704918e-05, 'epoch': 21.97}        \n",
      " 22%|████████▌                              | 1342/6100 [15:59<35:15,  2.25it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:08:34,223 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:08:34,223 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:08:34,223 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.61it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.79it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.61it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6936958432197571, 'eval_accuracy': 0.7463556851311953, 'eval_runtime': 4.6013, 'eval_samples_per_second': 149.087, 'eval_steps_per_second': 2.391, 'epoch': 22.0}\n",
      " 22%|████████▌                              | 1342/6100 [16:04<35:15,  2.25it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:08:38,825 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1342\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:08:38,826 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1342/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:08:38,944 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1342/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:08:38,944 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1342/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:08:39,120 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1220] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6034, 'learning_rate': 1.5573770491803278e-05, 'epoch': 22.13}       \n",
      "{'loss': 0.5656, 'learning_rate': 1.554098360655738e-05, 'epoch': 22.3}         \n",
      "{'loss': 0.5321, 'learning_rate': 1.5508196721311476e-05, 'epoch': 22.46}       \n",
      "{'loss': 0.5885, 'learning_rate': 1.5475409836065577e-05, 'epoch': 22.62}       \n",
      "{'loss': 0.5436, 'learning_rate': 1.544262295081967e-05, 'epoch': 22.79}        \n",
      "{'loss': 0.5965, 'learning_rate': 1.5409836065573772e-05, 'epoch': 22.95}       \n",
      " 23%|████████▉                              | 1403/6100 [16:43<35:12,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:09:17,511 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:09:17,511 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:09:17,511 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.76it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.42it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.32it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.33it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7467820644378662, 'eval_accuracy': 0.7361516034985423, 'eval_runtime': 4.7142, 'eval_samples_per_second': 145.519, 'eval_steps_per_second': 2.333, 'epoch': 23.0}\n",
      " 23%|████████▉                              | 1403/6100 [16:47<35:12,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:09:22,225 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1403\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:09:22,227 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1403/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:09:22,385 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1403/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:09:22,385 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1403/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:09:22,624 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1281] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5781, 'learning_rate': 1.537704918032787e-05, 'epoch': 23.11}        \n",
      "{'loss': 0.5212, 'learning_rate': 1.534426229508197e-05, 'epoch': 23.28}        \n",
      "{'loss': 0.6403, 'learning_rate': 1.5311475409836067e-05, 'epoch': 23.44}       \n",
      "{'loss': 0.5398, 'learning_rate': 1.5278688524590165e-05, 'epoch': 23.61}       \n",
      "{'loss': 0.5204, 'learning_rate': 1.5245901639344264e-05, 'epoch': 23.77}       \n",
      "{'loss': 0.5652, 'learning_rate': 1.5213114754098361e-05, 'epoch': 23.93}       \n",
      " 24%|█████████▎                             | 1464/6100 [17:26<34:57,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:10:00,853 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:10:00,854 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:10:00,854 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.19it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.04it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.86it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8158206343650818, 'eval_accuracy': 0.7215743440233237, 'eval_runtime': 6.0935, 'eval_samples_per_second': 112.578, 'eval_steps_per_second': 1.805, 'epoch': 24.0}\n",
      " 24%|█████████▎                             | 1464/6100 [17:32<34:57,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:10:06,948 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1464\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:10:06,949 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1464/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:10:07,119 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1464/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:10:07,119 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1464/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:10:07,360 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1342] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5275, 'learning_rate': 1.518032786885246e-05, 'epoch': 24.1}         \n",
      "{'loss': 0.5569, 'learning_rate': 1.5147540983606559e-05, 'epoch': 24.26}       \n",
      "{'loss': 0.5236, 'learning_rate': 1.5114754098360658e-05, 'epoch': 24.43}       \n",
      "{'loss': 0.6061, 'learning_rate': 1.5081967213114754e-05, 'epoch': 24.59}       \n",
      "{'loss': 0.5667, 'learning_rate': 1.5049180327868853e-05, 'epoch': 24.75}       \n",
      "{'loss': 0.5392, 'learning_rate': 1.5016393442622952e-05, 'epoch': 24.92}       \n",
      " 25%|█████████▊                             | 1525/6100 [18:10<41:24,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:10:45,269 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:10:45,269 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:10:45,269 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8241699934005737, 'eval_accuracy': 0.7157434402332361, 'eval_runtime': 6.2003, 'eval_samples_per_second': 110.639, 'eval_steps_per_second': 1.774, 'epoch': 25.0}\n",
      " 25%|█████████▊                             | 1525/6100 [18:17<41:24,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:10:51,470 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1525\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:10:51,471 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1525/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:10:51,625 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1525/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:10:51,625 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1525/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:10:51,871 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1403] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5364, 'learning_rate': 1.498360655737705e-05, 'epoch': 25.08}        \n",
      "{'loss': 0.5425, 'learning_rate': 1.495081967213115e-05, 'epoch': 25.25}        \n",
      "{'loss': 0.5736, 'learning_rate': 1.4918032786885249e-05, 'epoch': 25.41}       \n",
      "{'loss': 0.4988, 'learning_rate': 1.4885245901639344e-05, 'epoch': 25.57}       \n",
      "{'loss': 0.5123, 'learning_rate': 1.4852459016393443e-05, 'epoch': 25.74}       \n",
      "{'loss': 0.5597, 'learning_rate': 1.4819672131147543e-05, 'epoch': 25.9}        \n",
      " 26%|██████████▏                            | 1586/6100 [18:55<40:52,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:11:29,836 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:11:29,837 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:11:29,837 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.60it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6968361735343933, 'eval_accuracy': 0.749271137026239, 'eval_runtime': 6.1708, 'eval_samples_per_second': 111.168, 'eval_steps_per_second': 1.783, 'epoch': 26.0}\n",
      " 26%|██████████▏                            | 1586/6100 [19:01<40:52,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:11:36,008 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1586\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:11:36,009 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1586/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:11:36,176 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1586/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:11:36,177 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1586/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:11:36,418 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1464] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5711, 'learning_rate': 1.4786885245901642e-05, 'epoch': 26.07}       \n",
      "{'loss': 0.4975, 'learning_rate': 1.4754098360655739e-05, 'epoch': 26.23}       \n",
      "{'loss': 0.5105, 'learning_rate': 1.4721311475409836e-05, 'epoch': 26.39}       \n",
      "{'loss': 0.5366, 'learning_rate': 1.4688524590163935e-05, 'epoch': 26.56}       \n",
      "{'loss': 0.5614, 'learning_rate': 1.4655737704918034e-05, 'epoch': 26.72}       \n",
      "{'loss': 0.5921, 'learning_rate': 1.4622950819672133e-05, 'epoch': 26.89}       \n",
      " 27%|██████████▌                            | 1647/6100 [19:40<40:42,  1.82it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:12:14,851 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:12:14,851 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:12:14,851 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.61it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.48it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.83it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.717595636844635, 'eval_accuracy': 0.739067055393586, 'eval_runtime': 6.1321, 'eval_samples_per_second': 111.87, 'eval_steps_per_second': 1.794, 'epoch': 27.0}\n",
      " 27%|██████████▌                            | 1647/6100 [19:46<40:42,  1.82it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:12:20,990 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1647\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:12:20,992 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1647/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:12:21,130 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1647/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:12:21,130 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1647/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:12:21,371 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1525] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.592, 'learning_rate': 1.459016393442623e-05, 'epoch': 27.05}         \n",
      "{'loss': 0.5201, 'learning_rate': 1.455737704918033e-05, 'epoch': 27.21}        \n",
      "{'loss': 0.5336, 'learning_rate': 1.4524590163934427e-05, 'epoch': 27.38}       \n",
      "{'loss': 0.4907, 'learning_rate': 1.4491803278688526e-05, 'epoch': 27.54}       \n",
      "{'loss': 0.5865, 'learning_rate': 1.4459016393442623e-05, 'epoch': 27.7}        \n",
      "{'loss': 0.5735, 'learning_rate': 1.4426229508196722e-05, 'epoch': 27.87}       \n",
      " 28%|██████████▉                            | 1708/6100 [20:24<39:53,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:12:59,324 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:12:59,324 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:12:59,324 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.55it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7071985006332397, 'eval_accuracy': 0.7623906705539358, 'eval_runtime': 6.1165, 'eval_samples_per_second': 112.155, 'eval_steps_per_second': 1.798, 'epoch': 28.0}\n",
      " 28%|██████████▉                            | 1708/6100 [20:31<39:53,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:13:05,442 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1708\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:13:05,443 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1708/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:13:05,596 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1708/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:13:05,597 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1708/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:13:05,837 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1586] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4858, 'learning_rate': 1.4393442622950822e-05, 'epoch': 28.03}       \n",
      "{'loss': 0.503, 'learning_rate': 1.4360655737704919e-05, 'epoch': 28.2}         \n",
      "{'loss': 0.4843, 'learning_rate': 1.4327868852459016e-05, 'epoch': 28.36}       \n",
      "{'loss': 0.5777, 'learning_rate': 1.4295081967213115e-05, 'epoch': 28.52}       \n",
      "{'loss': 0.4708, 'learning_rate': 1.4262295081967214e-05, 'epoch': 28.69}       \n",
      "{'loss': 0.5529, 'learning_rate': 1.4229508196721313e-05, 'epoch': 28.85}       \n",
      " 29%|███████████▎                           | 1769/6100 [21:09<39:22,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:13:43,843 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:13:43,843 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:13:43,843 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.65it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.64it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7738497853279114, 'eval_accuracy': 0.7448979591836735, 'eval_runtime': 4.5909, 'eval_samples_per_second': 149.427, 'eval_steps_per_second': 2.396, 'epoch': 29.0}\n",
      " 29%|███████████▎                           | 1769/6100 [21:14<39:22,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:13:48,437 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1769\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:13:48,438 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1769/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:13:48,534 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1769/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:13:48,535 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1769/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:13:48,713 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1647] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5356, 'learning_rate': 1.4196721311475412e-05, 'epoch': 29.02}       \n",
      "{'loss': 0.5172, 'learning_rate': 1.4163934426229508e-05, 'epoch': 29.18}       \n",
      "{'loss': 0.539, 'learning_rate': 1.4131147540983607e-05, 'epoch': 29.34}        \n",
      "{'loss': 0.5739, 'learning_rate': 1.4098360655737706e-05, 'epoch': 29.51}       \n",
      "{'loss': 0.5007, 'learning_rate': 1.4065573770491805e-05, 'epoch': 29.67}       \n",
      "{'loss': 0.5258, 'learning_rate': 1.4032786885245904e-05, 'epoch': 29.84}       \n",
      "{'loss': 0.521, 'learning_rate': 1.4e-05, 'epoch': 30.0}                        \n",
      " 30%|███████████▋                           | 1830/6100 [21:53<35:18,  2.02it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:14:27,452 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:14:27,452 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:14:27,452 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.76it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.98it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.66it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7768164873123169, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 4.4513, 'eval_samples_per_second': 154.113, 'eval_steps_per_second': 2.471, 'epoch': 30.0}\n",
      " 30%|███████████▋                           | 1830/6100 [21:57<35:18,  2.02it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.61it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:14:31,904 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1830\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:14:31,905 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1830/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:14:32,020 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1830/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:14:32,021 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1830/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:14:32,192 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1708] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5034, 'learning_rate': 1.3967213114754099e-05, 'epoch': 30.16}       \n",
      "{'loss': 0.4942, 'learning_rate': 1.3934426229508198e-05, 'epoch': 30.33}       \n",
      "{'loss': 0.4845, 'learning_rate': 1.3901639344262297e-05, 'epoch': 30.49}       \n",
      "{'loss': 0.5562, 'learning_rate': 1.3868852459016396e-05, 'epoch': 30.66}       \n",
      "{'loss': 0.4691, 'learning_rate': 1.3836065573770492e-05, 'epoch': 30.82}       \n",
      "{'loss': 0.5231, 'learning_rate': 1.380327868852459e-05, 'epoch': 30.98}        \n",
      " 31%|████████████                           | 1891/6100 [22:35<31:32,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:15:09,731 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:15:09,731 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:15:09,731 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.63it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.61it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.32it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.735073983669281, 'eval_accuracy': 0.7434402332361516, 'eval_runtime': 4.662, 'eval_samples_per_second': 147.148, 'eval_steps_per_second': 2.36, 'epoch': 31.0}\n",
      " 31%|████████████                           | 1891/6100 [22:40<31:32,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:15:14,393 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1891\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:15:14,394 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1891/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:15:14,508 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1891/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:15:14,509 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1891/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:15:14,681 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1769] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5032, 'learning_rate': 1.377049180327869e-05, 'epoch': 31.15}        \n",
      "{'loss': 0.4704, 'learning_rate': 1.3737704918032789e-05, 'epoch': 31.31}       \n",
      "{'loss': 0.4677, 'learning_rate': 1.3704918032786888e-05, 'epoch': 31.48}       \n",
      "{'loss': 0.5124, 'learning_rate': 1.3672131147540985e-05, 'epoch': 31.64}       \n",
      "{'loss': 0.4776, 'learning_rate': 1.3639344262295082e-05, 'epoch': 31.8}        \n",
      "{'loss': 0.5216, 'learning_rate': 1.3606557377049181e-05, 'epoch': 31.97}       \n",
      " 32%|████████████▍                          | 1952/6100 [23:21<32:35,  2.12it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:15:55,620 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:15:55,620 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:15:55,620 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.80it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.57it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.46it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7305223345756531, 'eval_accuracy': 0.7478134110787172, 'eval_runtime': 4.6016, 'eval_samples_per_second': 149.08, 'eval_steps_per_second': 2.39, 'epoch': 32.0}\n",
      " 32%|████████████▍                          | 1952/6100 [23:25<32:35,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.24it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:16:00,221 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1952\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:16:00,222 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1952/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:16:00,332 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1952/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:16:00,332 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1952/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:16:00,506 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1830] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4766, 'learning_rate': 1.357377049180328e-05, 'epoch': 32.13}        \n",
      "{'loss': 0.5007, 'learning_rate': 1.3540983606557378e-05, 'epoch': 32.3}        \n",
      "{'loss': 0.4725, 'learning_rate': 1.3508196721311477e-05, 'epoch': 32.46}       \n",
      "{'loss': 0.5374, 'learning_rate': 1.3475409836065574e-05, 'epoch': 32.62}       \n",
      "{'loss': 0.4605, 'learning_rate': 1.3442622950819673e-05, 'epoch': 32.79}       \n",
      "{'loss': 0.5046, 'learning_rate': 1.340983606557377e-05, 'epoch': 32.95}        \n",
      " 33%|████████████▊                          | 2013/6100 [24:03<30:43,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:16:38,226 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:16:38,226 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:16:38,226 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.31it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.79it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.35it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8555082678794861, 'eval_accuracy': 0.7142857142857143, 'eval_runtime': 4.6174, 'eval_samples_per_second': 148.568, 'eval_steps_per_second': 2.382, 'epoch': 33.0}\n",
      " 33%|████████████▊                          | 2013/6100 [24:08<30:43,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.25it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:16:42,845 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2013\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:16:42,846 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2013/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:16:42,960 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2013/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:16:42,961 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2013/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:16:43,137 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1891] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4972, 'learning_rate': 1.337704918032787e-05, 'epoch': 33.11}        \n",
      "{'loss': 0.4892, 'learning_rate': 1.3344262295081969e-05, 'epoch': 33.28}       \n",
      "{'loss': 0.5046, 'learning_rate': 1.3311475409836068e-05, 'epoch': 33.44}       \n",
      "{'loss': 0.4796, 'learning_rate': 1.3278688524590165e-05, 'epoch': 33.61}       \n",
      "{'loss': 0.4951, 'learning_rate': 1.3245901639344262e-05, 'epoch': 33.77}       \n",
      "{'loss': 0.5368, 'learning_rate': 1.3213114754098361e-05, 'epoch': 33.93}       \n",
      " 34%|█████████████▎                         | 2074/6100 [24:48<30:13,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:17:22,399 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:17:22,399 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:17:22,399 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.24it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.61it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.50it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7216493487358093, 'eval_accuracy': 0.7419825072886297, 'eval_runtime': 4.563, 'eval_samples_per_second': 150.34, 'eval_steps_per_second': 2.411, 'epoch': 34.0}\n",
      " 34%|█████████████▎                         | 2074/6100 [24:52<30:13,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.31it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:17:26,962 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2074\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:17:26,963 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2074/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:17:27,067 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2074/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:17:27,068 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2074/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:17:27,240 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-1952] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4651, 'learning_rate': 1.318032786885246e-05, 'epoch': 34.1}         \n",
      "{'loss': 0.4862, 'learning_rate': 1.314754098360656e-05, 'epoch': 34.26}        \n",
      "{'loss': 0.4558, 'learning_rate': 1.3114754098360655e-05, 'epoch': 34.43}       \n",
      "{'loss': 0.4153, 'learning_rate': 1.3081967213114754e-05, 'epoch': 34.59}       \n",
      "{'loss': 0.4714, 'learning_rate': 1.3049180327868853e-05, 'epoch': 34.75}       \n",
      "{'loss': 0.4642, 'learning_rate': 1.3016393442622952e-05, 'epoch': 34.92}       \n",
      " 35%|█████████████▋                         | 2135/6100 [25:31<29:33,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:18:05,821 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:18:05,821 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:18:05,821 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.55it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.61it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7861048579216003, 'eval_accuracy': 0.7215743440233237, 'eval_runtime': 4.5359, 'eval_samples_per_second': 151.239, 'eval_steps_per_second': 2.425, 'epoch': 35.0}\n",
      " 35%|█████████████▋                         | 2135/6100 [25:36<29:33,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:18:10,357 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2135\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:18:10,358 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2135/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:18:10,472 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2135/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:18:10,473 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2135/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:18:10,652 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2013] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5068, 'learning_rate': 1.2983606557377051e-05, 'epoch': 35.08}       \n",
      "{'loss': 0.5115, 'learning_rate': 1.295081967213115e-05, 'epoch': 35.25}        \n",
      "{'loss': 0.533, 'learning_rate': 1.2918032786885246e-05, 'epoch': 35.41}        \n",
      "{'loss': 0.4416, 'learning_rate': 1.2885245901639345e-05, 'epoch': 35.57}       \n",
      "{'loss': 0.4056, 'learning_rate': 1.2852459016393444e-05, 'epoch': 35.74}       \n",
      "{'loss': 0.464, 'learning_rate': 1.2819672131147543e-05, 'epoch': 35.9}         \n",
      " 36%|██████████████                         | 2196/6100 [26:15<29:30,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:18:49,890 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:18:49,890 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:18:49,890 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.61it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.70it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.63it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.37it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.30it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7673594355583191, 'eval_accuracy': 0.7623906705539358, 'eval_runtime': 4.5794, 'eval_samples_per_second': 149.802, 'eval_steps_per_second': 2.402, 'epoch': 36.0}\n",
      " 36%|██████████████                         | 2196/6100 [26:20<29:30,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:18:54,470 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2196\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:18:54,470 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2196/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:18:54,581 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2196/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:18:54,582 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2196/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:18:54,759 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2074] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4566, 'learning_rate': 1.2786885245901642e-05, 'epoch': 36.07}       \n",
      "{'loss': 0.4905, 'learning_rate': 1.2754098360655738e-05, 'epoch': 36.23}       \n",
      "{'loss': 0.5113, 'learning_rate': 1.2721311475409837e-05, 'epoch': 36.39}       \n",
      "{'loss': 0.4557, 'learning_rate': 1.2688524590163936e-05, 'epoch': 36.56}       \n",
      "{'loss': 0.4944, 'learning_rate': 1.2655737704918035e-05, 'epoch': 36.72}       \n",
      "{'loss': 0.4565, 'learning_rate': 1.2622950819672132e-05, 'epoch': 36.89}       \n",
      " 37%|██████████████▍                        | 2257/6100 [26:59<29:12,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:19:33,492 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:19:33,492 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:19:33,492 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.55it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.23it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.62it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7902303338050842, 'eval_accuracy': 0.7244897959183674, 'eval_runtime': 4.7112, 'eval_samples_per_second': 145.611, 'eval_steps_per_second': 2.335, 'epoch': 37.0}\n",
      " 37%|██████████████▍                        | 2257/6100 [27:03<29:12,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.29it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:19:38,204 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2257\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:19:38,205 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2257/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:19:38,368 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2257/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:19:38,369 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2257/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:19:38,609 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2135] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4989, 'learning_rate': 1.2590163934426231e-05, 'epoch': 37.05}       \n",
      "{'loss': 0.4666, 'learning_rate': 1.2557377049180329e-05, 'epoch': 37.21}       \n",
      "{'loss': 0.4696, 'learning_rate': 1.2524590163934428e-05, 'epoch': 37.38}       \n",
      "{'loss': 0.4788, 'learning_rate': 1.2491803278688525e-05, 'epoch': 37.54}       \n",
      "{'loss': 0.4467, 'learning_rate': 1.2459016393442624e-05, 'epoch': 37.7}        \n",
      "{'loss': 0.4599, 'learning_rate': 1.2426229508196723e-05, 'epoch': 37.87}       \n",
      " 38%|██████████████▊                        | 2318/6100 [27:44<27:54,  2.26it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:20:18,767 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:20:18,767 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:20:18,767 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.92it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.59it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.46it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.34it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7883281111717224, 'eval_accuracy': 0.7332361516034985, 'eval_runtime': 4.5839, 'eval_samples_per_second': 149.654, 'eval_steps_per_second': 2.4, 'epoch': 38.0}\n",
      " 38%|██████████████▊                        | 2318/6100 [27:48<27:54,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.23it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:20:23,351 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2318\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:20:23,352 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2318/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:20:23,466 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2318/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:20:23,467 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2318/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:20:23,646 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2196] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4365, 'learning_rate': 1.239344262295082e-05, 'epoch': 38.03}        \n",
      "{'loss': 0.413, 'learning_rate': 1.236065573770492e-05, 'epoch': 38.2}          \n",
      "{'loss': 0.4246, 'learning_rate': 1.2327868852459017e-05, 'epoch': 38.36}       \n",
      "{'loss': 0.4633, 'learning_rate': 1.2295081967213116e-05, 'epoch': 38.52}       \n",
      "{'loss': 0.453, 'learning_rate': 1.2262295081967215e-05, 'epoch': 38.69}        \n",
      "{'loss': 0.5127, 'learning_rate': 1.2229508196721312e-05, 'epoch': 38.85}       \n",
      " 39%|███████████████▏                       | 2379/6100 [28:28<27:42,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:21:02,605 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:21:02,605 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:21:02,605 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.37it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.75it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.57it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.47it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7405622601509094, 'eval_accuracy': 0.7536443148688047, 'eval_runtime': 4.6482, 'eval_samples_per_second': 147.584, 'eval_steps_per_second': 2.366, 'epoch': 39.0}\n",
      " 39%|███████████████▏                       | 2379/6100 [28:32<27:42,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:21:07,257 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2379\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:21:07,258 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2379/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:21:07,373 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2379/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:21:07,374 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2379/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:21:07,552 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2257] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4864, 'learning_rate': 1.219672131147541e-05, 'epoch': 39.02}        \n",
      "{'loss': 0.4244, 'learning_rate': 1.2163934426229509e-05, 'epoch': 39.18}       \n",
      "{'loss': 0.4589, 'learning_rate': 1.2131147540983608e-05, 'epoch': 39.34}       \n",
      "{'loss': 0.4422, 'learning_rate': 1.2098360655737707e-05, 'epoch': 39.51}       \n",
      "{'loss': 0.454, 'learning_rate': 1.2065573770491806e-05, 'epoch': 39.67}        \n",
      "{'loss': 0.441, 'learning_rate': 1.2032786885245901e-05, 'epoch': 39.84}        \n",
      "{'loss': 0.4542, 'learning_rate': 1.2e-05, 'epoch': 40.0}                       \n",
      " 40%|███████████████▌                       | 2440/6100 [29:12<27:09,  2.25it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:21:46,381 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:21:46,381 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:21:46,381 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.87it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.58it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.47it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.35it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.33it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7666367292404175, 'eval_accuracy': 0.7478134110787172, 'eval_runtime': 4.7265, 'eval_samples_per_second': 145.138, 'eval_steps_per_second': 2.327, 'epoch': 40.0}\n",
      " 40%|███████████████▌                       | 2440/6100 [29:16<27:09,  2.25it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.33it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:21:51,108 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2440\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:21:51,109 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2440/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:21:51,256 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2440/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:21:51,257 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2440/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:21:51,499 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2318] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.419, 'learning_rate': 1.19672131147541e-05, 'epoch': 40.16}          \n",
      "{'loss': 0.4153, 'learning_rate': 1.1934426229508198e-05, 'epoch': 40.33}       \n",
      "{'loss': 0.3961, 'learning_rate': 1.1901639344262297e-05, 'epoch': 40.49}       \n",
      "{'loss': 0.416, 'learning_rate': 1.1868852459016393e-05, 'epoch': 40.66}        \n",
      "{'loss': 0.41, 'learning_rate': 1.1836065573770492e-05, 'epoch': 40.82}         \n",
      "{'loss': 0.4636, 'learning_rate': 1.1803278688524591e-05, 'epoch': 40.98}       \n",
      " 41%|███████████████▉                       | 2501/6100 [29:55<27:10,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:22:30,238 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:22:30,238 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:22:30,238 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.40it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.11it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.95it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.87it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.85it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7770470976829529, 'eval_accuracy': 0.7565597667638484, 'eval_runtime': 5.5237, 'eval_samples_per_second': 124.193, 'eval_steps_per_second': 1.991, 'epoch': 41.0}\n",
      " 41%|███████████████▉                       | 2501/6100 [30:01<27:10,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.59it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:22:35,763 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2501\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:22:35,764 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2501/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:22:35,925 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2501/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:22:35,926 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2501/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:22:36,167 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2379] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4335, 'learning_rate': 1.177049180327869e-05, 'epoch': 41.15}        \n",
      "{'loss': 0.3741, 'learning_rate': 1.173770491803279e-05, 'epoch': 41.31}        \n",
      "{'loss': 0.4606, 'learning_rate': 1.1704918032786887e-05, 'epoch': 41.48}       \n",
      "{'loss': 0.4405, 'learning_rate': 1.1672131147540984e-05, 'epoch': 41.64}       \n",
      "{'loss': 0.4473, 'learning_rate': 1.1639344262295083e-05, 'epoch': 41.8}        \n",
      "{'loss': 0.4258, 'learning_rate': 1.1606557377049182e-05, 'epoch': 41.97}       \n",
      " 42%|████████████████▍                      | 2562/6100 [30:40<26:17,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:23:14,700 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:23:14,700 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:23:14,700 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.27it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.07it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.94it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.88it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.805391252040863, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 5.5141, 'eval_samples_per_second': 124.408, 'eval_steps_per_second': 1.995, 'epoch': 42.0}\n",
      " 42%|████████████████▍                      | 2562/6100 [30:45<26:17,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:23:20,215 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2562\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:23:20,216 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2562/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:23:20,377 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2562/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:23:20,378 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2562/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:23:20,620 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2440] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3916, 'learning_rate': 1.157377049180328e-05, 'epoch': 42.13}        \n",
      "{'loss': 0.4428, 'learning_rate': 1.1540983606557378e-05, 'epoch': 42.3}        \n",
      "{'loss': 0.4313, 'learning_rate': 1.1508196721311476e-05, 'epoch': 42.46}       \n",
      "{'loss': 0.4248, 'learning_rate': 1.1475409836065575e-05, 'epoch': 42.62}       \n",
      "{'loss': 0.408, 'learning_rate': 1.1442622950819672e-05, 'epoch': 42.79}        \n",
      "{'loss': 0.4098, 'learning_rate': 1.1409836065573771e-05, 'epoch': 42.95}       \n",
      " 43%|████████████████▊                      | 2623/6100 [31:24<30:03,  1.93it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:23:58,834 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:23:58,834 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:23:58,834 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.48it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.09it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.90it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7986352443695068, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 6.2314, 'eval_samples_per_second': 110.087, 'eval_steps_per_second': 1.765, 'epoch': 43.0}\n",
      " 43%|████████████████▊                      | 2623/6100 [31:30<30:03,  1.93it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:24:05,066 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2623\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:24:05,067 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2623/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:24:05,235 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2623/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:24:05,235 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2623/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:24:05,478 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2501] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4078, 'learning_rate': 1.137704918032787e-05, 'epoch': 43.11}        \n",
      "{'loss': 0.3855, 'learning_rate': 1.134426229508197e-05, 'epoch': 43.28}        \n",
      "{'loss': 0.4309, 'learning_rate': 1.1311475409836066e-05, 'epoch': 43.44}       \n",
      "{'loss': 0.4398, 'learning_rate': 1.1278688524590164e-05, 'epoch': 43.61}       \n",
      "{'loss': 0.3806, 'learning_rate': 1.1245901639344263e-05, 'epoch': 43.77}       \n",
      "{'loss': 0.4383, 'learning_rate': 1.1213114754098362e-05, 'epoch': 43.93}       \n",
      " 44%|█████████████████▏                     | 2684/6100 [32:09<31:07,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:24:43,625 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:24:43,625 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:24:43,625 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.89it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.77it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.72it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8318210244178772, 'eval_accuracy': 0.7128279883381924, 'eval_runtime': 6.3674, 'eval_samples_per_second': 107.736, 'eval_steps_per_second': 1.728, 'epoch': 44.0}\n",
      " 44%|█████████████████▏                     | 2684/6100 [32:15<31:07,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:24:49,992 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2684\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:24:49,993 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2684/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:24:50,150 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2684/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:24:50,151 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2684/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:24:50,401 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2562] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4091, 'learning_rate': 1.1180327868852461e-05, 'epoch': 44.1}        \n",
      "{'loss': 0.4468, 'learning_rate': 1.1147540983606557e-05, 'epoch': 44.26}       \n",
      "{'loss': 0.4388, 'learning_rate': 1.1114754098360656e-05, 'epoch': 44.43}       \n",
      "{'loss': 0.4199, 'learning_rate': 1.1081967213114755e-05, 'epoch': 44.59}       \n",
      "{'loss': 0.418, 'learning_rate': 1.1049180327868854e-05, 'epoch': 44.75}        \n",
      "{'loss': 0.4004, 'learning_rate': 1.1016393442622953e-05, 'epoch': 44.92}       \n",
      " 45%|█████████████████▌                     | 2745/6100 [32:54<30:40,  1.82it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:25:28,614 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:25:28,614 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:25:28,614 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.90it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.89it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.01it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.09it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8402919769287109, 'eval_accuracy': 0.7128279883381924, 'eval_runtime': 5.7509, 'eval_samples_per_second': 119.285, 'eval_steps_per_second': 1.913, 'epoch': 45.0}\n",
      " 45%|█████████████████▌                     | 2745/6100 [33:00<30:40,  1.82it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.29it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:25:34,365 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2745\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:25:34,366 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2745/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:25:34,470 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2745/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:25:34,470 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2745/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:25:34,644 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2623] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3934, 'learning_rate': 1.0983606557377052e-05, 'epoch': 45.08}       \n",
      "{'loss': 0.3803, 'learning_rate': 1.0950819672131147e-05, 'epoch': 45.25}       \n",
      "{'loss': 0.4272, 'learning_rate': 1.0918032786885246e-05, 'epoch': 45.41}       \n",
      "{'loss': 0.4761, 'learning_rate': 1.0885245901639345e-05, 'epoch': 45.57}       \n",
      "{'loss': 0.4658, 'learning_rate': 1.0852459016393445e-05, 'epoch': 45.74}       \n",
      "{'loss': 0.3804, 'learning_rate': 1.0819672131147544e-05, 'epoch': 45.9}        \n",
      " 46%|█████████████████▉                     | 2806/6100 [33:38<26:25,  2.08it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:26:12,626 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:26:12,626 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:26:12,626 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.76it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.75it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.56it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.46it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.32it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8252285718917847, 'eval_accuracy': 0.7259475218658892, 'eval_runtime': 4.6179, 'eval_samples_per_second': 148.552, 'eval_steps_per_second': 2.382, 'epoch': 46.0}\n",
      " 46%|█████████████████▉                     | 2806/6100 [33:42<26:25,  2.08it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:26:17,244 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2806\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:26:17,245 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2806/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:26:17,341 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2806/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:26:17,341 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2806/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:26:17,521 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2684] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4381, 'learning_rate': 1.078688524590164e-05, 'epoch': 46.07}        \n",
      "{'loss': 0.4522, 'learning_rate': 1.0754098360655738e-05, 'epoch': 46.23}       \n",
      "{'loss': 0.4635, 'learning_rate': 1.0721311475409837e-05, 'epoch': 46.39}       \n",
      "{'loss': 0.4041, 'learning_rate': 1.0688524590163936e-05, 'epoch': 46.56}       \n",
      "{'loss': 0.3826, 'learning_rate': 1.0655737704918034e-05, 'epoch': 46.72}       \n",
      "{'loss': 0.3926, 'learning_rate': 1.0622950819672131e-05, 'epoch': 46.89}       \n",
      " 47%|██████████████████▎                    | 2867/6100 [34:22<24:40,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:26:56,366 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:26:56,366 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:26:56,366 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.66it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.84it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7999632358551025, 'eval_accuracy': 0.7521865889212828, 'eval_runtime': 4.5247, 'eval_samples_per_second': 151.612, 'eval_steps_per_second': 2.431, 'epoch': 47.0}\n",
      " 47%|██████████████████▎                    | 2867/6100 [34:26<24:40,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.31it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:27:00,891 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2867\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:27:00,892 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2867/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:27:01,010 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2867/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:27:01,011 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2867/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:27:01,183 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2745] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4197, 'learning_rate': 1.059016393442623e-05, 'epoch': 47.05}        \n",
      "{'loss': 0.4276, 'learning_rate': 1.0557377049180329e-05, 'epoch': 47.21}       \n",
      "{'loss': 0.3867, 'learning_rate': 1.0524590163934426e-05, 'epoch': 47.38}       \n",
      "{'loss': 0.4179, 'learning_rate': 1.0491803278688525e-05, 'epoch': 47.54}       \n",
      "{'loss': 0.4248, 'learning_rate': 1.0459016393442624e-05, 'epoch': 47.7}        \n",
      "{'loss': 0.3984, 'learning_rate': 1.0426229508196722e-05, 'epoch': 47.87}       \n",
      " 48%|██████████████████▋                    | 2928/6100 [35:05<23:34,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:27:40,109 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:27:40,109 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:27:40,109 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.86it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8309954404830933, 'eval_accuracy': 0.739067055393586, 'eval_runtime': 4.5033, 'eval_samples_per_second': 152.332, 'eval_steps_per_second': 2.443, 'epoch': 48.0}\n",
      " 48%|██████████████████▋                    | 2928/6100 [35:10<23:34,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:27:44,617 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2928\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:27:44,618 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2928/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:27:44,735 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2928/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:27:44,736 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2928/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:27:44,911 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2806] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4373, 'learning_rate': 1.0393442622950821e-05, 'epoch': 48.03}       \n",
      "{'loss': 0.4259, 'learning_rate': 1.0360655737704918e-05, 'epoch': 48.2}        \n",
      "{'loss': 0.4007, 'learning_rate': 1.0327868852459017e-05, 'epoch': 48.36}       \n",
      "{'loss': 0.3917, 'learning_rate': 1.0295081967213116e-05, 'epoch': 48.52}       \n",
      "{'loss': 0.361, 'learning_rate': 1.0262295081967214e-05, 'epoch': 48.69}        \n",
      "{'loss': 0.3722, 'learning_rate': 1.0229508196721311e-05, 'epoch': 48.85}       \n",
      " 49%|███████████████████                    | 2989/6100 [35:48<23:24,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:28:22,852 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:28:22,852 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:28:22,852 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.57it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.32it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8150638341903687, 'eval_accuracy': 0.7288629737609329, 'eval_runtime': 4.6817, 'eval_samples_per_second': 146.528, 'eval_steps_per_second': 2.35, 'epoch': 49.0}\n",
      " 49%|███████████████████                    | 2989/6100 [35:53<23:24,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.14it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:28:27,541 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2989\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:28:27,542 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2989/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:28:27,656 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2989/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:28:27,657 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2989/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:28:27,838 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2867] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3992, 'learning_rate': 1.019672131147541e-05, 'epoch': 49.02}        \n",
      "{'loss': 0.3904, 'learning_rate': 1.0163934426229509e-05, 'epoch': 49.18}       \n",
      "{'loss': 0.3402, 'learning_rate': 1.0131147540983608e-05, 'epoch': 49.34}       \n",
      "{'loss': 0.3632, 'learning_rate': 1.0098360655737707e-05, 'epoch': 49.51}       \n",
      "{'loss': 0.4187, 'learning_rate': 1.0065573770491803e-05, 'epoch': 49.67}       \n",
      "{'loss': 0.4249, 'learning_rate': 1.0032786885245902e-05, 'epoch': 49.84}       \n",
      "{'loss': 0.3508, 'learning_rate': 1e-05, 'epoch': 50.0}                         \n",
      " 50%|███████████████████▌                   | 3050/6100 [36:34<22:41,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:29:08,676 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:29:08,676 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:29:08,676 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.36it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.23it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8219510316848755, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 4.4833, 'eval_samples_per_second': 153.014, 'eval_steps_per_second': 2.454, 'epoch': 50.0}\n",
      " 50%|███████████████████▌                   | 3050/6100 [36:38<22:41,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.36it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:29:13,159 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3050\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:29:13,160 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3050/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:29:13,263 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3050/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:29:13,264 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3050/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:29:13,439 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2928] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3491, 'learning_rate': 9.9672131147541e-06, 'epoch': 50.16}          \n",
      "{'loss': 0.4095, 'learning_rate': 9.934426229508197e-06, 'epoch': 50.33}        \n",
      "{'loss': 0.3615, 'learning_rate': 9.901639344262296e-06, 'epoch': 50.49}        \n",
      "{'loss': 0.4136, 'learning_rate': 9.868852459016395e-06, 'epoch': 50.66}        \n",
      "{'loss': 0.3886, 'learning_rate': 9.836065573770493e-06, 'epoch': 50.82}        \n",
      "{'loss': 0.4361, 'learning_rate': 9.803278688524592e-06, 'epoch': 50.98}        \n",
      " 51%|███████████████████▉                   | 3111/6100 [37:17<22:02,  2.26it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:29:51,694 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:29:51,694 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:29:51,694 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.62it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.32it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.27it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8708795309066772, 'eval_accuracy': 0.7230320699708455, 'eval_runtime': 4.6659, 'eval_samples_per_second': 147.024, 'eval_steps_per_second': 2.358, 'epoch': 51.0}\n",
      " 51%|███████████████████▉                   | 3111/6100 [37:22<22:02,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:29:56,360 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3111\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:29:56,361 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3111/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:29:56,476 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3111/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:29:56,476 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3111/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:29:56,652 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-2989] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3252, 'learning_rate': 9.770491803278689e-06, 'epoch': 51.15}        \n",
      "{'loss': 0.3668, 'learning_rate': 9.737704918032788e-06, 'epoch': 51.31}        \n",
      "{'loss': 0.4262, 'learning_rate': 9.704918032786887e-06, 'epoch': 51.48}        \n",
      "{'loss': 0.3628, 'learning_rate': 9.672131147540984e-06, 'epoch': 51.64}        \n",
      "{'loss': 0.3633, 'learning_rate': 9.639344262295083e-06, 'epoch': 51.8}         \n",
      "{'loss': 0.4063, 'learning_rate': 9.60655737704918e-06, 'epoch': 51.97}         \n",
      " 52%|████████████████████▎                  | 3172/6100 [38:02<22:05,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:30:36,579 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:30:36,579 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:30:36,579 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.57it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.56it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.45it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8324378728866577, 'eval_accuracy': 0.7317784256559767, 'eval_runtime': 4.6171, 'eval_samples_per_second': 148.578, 'eval_steps_per_second': 2.382, 'epoch': 52.0}\n",
      " 52%|████████████████████▎                  | 3172/6100 [38:06<22:05,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:30:41,197 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3172\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:30:41,198 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3172/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:30:41,309 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3172/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:30:41,310 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3172/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:30:41,486 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3050] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3573, 'learning_rate': 9.57377049180328e-06, 'epoch': 52.13}         \n",
      "{'loss': 0.3786, 'learning_rate': 9.540983606557377e-06, 'epoch': 52.3}         \n",
      "{'loss': 0.4439, 'learning_rate': 9.508196721311476e-06, 'epoch': 52.46}        \n",
      "{'loss': 0.3491, 'learning_rate': 9.475409836065575e-06, 'epoch': 52.62}        \n",
      "{'loss': 0.401, 'learning_rate': 9.442622950819673e-06, 'epoch': 52.79}         \n",
      "{'loss': 0.4128, 'learning_rate': 9.409836065573772e-06, 'epoch': 52.95}        \n",
      " 53%|████████████████████▋                  | 3233/6100 [38:45<21:14,  2.25it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:31:19,916 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:31:19,916 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:31:19,916 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.33it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8466668725013733, 'eval_accuracy': 0.717201166180758, 'eval_runtime': 4.5217, 'eval_samples_per_second': 151.714, 'eval_steps_per_second': 2.433, 'epoch': 53.0}\n",
      " 53%|████████████████████▋                  | 3233/6100 [38:50<21:14,  2.25it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:31:24,439 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3233\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:31:24,439 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3233/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:31:24,560 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3233/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:31:24,560 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3233/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:31:24,734 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3111] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3695, 'learning_rate': 9.377049180327869e-06, 'epoch': 53.11}        \n",
      "{'loss': 0.3492, 'learning_rate': 9.344262295081968e-06, 'epoch': 53.28}        \n",
      "{'loss': 0.3485, 'learning_rate': 9.311475409836065e-06, 'epoch': 53.44}        \n",
      "{'loss': 0.3444, 'learning_rate': 9.278688524590164e-06, 'epoch': 53.61}        \n",
      "{'loss': 0.3744, 'learning_rate': 9.245901639344263e-06, 'epoch': 53.77}        \n",
      "{'loss': 0.3751, 'learning_rate': 9.21311475409836e-06, 'epoch': 53.93}         \n",
      " 54%|█████████████████████                  | 3294/6100 [39:28<20:51,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:32:03,171 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:32:03,171 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:32:03,171 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.53it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.19it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8244989514350891, 'eval_accuracy': 0.739067055393586, 'eval_runtime': 4.6479, 'eval_samples_per_second': 147.593, 'eval_steps_per_second': 2.367, 'epoch': 54.0}\n",
      " 54%|█████████████████████                  | 3294/6100 [39:33<20:51,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:32:07,822 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3294\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:32:07,823 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3294/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:32:07,938 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3294/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:32:07,939 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3294/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:32:08,117 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3172] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3763, 'learning_rate': 9.18032786885246e-06, 'epoch': 54.1}          \n",
      "{'loss': 0.3563, 'learning_rate': 9.147540983606557e-06, 'epoch': 54.26}        \n",
      "{'loss': 0.3493, 'learning_rate': 9.114754098360656e-06, 'epoch': 54.43}        \n",
      "{'loss': 0.3869, 'learning_rate': 9.081967213114755e-06, 'epoch': 54.59}        \n",
      "{'loss': 0.4186, 'learning_rate': 9.049180327868853e-06, 'epoch': 54.75}        \n",
      "{'loss': 0.3891, 'learning_rate': 9.016393442622952e-06, 'epoch': 54.92}        \n",
      " 55%|█████████████████████▍                 | 3355/6100 [40:11<20:44,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:32:46,285 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:32:46,285 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:32:46,285 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.79it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.28it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.09it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:02,  1.99it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.91it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8620901107788086, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 5.3766, 'eval_samples_per_second': 127.591, 'eval_steps_per_second': 2.046, 'epoch': 55.0}\n",
      " 55%|█████████████████████▍                 | 3355/6100 [40:17<20:44,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.95it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:32:51,662 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3355\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:32:51,663 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3355/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:32:51,822 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3355/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:32:51,822 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3355/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:32:52,071 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3233] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3397, 'learning_rate': 8.98360655737705e-06, 'epoch': 55.08}         \n",
      "{'loss': 0.391, 'learning_rate': 8.950819672131148e-06, 'epoch': 55.25}         \n",
      "{'loss': 0.3421, 'learning_rate': 8.918032786885247e-06, 'epoch': 55.41}        \n",
      "{'loss': 0.3616, 'learning_rate': 8.885245901639346e-06, 'epoch': 55.57}        \n",
      "{'loss': 0.3421, 'learning_rate': 8.852459016393443e-06, 'epoch': 55.74}        \n",
      "{'loss': 0.3704, 'learning_rate': 8.819672131147542e-06, 'epoch': 55.9}         \n",
      " 56%|█████████████████████▊                 | 3416/6100 [40:55<21:03,  2.12it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:33:30,105 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:33:30,105 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:33:30,105 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.40it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.04it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.90it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.84it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.904141902923584, 'eval_accuracy': 0.7099125364431487, 'eval_runtime': 6.2754, 'eval_samples_per_second': 109.315, 'eval_steps_per_second': 1.753, 'epoch': 56.0}\n",
      " 56%|█████████████████████▊                 | 3416/6100 [41:02<21:03,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:33:36,381 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3416\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:33:36,382 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3416/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:33:36,542 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3416/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:33:36,543 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3416/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:33:36,797 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3294] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3929, 'learning_rate': 8.78688524590164e-06, 'epoch': 56.07}         \n",
      "{'loss': 0.3451, 'learning_rate': 8.754098360655739e-06, 'epoch': 56.23}        \n",
      "{'loss': 0.2977, 'learning_rate': 8.721311475409838e-06, 'epoch': 56.39}        \n",
      "{'loss': 0.3695, 'learning_rate': 8.688524590163935e-06, 'epoch': 56.56}        \n",
      "{'loss': 0.3715, 'learning_rate': 8.655737704918034e-06, 'epoch': 56.72}        \n",
      "{'loss': 0.4031, 'learning_rate': 8.622950819672132e-06, 'epoch': 56.89}        \n",
      " 57%|██████████████████████▏                | 3477/6100 [41:40<23:14,  1.88it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:34:14,630 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:34:14,630 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:34:14,630 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8747921586036682, 'eval_accuracy': 0.7201166180758017, 'eval_runtime': 6.1221, 'eval_samples_per_second': 112.053, 'eval_steps_per_second': 1.797, 'epoch': 57.0}\n",
      " 57%|██████████████████████▏                | 3477/6100 [41:46<23:14,  1.88it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:34:20,753 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3477\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:34:20,754 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3477/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:34:20,911 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3477/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:34:20,912 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3477/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:34:21,156 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3355] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3769, 'learning_rate': 8.59016393442623e-06, 'epoch': 57.05}         \n",
      "{'loss': 0.4111, 'learning_rate': 8.55737704918033e-06, 'epoch': 57.21}         \n",
      "{'loss': 0.361, 'learning_rate': 8.524590163934427e-06, 'epoch': 57.38}         \n",
      "{'loss': 0.2979, 'learning_rate': 8.491803278688526e-06, 'epoch': 57.54}        \n",
      "{'loss': 0.3648, 'learning_rate': 8.459016393442623e-06, 'epoch': 57.7}         \n",
      "{'loss': 0.3753, 'learning_rate': 8.426229508196722e-06, 'epoch': 57.87}        \n",
      " 58%|██████████████████████▌                | 3538/6100 [42:24<23:14,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:34:59,283 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:34:59,283 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:34:59,283 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.51it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.860503613948822, 'eval_accuracy': 0.7419825072886297, 'eval_runtime': 6.2064, 'eval_samples_per_second': 110.531, 'eval_steps_per_second': 1.772, 'epoch': 58.0}\n",
      " 58%|██████████████████████▌                | 3538/6100 [42:31<23:14,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:35:05,490 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3538\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:35:05,492 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3538/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:35:05,656 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3538/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:35:05,656 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3538/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:35:05,900 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3416] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3788, 'learning_rate': 8.39344262295082e-06, 'epoch': 58.03}         \n",
      "{'loss': 0.3441, 'learning_rate': 8.360655737704919e-06, 'epoch': 58.2}         \n",
      "{'loss': 0.3974, 'learning_rate': 8.327868852459016e-06, 'epoch': 58.36}        \n",
      "{'loss': 0.3091, 'learning_rate': 8.295081967213115e-06, 'epoch': 58.52}        \n",
      "{'loss': 0.3186, 'learning_rate': 8.262295081967214e-06, 'epoch': 58.69}        \n",
      "{'loss': 0.3756, 'learning_rate': 8.229508196721311e-06, 'epoch': 58.85}        \n",
      " 59%|███████████████████████                | 3599/6100 [43:09<22:20,  1.87it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:35:43,929 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:35:43,929 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:35:43,929 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.58it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.17it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8338270783424377, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 6.1442, 'eval_samples_per_second': 111.65, 'eval_steps_per_second': 1.79, 'epoch': 59.0}\n",
      " 59%|███████████████████████                | 3599/6100 [43:15<22:20,  1.87it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:35:50,074 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3599\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:35:50,075 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3599/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:35:50,229 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3599/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:35:50,229 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3599/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:35:50,472 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3477] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3691, 'learning_rate': 8.19672131147541e-06, 'epoch': 59.02}         \n",
      "{'loss': 0.3209, 'learning_rate': 8.163934426229508e-06, 'epoch': 59.18}        \n",
      "{'loss': 0.3587, 'learning_rate': 8.131147540983607e-06, 'epoch': 59.34}        \n",
      "{'loss': 0.4045, 'learning_rate': 8.098360655737706e-06, 'epoch': 59.51}        \n",
      "{'loss': 0.383, 'learning_rate': 8.065573770491803e-06, 'epoch': 59.67}         \n",
      "{'loss': 0.3638, 'learning_rate': 8.032786885245902e-06, 'epoch': 59.84}        \n",
      "{'loss': 0.3344, 'learning_rate': 8.000000000000001e-06, 'epoch': 60.0}         \n",
      " 60%|███████████████████████▍               | 3660/6100 [43:54<22:11,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:36:28,626 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:36:28,626 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:36:28,626 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.51it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8544891476631165, 'eval_accuracy': 0.7259475218658892, 'eval_runtime': 6.2159, 'eval_samples_per_second': 110.363, 'eval_steps_per_second': 1.77, 'epoch': 60.0}\n",
      " 60%|███████████████████████▍               | 3660/6100 [44:00<22:11,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:36:34,842 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3660\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:36:34,844 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3660/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:36:35,009 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3660/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:36:35,009 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3660/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:36:35,252 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3538] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3476, 'learning_rate': 7.967213114754099e-06, 'epoch': 60.16}        \n",
      "{'loss': 0.3623, 'learning_rate': 7.934426229508198e-06, 'epoch': 60.33}        \n",
      "{'loss': 0.335, 'learning_rate': 7.901639344262295e-06, 'epoch': 60.49}         \n",
      "{'loss': 0.3339, 'learning_rate': 7.868852459016394e-06, 'epoch': 60.66}        \n",
      "{'loss': 0.3368, 'learning_rate': 7.836065573770493e-06, 'epoch': 60.82}        \n",
      "{'loss': 0.3559, 'learning_rate': 7.80327868852459e-06, 'epoch': 60.98}         \n",
      " 61%|███████████████████████▊               | 3721/6100 [44:38<21:24,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:37:13,099 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:37:13,099 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:37:13,099 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8848073482513428, 'eval_accuracy': 0.7303206997084548, 'eval_runtime': 6.1962, 'eval_samples_per_second': 110.713, 'eval_steps_per_second': 1.775, 'epoch': 61.0}\n",
      " 61%|███████████████████████▊               | 3721/6100 [44:44<21:24,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:37:19,296 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3721\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:37:19,298 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3721/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:37:19,463 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3721/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:37:19,464 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3721/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:37:19,711 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3599] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2811, 'learning_rate': 7.77049180327869e-06, 'epoch': 61.15}         \n",
      "{'loss': 0.3334, 'learning_rate': 7.737704918032789e-06, 'epoch': 61.31}        \n",
      "{'loss': 0.3849, 'learning_rate': 7.704918032786886e-06, 'epoch': 61.48}        \n",
      "{'loss': 0.3375, 'learning_rate': 7.672131147540985e-06, 'epoch': 61.64}        \n",
      "{'loss': 0.3503, 'learning_rate': 7.639344262295082e-06, 'epoch': 61.8}         \n",
      "{'loss': 0.3869, 'learning_rate': 7.6065573770491804e-06, 'epoch': 61.97}       \n",
      " 62%|████████████████████████▏              | 3782/6100 [45:23<20:58,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:37:57,748 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:37:57,748 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:37:57,748 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.56it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.16it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8383070230484009, 'eval_accuracy': 0.7332361516034985, 'eval_runtime': 6.1558, 'eval_samples_per_second': 111.439, 'eval_steps_per_second': 1.787, 'epoch': 62.0}\n",
      " 62%|████████████████████████▏              | 3782/6100 [45:29<20:58,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:38:03,904 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3782\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:38:03,905 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3782/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:38:04,072 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3782/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:38:04,072 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3782/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:38:04,314 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3660] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3349, 'learning_rate': 7.5737704918032795e-06, 'epoch': 62.13}       \n",
      "{'loss': 0.3192, 'learning_rate': 7.540983606557377e-06, 'epoch': 62.3}         \n",
      "{'loss': 0.2872, 'learning_rate': 7.508196721311476e-06, 'epoch': 62.46}        \n",
      "{'loss': 0.3349, 'learning_rate': 7.475409836065575e-06, 'epoch': 62.62}        \n",
      "{'loss': 0.3481, 'learning_rate': 7.442622950819672e-06, 'epoch': 62.79}        \n",
      "{'loss': 0.3498, 'learning_rate': 7.409836065573771e-06, 'epoch': 62.95}        \n",
      " 63%|████████████████████████▌              | 3843/6100 [46:08<20:21,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:38:42,428 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:38:42,428 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:38:42,428 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.90it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.82it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8613824248313904, 'eval_accuracy': 0.7434402332361516, 'eval_runtime': 6.3059, 'eval_samples_per_second': 108.787, 'eval_steps_per_second': 1.744, 'epoch': 63.0}\n",
      " 63%|████████████████████████▌              | 3843/6100 [46:14<20:21,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:38:48,735 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3843\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:38:48,735 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3843/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:38:48,891 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3843/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:38:48,892 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3843/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:38:49,138 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3721] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3437, 'learning_rate': 7.3770491803278695e-06, 'epoch': 63.11}       \n",
      "{'loss': 0.2896, 'learning_rate': 7.344262295081968e-06, 'epoch': 63.28}        \n",
      "{'loss': 0.2923, 'learning_rate': 7.311475409836067e-06, 'epoch': 63.44}        \n",
      "{'loss': 0.342, 'learning_rate': 7.278688524590165e-06, 'epoch': 63.61}         \n",
      "{'loss': 0.2971, 'learning_rate': 7.245901639344263e-06, 'epoch': 63.77}        \n",
      "{'loss': 0.3274, 'learning_rate': 7.213114754098361e-06, 'epoch': 63.93}        \n",
      " 64%|████████████████████████▉              | 3904/6100 [46:52<20:15,  1.81it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:39:27,140 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:39:27,140 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:39:27,140 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.62it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8730121850967407, 'eval_accuracy': 0.7317784256559767, 'eval_runtime': 4.7028, 'eval_samples_per_second': 145.87, 'eval_steps_per_second': 2.339, 'epoch': 64.0}\n",
      " 64%|████████████████████████▉              | 3904/6100 [46:57<20:15,  1.81it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.58it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:39:31,844 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3904\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:39:31,844 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3904/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:39:31,955 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3904/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:39:31,955 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3904/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:39:32,127 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3782] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3889, 'learning_rate': 7.1803278688524594e-06, 'epoch': 64.1}        \n",
      "{'loss': 0.3324, 'learning_rate': 7.147540983606558e-06, 'epoch': 64.26}        \n",
      "{'loss': 0.3371, 'learning_rate': 7.114754098360657e-06, 'epoch': 64.43}        \n",
      "{'loss': 0.3302, 'learning_rate': 7.081967213114754e-06, 'epoch': 64.59}        \n",
      "{'loss': 0.3169, 'learning_rate': 7.049180327868853e-06, 'epoch': 64.75}        \n",
      "{'loss': 0.3455, 'learning_rate': 7.016393442622952e-06, 'epoch': 64.92}        \n",
      " 65%|█████████████████████████▎             | 3965/6100 [47:36<19:18,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:40:11,093 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:40:11,093 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:40:11,093 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.93it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:01,  2.06it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.18it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.23it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8942492008209229, 'eval_accuracy': 0.7274052478134111, 'eval_runtime': 5.542, 'eval_samples_per_second': 123.781, 'eval_steps_per_second': 1.985, 'epoch': 65.0}\n",
      " 65%|█████████████████████████▎             | 3965/6100 [47:42<19:18,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.12it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:40:16,635 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3965\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:40:16,636 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3965/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:40:16,741 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3965/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:40:16,741 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3965/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:40:16,921 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3843] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3342, 'learning_rate': 6.983606557377049e-06, 'epoch': 65.08}        \n",
      "{'loss': 0.3288, 'learning_rate': 6.9508196721311484e-06, 'epoch': 65.25}       \n",
      "{'loss': 0.3495, 'learning_rate': 6.918032786885246e-06, 'epoch': 65.41}        \n",
      "{'loss': 0.3144, 'learning_rate': 6.885245901639345e-06, 'epoch': 65.57}        \n",
      "{'loss': 0.3169, 'learning_rate': 6.852459016393444e-06, 'epoch': 65.74}        \n",
      "{'loss': 0.2868, 'learning_rate': 6.819672131147541e-06, 'epoch': 65.9}         \n",
      " 66%|█████████████████████████▋             | 4026/6100 [48:21<18:42,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:40:55,467 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:40:55,467 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:40:55,467 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.92it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8524314165115356, 'eval_accuracy': 0.7434402332361516, 'eval_runtime': 6.1367, 'eval_samples_per_second': 111.786, 'eval_steps_per_second': 1.792, 'epoch': 66.0}\n",
      " 66%|█████████████████████████▋             | 4026/6100 [48:27<18:42,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:41:01,604 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4026\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:41:01,605 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4026/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:41:01,764 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4026/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:41:01,764 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4026/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:41:02,009 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3904] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3064, 'learning_rate': 6.78688524590164e-06, 'epoch': 66.07}         \n",
      "{'loss': 0.3249, 'learning_rate': 6.7540983606557384e-06, 'epoch': 66.23}       \n",
      "{'loss': 0.3848, 'learning_rate': 6.721311475409837e-06, 'epoch': 66.39}        \n",
      "{'loss': 0.3252, 'learning_rate': 6.688524590163935e-06, 'epoch': 66.56}        \n",
      "{'loss': 0.2911, 'learning_rate': 6.655737704918034e-06, 'epoch': 66.72}        \n",
      "{'loss': 0.3142, 'learning_rate': 6.622950819672131e-06, 'epoch': 66.89}        \n",
      " 67%|██████████████████████████▏            | 4087/6100 [49:05<18:39,  1.80it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:41:40,321 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:41:40,322 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:41:40,322 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.62it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.54it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.21it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8631618618965149, 'eval_accuracy': 0.7434402332361516, 'eval_runtime': 6.1555, 'eval_samples_per_second': 111.446, 'eval_steps_per_second': 1.787, 'epoch': 67.0}\n",
      " 67%|██████████████████████████▏            | 4087/6100 [49:12<18:39,  1.80it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:41:46,477 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4087\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:41:46,478 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4087/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:41:46,641 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4087/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:41:46,641 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4087/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:41:46,893 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-3965] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3677, 'learning_rate': 6.59016393442623e-06, 'epoch': 67.05}         \n",
      "{'loss': 0.3179, 'learning_rate': 6.5573770491803276e-06, 'epoch': 67.21}       \n",
      "{'loss': 0.3181, 'learning_rate': 6.524590163934427e-06, 'epoch': 67.38}        \n",
      "{'loss': 0.3584, 'learning_rate': 6.491803278688526e-06, 'epoch': 67.54}        \n",
      "{'loss': 0.2699, 'learning_rate': 6.459016393442623e-06, 'epoch': 67.7}         \n",
      "{'loss': 0.3281, 'learning_rate': 6.426229508196722e-06, 'epoch': 67.87}        \n",
      " 68%|██████████████████████████▌            | 4148/6100 [49:50<17:30,  1.86it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:42:24,664 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:42:24,664 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:42:24,664 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  1.98it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.87it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.78it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8761858940124512, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 6.3634, 'eval_samples_per_second': 107.804, 'eval_steps_per_second': 1.729, 'epoch': 68.0}\n",
      " 68%|██████████████████████████▌            | 4148/6100 [49:56<17:30,  1.86it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:42:31,028 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4148\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:42:31,030 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4148/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:42:31,188 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4148/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:42:31,189 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4148/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:42:31,434 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4026] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2961, 'learning_rate': 6.393442622950821e-06, 'epoch': 68.03}        \n",
      "{'loss': 0.3038, 'learning_rate': 6.360655737704918e-06, 'epoch': 68.2}         \n",
      "{'loss': 0.299, 'learning_rate': 6.327868852459017e-06, 'epoch': 68.36}         \n",
      "{'loss': 0.363, 'learning_rate': 6.295081967213116e-06, 'epoch': 68.52}         \n",
      "{'loss': 0.329, 'learning_rate': 6.262295081967214e-06, 'epoch': 68.69}         \n",
      "{'loss': 0.3373, 'learning_rate': 6.229508196721312e-06, 'epoch': 68.85}        \n",
      " 69%|██████████████████████████▉            | 4209/6100 [50:34<16:59,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:43:09,139 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:43:09,139 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:43:09,139 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.58it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.841492772102356, 'eval_accuracy': 0.7361516034985423, 'eval_runtime': 6.1941, 'eval_samples_per_second': 110.751, 'eval_steps_per_second': 1.776, 'epoch': 69.0}\n",
      " 69%|██████████████████████████▉            | 4209/6100 [50:40<16:59,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:43:15,333 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4209\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:43:15,335 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4209/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:43:15,496 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4209/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:43:15,496 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4209/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:43:15,748 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4087] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2996, 'learning_rate': 6.19672131147541e-06, 'epoch': 69.02}         \n",
      "{'loss': 0.2837, 'learning_rate': 6.163934426229508e-06, 'epoch': 69.18}        \n",
      "{'loss': 0.2889, 'learning_rate': 6.131147540983607e-06, 'epoch': 69.34}        \n",
      "{'loss': 0.3062, 'learning_rate': 6.098360655737705e-06, 'epoch': 69.51}        \n",
      "{'loss': 0.3068, 'learning_rate': 6.065573770491804e-06, 'epoch': 69.67}        \n",
      "{'loss': 0.2907, 'learning_rate': 6.032786885245903e-06, 'epoch': 69.84}        \n",
      "{'loss': 0.3292, 'learning_rate': 6e-06, 'epoch': 70.0}                         \n",
      " 70%|███████████████████████████▎           | 4270/6100 [51:19<16:31,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:43:53,672 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:43:53,672 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:43:53,672 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  2.00it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8581226468086243, 'eval_accuracy': 0.7317784256559767, 'eval_runtime': 6.1843, 'eval_samples_per_second': 110.926, 'eval_steps_per_second': 1.779, 'epoch': 70.0}\n",
      " 70%|███████████████████████████▎           | 4270/6100 [51:25<16:31,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:43:59,861 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4270\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:43:59,862 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4270/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:44:00,018 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4270/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:44:00,019 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4270/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:44:00,270 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4148] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2827, 'learning_rate': 5.967213114754099e-06, 'epoch': 70.16}        \n",
      "{'loss': 0.3202, 'learning_rate': 5.9344262295081965e-06, 'epoch': 70.33}       \n",
      "{'loss': 0.3359, 'learning_rate': 5.9016393442622956e-06, 'epoch': 70.49}       \n",
      "{'loss': 0.3035, 'learning_rate': 5.868852459016395e-06, 'epoch': 70.66}        \n",
      "{'loss': 0.3629, 'learning_rate': 5.836065573770492e-06, 'epoch': 70.82}        \n",
      "{'loss': 0.2835, 'learning_rate': 5.803278688524591e-06, 'epoch': 70.98}        \n",
      " 71%|███████████████████████████▋           | 4331/6100 [52:03<16:18,  1.81it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:44:38,329 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:44:38,329 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:44:38,329 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.95it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:01,  2.06it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.10it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.17it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9290258884429932, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 5.6338, 'eval_samples_per_second': 121.765, 'eval_steps_per_second': 1.952, 'epoch': 71.0}\n",
      " 71%|███████████████████████████▋           | 4331/6100 [52:09<16:18,  1.81it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.06it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:44:43,964 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4331\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:44:43,964 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4331/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:44:44,069 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4331/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:44:44,070 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4331/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:44:44,245 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4209] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3107, 'learning_rate': 5.770491803278689e-06, 'epoch': 71.15}        \n",
      "{'loss': 0.3221, 'learning_rate': 5.737704918032787e-06, 'epoch': 71.31}        \n",
      "{'loss': 0.3035, 'learning_rate': 5.7049180327868855e-06, 'epoch': 71.48}       \n",
      "{'loss': 0.2979, 'learning_rate': 5.672131147540985e-06, 'epoch': 71.64}        \n",
      "{'loss': 0.2728, 'learning_rate': 5.639344262295082e-06, 'epoch': 71.8}         \n",
      "{'loss': 0.3465, 'learning_rate': 5.606557377049181e-06, 'epoch': 71.97}        \n",
      " 72%|████████████████████████████           | 4392/6100 [52:48<15:42,  1.81it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:45:22,913 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:45:22,913 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:45:22,913 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.15it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.73it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8802815079689026, 'eval_accuracy': 0.7376093294460642, 'eval_runtime': 6.2522, 'eval_samples_per_second': 109.721, 'eval_steps_per_second': 1.759, 'epoch': 72.0}\n",
      " 72%|████████████████████████████           | 4392/6100 [52:54<15:42,  1.81it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:45:29,166 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4392\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:45:29,167 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4392/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:45:29,329 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4392/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:45:29,330 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4392/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:45:29,576 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4270] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3192, 'learning_rate': 5.573770491803278e-06, 'epoch': 72.13}        \n",
      "{'loss': 0.3254, 'learning_rate': 5.540983606557377e-06, 'epoch': 72.3}         \n",
      "{'loss': 0.3033, 'learning_rate': 5.508196721311476e-06, 'epoch': 72.46}        \n",
      "{'loss': 0.3033, 'learning_rate': 5.475409836065574e-06, 'epoch': 72.62}        \n",
      "{'loss': 0.3145, 'learning_rate': 5.442622950819673e-06, 'epoch': 72.79}        \n",
      "{'loss': 0.315, 'learning_rate': 5.409836065573772e-06, 'epoch': 72.95}         \n",
      " 73%|████████████████████████████▍          | 4453/6100 [53:33<14:56,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:46:07,898 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:46:07,898 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:46:07,898 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.57it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.77it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9274829626083374, 'eval_accuracy': 0.739067055393586, 'eval_runtime': 6.2457, 'eval_samples_per_second': 109.836, 'eval_steps_per_second': 1.761, 'epoch': 73.0}\n",
      " 73%|████████████████████████████▍          | 4453/6100 [53:39<14:56,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:46:14,145 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4453\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:46:14,146 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4453/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:46:14,305 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4453/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:46:14,306 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4453/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:46:14,552 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4331] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3438, 'learning_rate': 5.377049180327869e-06, 'epoch': 73.11}        \n",
      "{'loss': 0.3302, 'learning_rate': 5.344262295081968e-06, 'epoch': 73.28}        \n",
      "{'loss': 0.3446, 'learning_rate': 5.3114754098360655e-06, 'epoch': 73.44}       \n",
      "{'loss': 0.2873, 'learning_rate': 5.2786885245901645e-06, 'epoch': 73.61}       \n",
      "{'loss': 0.3056, 'learning_rate': 5.245901639344263e-06, 'epoch': 73.77}        \n",
      "{'loss': 0.2834, 'learning_rate': 5.213114754098361e-06, 'epoch': 73.93}        \n",
      " 74%|████████████████████████████▊          | 4514/6100 [54:18<14:23,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:46:52,477 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:46:52,478 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:46:52,478 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.52it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.54it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.87it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.85it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.93it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8906885981559753, 'eval_accuracy': 0.7478134110787172, 'eval_runtime': 6.0923, 'eval_samples_per_second': 112.602, 'eval_steps_per_second': 1.806, 'epoch': 74.0}\n",
      " 74%|████████████████████████████▊          | 4514/6100 [54:24<14:23,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:46:58,571 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4514\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:46:58,572 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4514/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:46:58,729 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4514/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:46:58,729 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4514/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:46:58,982 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4392] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3209, 'learning_rate': 5.180327868852459e-06, 'epoch': 74.1}         \n",
      "{'loss': 0.3055, 'learning_rate': 5.147540983606558e-06, 'epoch': 74.26}        \n",
      "{'loss': 0.2686, 'learning_rate': 5.1147540983606555e-06, 'epoch': 74.43}       \n",
      "{'loss': 0.3117, 'learning_rate': 5.0819672131147545e-06, 'epoch': 74.59}       \n",
      "{'loss': 0.3032, 'learning_rate': 5.0491803278688535e-06, 'epoch': 74.75}       \n",
      "{'loss': 0.3312, 'learning_rate': 5.016393442622951e-06, 'epoch': 74.92}        \n",
      " 75%|█████████████████████████████▎         | 4575/6100 [55:02<13:50,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:47:37,143 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:47:37,143 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:47:37,143 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.09it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8847140073776245, 'eval_accuracy': 0.7332361516034985, 'eval_runtime': 6.2218, 'eval_samples_per_second': 110.258, 'eval_steps_per_second': 1.768, 'epoch': 75.0}\n",
      " 75%|█████████████████████████████▎         | 4575/6100 [55:09<13:50,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:47:43,366 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4575\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:47:43,367 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4575/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:47:43,527 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4575/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:47:43,528 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4575/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2887] 2023-10-05 11:47:43,781 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4453] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3064, 'learning_rate': 4.98360655737705e-06, 'epoch': 75.08}         \n",
      "{'loss': 0.271, 'learning_rate': 4.950819672131148e-06, 'epoch': 75.25}         \n",
      "{'loss': 0.3071, 'learning_rate': 4.918032786885246e-06, 'epoch': 75.41}        \n",
      "{'loss': 0.2764, 'learning_rate': 4.8852459016393445e-06, 'epoch': 75.57}       \n",
      "{'loss': 0.2644, 'learning_rate': 4.8524590163934435e-06, 'epoch': 75.74}       \n",
      "{'loss': 0.3297, 'learning_rate': 4.819672131147542e-06, 'epoch': 75.9}         \n",
      " 76%|█████████████████████████████▋         | 4636/6100 [55:47<10:54,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:48:21,970 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:48:21,970 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:48:21,970 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9278624057769775, 'eval_accuracy': 0.7288629737609329, 'eval_runtime': 6.1337, 'eval_samples_per_second': 111.841, 'eval_steps_per_second': 1.793, 'epoch': 76.0}\n",
      " 76%|█████████████████████████████▋         | 4636/6100 [55:53<10:54,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:48:28,104 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4636\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:48:28,105 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4636/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:48:28,261 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4636/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:48:28,261 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4636/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:48:28,520 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4514] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2388, 'learning_rate': 4.78688524590164e-06, 'epoch': 76.07}         \n",
      "{'loss': 0.2833, 'learning_rate': 4.754098360655738e-06, 'epoch': 76.23}        \n",
      "{'loss': 0.2718, 'learning_rate': 4.721311475409836e-06, 'epoch': 76.39}        \n",
      "{'loss': 0.2805, 'learning_rate': 4.6885245901639345e-06, 'epoch': 76.56}       \n",
      "{'loss': 0.3469, 'learning_rate': 4.655737704918033e-06, 'epoch': 76.72}        \n",
      "{'loss': 0.2606, 'learning_rate': 4.622950819672132e-06, 'epoch': 76.89}        \n",
      " 77%|██████████████████████████████         | 4697/6100 [56:32<10:33,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:49:06,907 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:49:06,907 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:49:06,907 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.53it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9225145578384399, 'eval_accuracy': 0.7376093294460642, 'eval_runtime': 6.021, 'eval_samples_per_second': 113.934, 'eval_steps_per_second': 1.827, 'epoch': 77.0}\n",
      " 77%|██████████████████████████████         | 4697/6100 [56:38<10:33,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:49:12,929 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4697\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:49:12,930 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4697/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:49:13,088 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4697/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:49:13,089 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4697/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:49:13,342 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4575] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2873, 'learning_rate': 4.59016393442623e-06, 'epoch': 77.05}         \n",
      "{'loss': 0.2968, 'learning_rate': 4.557377049180328e-06, 'epoch': 77.21}        \n",
      "{'loss': 0.304, 'learning_rate': 4.524590163934426e-06, 'epoch': 77.38}         \n",
      "{'loss': 0.2846, 'learning_rate': 4.491803278688525e-06, 'epoch': 77.54}        \n",
      "{'loss': 0.265, 'learning_rate': 4.4590163934426235e-06, 'epoch': 77.7}         \n",
      "{'loss': 0.2823, 'learning_rate': 4.426229508196722e-06, 'epoch': 77.87}        \n",
      " 78%|██████████████████████████████▍        | 4758/6100 [57:17<10:04,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:49:51,508 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:49:51,509 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:49:51,509 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.52it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.52it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.18it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.71it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9203553199768066, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 6.2674, 'eval_samples_per_second': 109.456, 'eval_steps_per_second': 1.755, 'epoch': 78.0}\n",
      " 78%|██████████████████████████████▍        | 4758/6100 [57:23<10:04,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:49:57,776 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4758\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:49:57,777 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4758/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:49:57,934 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4758/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:49:57,935 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4758/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:49:58,181 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4636] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2991, 'learning_rate': 4.39344262295082e-06, 'epoch': 78.03}         \n",
      "{'loss': 0.2876, 'learning_rate': 4.360655737704919e-06, 'epoch': 78.2}         \n",
      "{'loss': 0.2581, 'learning_rate': 4.327868852459017e-06, 'epoch': 78.36}        \n",
      "{'loss': 0.2791, 'learning_rate': 4.295081967213115e-06, 'epoch': 78.52}        \n",
      "{'loss': 0.2629, 'learning_rate': 4.2622950819672135e-06, 'epoch': 78.69}       \n",
      "{'loss': 0.2729, 'learning_rate': 4.229508196721312e-06, 'epoch': 78.85}        \n",
      " 79%|██████████████████████████████▊        | 4819/6100 [58:01<11:39,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:50:36,253 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:50:36,253 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:50:36,253 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.38it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.91it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9171534180641174, 'eval_accuracy': 0.7303206997084548, 'eval_runtime': 6.2669, 'eval_samples_per_second': 109.464, 'eval_steps_per_second': 1.755, 'epoch': 79.0}\n",
      " 79%|██████████████████████████████▊        | 4819/6100 [58:08<11:39,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:50:42,521 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4819\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:50:42,522 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4819/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:50:42,663 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4819/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:50:42,664 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4819/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:50:42,912 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4697] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.298, 'learning_rate': 4.19672131147541e-06, 'epoch': 79.02}          \n",
      "{'loss': 0.3537, 'learning_rate': 4.163934426229508e-06, 'epoch': 79.18}        \n",
      "{'loss': 0.2969, 'learning_rate': 4.131147540983607e-06, 'epoch': 79.34}        \n",
      "{'loss': 0.2967, 'learning_rate': 4.098360655737705e-06, 'epoch': 79.51}        \n",
      "{'loss': 0.3158, 'learning_rate': 4.0655737704918034e-06, 'epoch': 79.67}       \n",
      "{'loss': 0.3391, 'learning_rate': 4.032786885245902e-06, 'epoch': 79.84}        \n",
      "{'loss': 0.2824, 'learning_rate': 4.000000000000001e-06, 'epoch': 80.0}         \n",
      " 80%|███████████████████████████████▏       | 4880/6100 [58:46<10:48,  1.88it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:51:20,767 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:51:20,767 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:51:20,767 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9007529020309448, 'eval_accuracy': 0.7419825072886297, 'eval_runtime': 6.1799, 'eval_samples_per_second': 111.005, 'eval_steps_per_second': 1.78, 'epoch': 80.0}\n",
      " 80%|███████████████████████████████▏       | 4880/6100 [58:52<10:48,  1.88it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:51:26,948 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4880\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:51:26,949 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4880/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:51:27,111 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4880/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:51:27,112 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4880/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:51:27,360 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4758] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2729, 'learning_rate': 3.967213114754099e-06, 'epoch': 80.16}        \n",
      "{'loss': 0.2671, 'learning_rate': 3.934426229508197e-06, 'epoch': 80.33}        \n",
      "{'loss': 0.3314, 'learning_rate': 3.901639344262295e-06, 'epoch': 80.49}        \n",
      "{'loss': 0.3286, 'learning_rate': 3.868852459016394e-06, 'epoch': 80.66}        \n",
      "{'loss': 0.2729, 'learning_rate': 3.8360655737704925e-06, 'epoch': 80.82}       \n",
      "{'loss': 0.2668, 'learning_rate': 3.8032786885245902e-06, 'epoch': 80.98}       \n",
      " 81%|███████████████████████████████▌       | 4941/6100 [59:30<10:02,  1.92it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:52:04,924 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:52:04,925 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:52:04,925 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.44it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.86it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.83it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.82it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.92it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8932599425315857, 'eval_accuracy': 0.749271137026239, 'eval_runtime': 6.1133, 'eval_samples_per_second': 112.214, 'eval_steps_per_second': 1.799, 'epoch': 81.0}\n",
      " 81%|███████████████████████████████▌       | 4941/6100 [59:36<10:02,  1.92it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:52:11,038 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4941\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:52:11,039 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4941/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:52:11,199 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4941/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:52:11,199 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4941/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:52:11,452 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4819] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2781, 'learning_rate': 3.7704918032786884e-06, 'epoch': 81.15}       \n",
      "{'loss': 0.2628, 'learning_rate': 3.7377049180327874e-06, 'epoch': 81.31}       \n",
      "{'loss': 0.3103, 'learning_rate': 3.7049180327868856e-06, 'epoch': 81.48}       \n",
      "{'loss': 0.3089, 'learning_rate': 3.672131147540984e-06, 'epoch': 81.64}        \n",
      "{'loss': 0.2973, 'learning_rate': 3.6393442622950824e-06, 'epoch': 81.8}        \n",
      "{'loss': 0.3153, 'learning_rate': 3.6065573770491806e-06, 'epoch': 81.97}       \n",
      " 82%|██████████████████████████████▎      | 5002/6100 [1:00:15<09:32,  1.92it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:52:49,575 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:52:49,575 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:52:49,575 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.24it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.00it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.84it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8976122140884399, 'eval_accuracy': 0.7332361516034985, 'eval_runtime': 6.217, 'eval_samples_per_second': 110.343, 'eval_steps_per_second': 1.769, 'epoch': 82.0}\n",
      " 82%|██████████████████████████████▎      | 5002/6100 [1:00:21<09:32,  1.92it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:52:55,809 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5002\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:52:55,810 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5002/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:52:55,955 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5002/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:52:55,955 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5002/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:52:56,202 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4880] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2781, 'learning_rate': 3.573770491803279e-06, 'epoch': 82.13}        \n",
      "{'loss': 0.2871, 'learning_rate': 3.540983606557377e-06, 'epoch': 82.3}         \n",
      "{'loss': 0.2833, 'learning_rate': 3.508196721311476e-06, 'epoch': 82.46}        \n",
      "{'loss': 0.2641, 'learning_rate': 3.4754098360655742e-06, 'epoch': 82.62}       \n",
      "{'loss': 0.2837, 'learning_rate': 3.4426229508196724e-06, 'epoch': 82.79}       \n",
      "{'loss': 0.317, 'learning_rate': 3.4098360655737706e-06, 'epoch': 82.95}        \n",
      " 83%|██████████████████████████████▋      | 5063/6100 [1:00:59<09:18,  1.86it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:53:34,049 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:53:34,049 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:53:34,049 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.86it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9072352647781372, 'eval_accuracy': 0.7434402332361516, 'eval_runtime': 6.2084, 'eval_samples_per_second': 110.495, 'eval_steps_per_second': 1.772, 'epoch': 83.0}\n",
      " 83%|██████████████████████████████▋      | 5063/6100 [1:01:05<09:18,  1.86it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:53:40,258 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5063\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:53:40,259 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5063/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:53:40,420 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5063/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:53:40,420 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5063/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:53:40,670 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-4941] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2466, 'learning_rate': 3.3770491803278692e-06, 'epoch': 83.11}       \n",
      "{'loss': 0.3052, 'learning_rate': 3.3442622950819674e-06, 'epoch': 83.28}       \n",
      "{'loss': 0.2706, 'learning_rate': 3.3114754098360656e-06, 'epoch': 83.44}       \n",
      "{'loss': 0.3114, 'learning_rate': 3.2786885245901638e-06, 'epoch': 83.61}       \n",
      "{'loss': 0.2636, 'learning_rate': 3.245901639344263e-06, 'epoch': 83.77}        \n",
      "{'loss': 0.2719, 'learning_rate': 3.213114754098361e-06, 'epoch': 83.93}        \n",
      " 84%|███████████████████████████████      | 5124/6100 [1:01:44<08:28,  1.92it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:54:18,844 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:54:18,844 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:54:18,844 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.48it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.19it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.03it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.92it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.90985107421875, 'eval_accuracy': 0.7536443148688047, 'eval_runtime': 6.1479, 'eval_samples_per_second': 111.582, 'eval_steps_per_second': 1.789, 'epoch': 84.0}\n",
      " 84%|███████████████████████████████      | 5124/6100 [1:01:50<08:28,  1.92it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:54:24,993 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:458] 2023-10-05 11:54:24,994 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5124/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:54:25,153 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5124/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:54:25,153 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5124/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:54:25,400 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5002] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3176, 'learning_rate': 3.180327868852459e-06, 'epoch': 84.1}         \n",
      "{'loss': 0.27, 'learning_rate': 3.147540983606558e-06, 'epoch': 84.26}          \n",
      "{'loss': 0.2529, 'learning_rate': 3.114754098360656e-06, 'epoch': 84.43}        \n",
      "{'loss': 0.2754, 'learning_rate': 3.081967213114754e-06, 'epoch': 84.59}        \n",
      "{'loss': 0.271, 'learning_rate': 3.0491803278688524e-06, 'epoch': 84.75}        \n",
      "{'loss': 0.2475, 'learning_rate': 3.0163934426229514e-06, 'epoch': 84.92}       \n",
      " 85%|███████████████████████████████▍     | 5185/6100 [1:02:29<08:29,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:55:03,638 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:55:03,638 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:55:03,638 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  2.00it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.92it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.932196319103241, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 6.1968, 'eval_samples_per_second': 110.703, 'eval_steps_per_second': 1.775, 'epoch': 85.0}\n",
      " 85%|███████████████████████████████▍     | 5185/6100 [1:02:35<08:29,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:55:09,835 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5185\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:55:09,837 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5185/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:55:10,000 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5185/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:55:10,000 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5185/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:55:10,253 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5063] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3116, 'learning_rate': 2.9836065573770496e-06, 'epoch': 85.08}       \n",
      "{'loss': 0.3404, 'learning_rate': 2.9508196721311478e-06, 'epoch': 85.25}       \n",
      "{'loss': 0.2604, 'learning_rate': 2.918032786885246e-06, 'epoch': 85.41}        \n",
      "{'loss': 0.2444, 'learning_rate': 2.8852459016393446e-06, 'epoch': 85.57}       \n",
      "{'loss': 0.2654, 'learning_rate': 2.8524590163934428e-06, 'epoch': 85.74}       \n",
      "{'loss': 0.2427, 'learning_rate': 2.819672131147541e-06, 'epoch': 85.9}         \n",
      " 86%|███████████████████████████████▊     | 5246/6100 [1:03:13<07:43,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:55:48,110 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:55:48,110 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:55:48,110 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9408448338508606, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 6.2186, 'eval_samples_per_second': 110.314, 'eval_steps_per_second': 1.769, 'epoch': 86.0}\n",
      " 86%|███████████████████████████████▊     | 5246/6100 [1:03:19<07:43,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:55:54,329 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5246\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:55:54,330 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5246/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:55:54,491 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5246/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:55:54,491 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5246/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:55:54,738 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5124] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.31, 'learning_rate': 2.786885245901639e-06, 'epoch': 86.07}          \n",
      "{'loss': 0.2275, 'learning_rate': 2.754098360655738e-06, 'epoch': 86.23}        \n",
      "{'loss': 0.2606, 'learning_rate': 2.7213114754098364e-06, 'epoch': 86.39}       \n",
      "{'loss': 0.2811, 'learning_rate': 2.6885245901639346e-06, 'epoch': 86.56}       \n",
      "{'loss': 0.2805, 'learning_rate': 2.6557377049180328e-06, 'epoch': 86.72}       \n",
      "{'loss': 0.3203, 'learning_rate': 2.6229508196721314e-06, 'epoch': 86.89}       \n",
      " 87%|████████████████████████████████▏    | 5307/6100 [1:03:58<07:11,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:56:32,756 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:56:32,756 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:56:32,756 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.91it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9604907631874084, 'eval_accuracy': 0.7346938775510204, 'eval_runtime': 6.2061, 'eval_samples_per_second': 110.537, 'eval_steps_per_second': 1.772, 'epoch': 87.0}\n",
      " 87%|████████████████████████████████▏    | 5307/6100 [1:04:04<07:11,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:56:38,969 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5307\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:56:38,970 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5307/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:56:39,116 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5307/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:56:39,116 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5307/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:56:39,364 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5185] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2975, 'learning_rate': 2.5901639344262296e-06, 'epoch': 87.05}       \n",
      "{'loss': 0.2497, 'learning_rate': 2.5573770491803277e-06, 'epoch': 87.21}       \n",
      "{'loss': 0.3008, 'learning_rate': 2.5245901639344268e-06, 'epoch': 87.38}       \n",
      "{'loss': 0.2546, 'learning_rate': 2.491803278688525e-06, 'epoch': 87.54}        \n",
      "{'loss': 0.2561, 'learning_rate': 2.459016393442623e-06, 'epoch': 87.7}         \n",
      "{'loss': 0.2841, 'learning_rate': 2.4262295081967218e-06, 'epoch': 87.87}       \n",
      " 88%|████████████████████████████████▌    | 5368/6100 [1:04:42<06:30,  1.88it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:57:17,154 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:57:17,154 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:57:17,154 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.09it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.82it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9246311783790588, 'eval_accuracy': 0.739067055393586, 'eval_runtime': 6.1751, 'eval_samples_per_second': 111.09, 'eval_steps_per_second': 1.781, 'epoch': 88.0}\n",
      " 88%|████████████████████████████████▌    | 5368/6100 [1:04:48<06:30,  1.88it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:57:23,329 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5368\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:57:23,331 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5368/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:57:23,489 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5368/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:57:23,489 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5368/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:57:23,738 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5246] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2414, 'learning_rate': 2.39344262295082e-06, 'epoch': 88.03}         \n",
      "{'loss': 0.2841, 'learning_rate': 2.360655737704918e-06, 'epoch': 88.2}         \n",
      "{'loss': 0.254, 'learning_rate': 2.3278688524590163e-06, 'epoch': 88.36}        \n",
      "{'loss': 0.2647, 'learning_rate': 2.295081967213115e-06, 'epoch': 88.52}        \n",
      "{'loss': 0.329, 'learning_rate': 2.262295081967213e-06, 'epoch': 88.69}         \n",
      "{'loss': 0.3013, 'learning_rate': 2.2295081967213117e-06, 'epoch': 88.85}       \n",
      " 89%|████████████████████████████████▉    | 5429/6100 [1:05:27<05:52,  1.90it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:58:01,755 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:58:01,755 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:58:01,755 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.44it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9369117021560669, 'eval_accuracy': 0.7303206997084548, 'eval_runtime': 6.2201, 'eval_samples_per_second': 110.288, 'eval_steps_per_second': 1.768, 'epoch': 89.0}\n",
      " 89%|████████████████████████████████▉    | 5429/6100 [1:05:33<05:52,  1.90it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:58:07,976 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5429\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:58:07,977 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5429/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:58:08,135 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5429/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:58:08,136 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5429/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:58:08,382 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5307] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3093, 'learning_rate': 2.19672131147541e-06, 'epoch': 89.02}         \n",
      "{'loss': 0.279, 'learning_rate': 2.1639344262295085e-06, 'epoch': 89.18}        \n",
      "{'loss': 0.2806, 'learning_rate': 2.1311475409836067e-06, 'epoch': 89.34}       \n",
      "{'loss': 0.2722, 'learning_rate': 2.098360655737705e-06, 'epoch': 89.51}        \n",
      "{'loss': 0.317, 'learning_rate': 2.0655737704918035e-06, 'epoch': 89.67}        \n",
      "{'loss': 0.2612, 'learning_rate': 2.0327868852459017e-06, 'epoch': 89.84}       \n",
      "{'loss': 0.2763, 'learning_rate': 2.0000000000000003e-06, 'epoch': 90.0}        \n",
      " 90%|█████████████████████████████████▎   | 5490/6100 [1:06:12<05:33,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:58:46,395 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:58:46,395 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:58:46,395 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.55it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9233475923538208, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 6.2155, 'eval_samples_per_second': 110.37, 'eval_steps_per_second': 1.77, 'epoch': 90.0}\n",
      " 90%|█████████████████████████████████▎   | 5490/6100 [1:06:18<05:33,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:58:52,611 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5490\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:58:52,612 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5490/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:58:52,775 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5490/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:58:52,775 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5490/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:58:53,024 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5368] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2331, 'learning_rate': 1.9672131147540985e-06, 'epoch': 90.16}       \n",
      "{'loss': 0.2492, 'learning_rate': 1.934426229508197e-06, 'epoch': 90.33}        \n",
      "{'loss': 0.2996, 'learning_rate': 1.9016393442622951e-06, 'epoch': 90.49}       \n",
      "{'loss': 0.2894, 'learning_rate': 1.8688524590163937e-06, 'epoch': 90.66}       \n",
      "{'loss': 0.3035, 'learning_rate': 1.836065573770492e-06, 'epoch': 90.82}        \n",
      "{'loss': 0.2968, 'learning_rate': 1.8032786885245903e-06, 'epoch': 90.98}       \n",
      " 91%|█████████████████████████████████▋   | 5551/6100 [1:06:56<05:00,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 11:59:30,969 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 11:59:30,970 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 11:59:30,970 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.38it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9171872138977051, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 6.1992, 'eval_samples_per_second': 110.66, 'eval_steps_per_second': 1.774, 'epoch': 91.0}\n",
      " 91%|█████████████████████████████████▋   | 5551/6100 [1:07:02<05:00,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 11:59:37,169 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5551\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 11:59:37,170 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5551/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 11:59:37,330 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5551/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 11:59:37,331 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5551/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 11:59:37,582 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5429] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2564, 'learning_rate': 1.7704918032786885e-06, 'epoch': 91.15}       \n",
      "{'loss': 0.2543, 'learning_rate': 1.7377049180327871e-06, 'epoch': 91.31}       \n",
      "{'loss': 0.2781, 'learning_rate': 1.7049180327868853e-06, 'epoch': 91.48}       \n",
      "{'loss': 0.2538, 'learning_rate': 1.6721311475409837e-06, 'epoch': 91.64}       \n",
      "{'loss': 0.2176, 'learning_rate': 1.6393442622950819e-06, 'epoch': 91.8}        \n",
      "{'loss': 0.3238, 'learning_rate': 1.6065573770491805e-06, 'epoch': 91.97}       \n",
      " 92%|██████████████████████████████████   | 5612/6100 [1:07:41<04:25,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:00:15,592 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:00:15,592 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:00:15,592 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9179993271827698, 'eval_accuracy': 0.7463556851311953, 'eval_runtime': 6.1953, 'eval_samples_per_second': 110.729, 'eval_steps_per_second': 1.776, 'epoch': 92.0}\n",
      " 92%|██████████████████████████████████   | 5612/6100 [1:07:47<04:25,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:00:21,793 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5612\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:00:21,794 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5612/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:00:21,950 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5612/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:00:21,950 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5612/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:00:22,198 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5490] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.285, 'learning_rate': 1.573770491803279e-06, 'epoch': 92.13}         \n",
      "{'loss': 0.2879, 'learning_rate': 1.540983606557377e-06, 'epoch': 92.3}         \n",
      "{'loss': 0.3075, 'learning_rate': 1.5081967213114757e-06, 'epoch': 92.46}       \n",
      "{'loss': 0.2583, 'learning_rate': 1.4754098360655739e-06, 'epoch': 92.62}       \n",
      "{'loss': 0.282, 'learning_rate': 1.4426229508196723e-06, 'epoch': 92.79}        \n",
      "{'loss': 0.2365, 'learning_rate': 1.4098360655737705e-06, 'epoch': 92.95}       \n",
      " 93%|██████████████████████████████████▍  | 5673/6100 [1:08:25<03:54,  1.82it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:01:00,112 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:01:00,112 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:01:00,112 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9266889691352844, 'eval_accuracy': 0.7463556851311953, 'eval_runtime': 6.2229, 'eval_samples_per_second': 110.239, 'eval_steps_per_second': 1.768, 'epoch': 93.0}\n",
      " 93%|██████████████████████████████████▍  | 5673/6100 [1:08:31<03:54,  1.82it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:01:06,336 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5673\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:01:06,337 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5673/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:01:06,486 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5673/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:01:06,487 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5673/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:01:06,736 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5551] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2508, 'learning_rate': 1.377049180327869e-06, 'epoch': 93.11}        \n",
      "{'loss': 0.2703, 'learning_rate': 1.3442622950819673e-06, 'epoch': 93.28}       \n",
      "{'loss': 0.2733, 'learning_rate': 1.3114754098360657e-06, 'epoch': 93.44}       \n",
      "{'loss': 0.3135, 'learning_rate': 1.2786885245901639e-06, 'epoch': 93.61}       \n",
      "{'loss': 0.2572, 'learning_rate': 1.2459016393442625e-06, 'epoch': 93.77}       \n",
      "{'loss': 0.2853, 'learning_rate': 1.2131147540983609e-06, 'epoch': 93.93}       \n",
      " 94%|██████████████████████████████████▊  | 5734/6100 [1:09:10<03:24,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:01:44,662 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:01:44,662 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:01:44,662 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.46it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.83it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.07it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9342395067214966, 'eval_accuracy': 0.7419825072886297, 'eval_runtime': 6.0103, 'eval_samples_per_second': 114.137, 'eval_steps_per_second': 1.83, 'epoch': 94.0}\n",
      " 94%|██████████████████████████████████▊  | 5734/6100 [1:09:16<03:24,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.72it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:01:50,673 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5734\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:01:50,674 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5734/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:01:50,789 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5734/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:01:50,790 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5734/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:01:50,970 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5612] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2737, 'learning_rate': 1.180327868852459e-06, 'epoch': 94.1}         \n",
      "{'loss': 0.2506, 'learning_rate': 1.1475409836065575e-06, 'epoch': 94.26}       \n",
      "{'loss': 0.2599, 'learning_rate': 1.1147540983606559e-06, 'epoch': 94.43}       \n",
      "{'loss': 0.2703, 'learning_rate': 1.0819672131147543e-06, 'epoch': 94.59}       \n",
      "{'loss': 0.2732, 'learning_rate': 1.0491803278688525e-06, 'epoch': 94.75}       \n",
      "{'loss': 0.257, 'learning_rate': 1.0163934426229509e-06, 'epoch': 94.92}        \n",
      " 95%|███████████████████████████████████▏ | 5795/6100 [1:09:54<02:46,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:02:29,047 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:02:29,047 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:02:29,047 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.48it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.47it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.43it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.40it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.36it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.27it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9331585168838501, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 5.2316, 'eval_samples_per_second': 131.126, 'eval_steps_per_second': 2.103, 'epoch': 95.0}\n",
      " 95%|███████████████████████████████████▏ | 5795/6100 [1:09:59<02:46,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.07it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:02:34,279 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5795\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:02:34,279 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5795/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:02:34,398 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5795/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:02:34,398 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5795/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:02:34,577 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5673] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2442, 'learning_rate': 9.836065573770493e-07, 'epoch': 95.08}        \n",
      "{'loss': 0.3025, 'learning_rate': 9.508196721311476e-07, 'epoch': 95.25}        \n",
      "{'loss': 0.2557, 'learning_rate': 9.18032786885246e-07, 'epoch': 95.41}         \n",
      "{'loss': 0.2982, 'learning_rate': 8.852459016393443e-07, 'epoch': 95.57}        \n",
      "{'loss': 0.2778, 'learning_rate': 8.524590163934427e-07, 'epoch': 95.74}        \n",
      "{'loss': 0.2655, 'learning_rate': 8.196721311475409e-07, 'epoch': 95.9}         \n",
      " 96%|███████████████████████████████████▌ | 5856/6100 [1:10:36<01:50,  2.22it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:03:10,923 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:03:10,923 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:03:10,923 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.36it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9323705434799194, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 4.5887, 'eval_samples_per_second': 149.498, 'eval_steps_per_second': 2.397, 'epoch': 96.0}\n",
      " 96%|███████████████████████████████████▌ | 5856/6100 [1:10:41<01:50,  2.22it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.28it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:03:15,513 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5856\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:03:15,513 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5856/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:03:15,633 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5856/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:03:15,634 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5856/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:03:15,816 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5734] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2485, 'learning_rate': 7.868852459016395e-07, 'epoch': 96.07}        \n",
      "{'loss': 0.2477, 'learning_rate': 7.540983606557379e-07, 'epoch': 96.23}        \n",
      "{'loss': 0.2618, 'learning_rate': 7.213114754098361e-07, 'epoch': 96.39}        \n",
      "{'loss': 0.2389, 'learning_rate': 6.885245901639345e-07, 'epoch': 96.56}        \n",
      "{'loss': 0.2968, 'learning_rate': 6.557377049180328e-07, 'epoch': 96.72}        \n",
      "{'loss': 0.3032, 'learning_rate': 6.229508196721312e-07, 'epoch': 96.89}        \n",
      " 97%|███████████████████████████████████▉ | 5917/6100 [1:11:19<01:22,  2.23it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:03:53,761 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:03:53,762 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:03:53,762 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.35it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.78it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.59it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.46it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9317484498023987, 'eval_accuracy': 0.7376093294460642, 'eval_runtime': 4.6527, 'eval_samples_per_second': 147.442, 'eval_steps_per_second': 2.364, 'epoch': 97.0}\n",
      " 97%|███████████████████████████████████▉ | 5917/6100 [1:11:24<01:22,  2.23it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.21it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:03:58,414 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5917\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:03:58,415 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5917/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:03:58,518 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5917/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:03:58,519 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5917/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:03:58,700 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5795] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2458, 'learning_rate': 5.901639344262295e-07, 'epoch': 97.05}        \n",
      "{'loss': 0.2575, 'learning_rate': 5.573770491803279e-07, 'epoch': 97.21}        \n",
      "{'loss': 0.2597, 'learning_rate': 5.245901639344262e-07, 'epoch': 97.38}        \n",
      "{'loss': 0.2474, 'learning_rate': 4.918032786885246e-07, 'epoch': 97.54}        \n",
      "{'loss': 0.2248, 'learning_rate': 4.59016393442623e-07, 'epoch': 97.7}          \n",
      "{'loss': 0.2523, 'learning_rate': 4.262295081967213e-07, 'epoch': 97.87}        \n",
      " 98%|████████████████████████████████████▎| 5978/6100 [1:12:02<00:55,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:04:36,607 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:04:36,608 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:04:36,608 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.53it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9381459355354309, 'eval_accuracy': 0.7361516034985423, 'eval_runtime': 6.212, 'eval_samples_per_second': 110.431, 'eval_steps_per_second': 1.771, 'epoch': 98.0}\n",
      " 98%|████████████████████████████████████▎| 5978/6100 [1:12:08<00:55,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:04:42,821 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5978\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:04:42,822 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5978/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:04:42,989 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5978/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:04:42,990 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5978/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:04:43,239 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5856] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2758, 'learning_rate': 3.934426229508197e-07, 'epoch': 98.03}        \n",
      "{'loss': 0.2482, 'learning_rate': 3.6065573770491807e-07, 'epoch': 98.2}        \n",
      "{'loss': 0.3109, 'learning_rate': 3.278688524590164e-07, 'epoch': 98.36}        \n",
      "{'loss': 0.2865, 'learning_rate': 2.9508196721311477e-07, 'epoch': 98.52}       \n",
      "{'loss': 0.2196, 'learning_rate': 2.622950819672131e-07, 'epoch': 98.69}        \n",
      "{'loss': 0.2717, 'learning_rate': 2.295081967213115e-07, 'epoch': 98.85}        \n",
      " 99%|████████████████████████████████████▋| 6039/6100 [1:12:46<00:32,  1.87it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:05:21,150 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:05:21,150 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:05:21,150 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.66it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.51it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.88it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.931779146194458, 'eval_accuracy': 0.7434402332361516, 'eval_runtime': 6.1154, 'eval_samples_per_second': 112.176, 'eval_steps_per_second': 1.799, 'epoch': 99.0}\n",
      " 99%|████████████████████████████████████▋| 6039/6100 [1:12:52<00:32,  1.87it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:05:27,265 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6039\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:05:27,266 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6039/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:05:27,403 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6039/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:05:27,404 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6039/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:05:27,656 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5917] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2007, 'learning_rate': 1.9672131147540986e-07, 'epoch': 99.02}       \n",
      "{'loss': 0.2703, 'learning_rate': 1.639344262295082e-07, 'epoch': 99.18}        \n",
      "{'loss': 0.3105, 'learning_rate': 1.3114754098360656e-07, 'epoch': 99.34}       \n",
      "{'loss': 0.2669, 'learning_rate': 9.836065573770493e-08, 'epoch': 99.51}        \n",
      "{'loss': 0.2689, 'learning_rate': 6.557377049180328e-08, 'epoch': 99.67}        \n",
      "{'loss': 0.2778, 'learning_rate': 3.278688524590164e-08, 'epoch': 99.84}        \n",
      "{'loss': 0.2312, 'learning_rate': 0.0, 'epoch': 100.0}                          \n",
      "100%|█████████████████████████████████████| 6100/6100 [1:13:31<00:00,  1.84it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:06:05,793 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:06:05,793 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:06:05,793 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.34it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.07it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.84it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9305127263069153, 'eval_accuracy': 0.7405247813411079, 'eval_runtime': 6.2445, 'eval_samples_per_second': 109.856, 'eval_steps_per_second': 1.762, 'epoch': 100.0}\n",
      "100%|█████████████████████████████████████| 6100/6100 [1:13:37<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:06:12,051 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6100\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:06:12,052 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6100/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:06:12,209 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6100/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:06:12,209 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6100/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:06:12,460 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-5978] due to args.save_total_limit\n",
      "[INFO|trainer.py:1916] 2023-10-05 12:06:12,494 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2051] 2023-10-05 12:06:12,494 >> Loading best model from outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-854 (score: 0.6627798080444336).\n",
      "{'train_runtime': 4418.2216, 'train_samples_per_second': 87.886, 'train_steps_per_second': 1.381, 'train_loss': 0.43685789041831846, 'epoch': 100.0}\n",
      "100%|█████████████████████████████████████| 6100/6100 [1:13:38<00:00,  1.38it/s]\n",
      "[INFO|trainer.py:2800] 2023-10-05 12:06:12,575 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_6\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:06:12,576 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_6/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:06:12,708 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_6/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:06:12,708 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_6/preprocessor_config.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      100.0\n",
      "  train_loss               =     0.4369\n",
      "  train_runtime            = 1:13:38.22\n",
      "  train_samples_per_second =     87.886\n",
      "  train_steps_per_second   =      1.381\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:06:12,721 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:06:12,721 >>   Num examples = 686\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:06:12,721 >>   Batch size = 64\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.87it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =      100.0\n",
      "  eval_accuracy           =     0.7755\n",
      "  eval_loss               =     0.6628\n",
      "  eval_runtime            = 0:00:04.67\n",
      "  eval_samples_per_second =    146.657\n",
      "  eval_steps_per_second   =      2.352\n",
      "10/05/2023 12:06:20 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: False\n",
      "10/05/2023 12:06:20 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=2,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs_all/swin_combine_pseudo_30%_Fold_7/runs/Oct05_12-06-20_thanawit-Z690-Pro-RS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=100.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=outputs_all/swin_combine_pseudo_30%_Fold_7,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs_all/swin_combine_pseudo_30%_Fold_7,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "Resolving data files: 100%|██████████████| 4578/4578 [00:00<00:00, 66869.31it/s]\n",
      "10/05/2023 12:06:22 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-45f6ae0e42f8d244/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 95.10it/s]\n",
      "10/05/2023 12:06:22 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-45f6ae0e42f8d244/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-b9eb9fcba1f322c9.arrow\n",
      "10/05/2023 12:06:22 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-45f6ae0e42f8d244/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-8cbb31a29721b316.arrow and /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-45f6ae0e42f8d244/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-58bd7bfd1c4bc8a7.arrow\n",
      "[INFO|configuration_utils.py:669] 2023-10-05 12:06:24,782 >> loading configuration file config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-10-05 12:06:24,783 >> Model config SwinConfig {\n",
      "  \"_name_or_path\": \"microsoft/swin-tiny-patch4-window7-224\",\n",
      "  \"architectures\": [\n",
      "    \"SwinForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    6,\n",
      "    2\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"embed_dim\": 96,\n",
      "  \"encoder_stride\": 32,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Atypical\",\n",
      "    \"1\": \"Indeterminate\",\n",
      "    \"2\": \"Negative\",\n",
      "    \"3\": \"Typical\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Atypical\": \"0\",\n",
      "    \"Indeterminate\": \"1\",\n",
      "    \"Negative\": \"2\",\n",
      "    \"Typical\": \"3\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mlp_ratio\": 4.0,\n",
      "  \"model_type\": \"swin\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_heads\": [\n",
      "    3,\n",
      "    6,\n",
      "    12,\n",
      "    24\n",
      "  ],\n",
      "  \"num_layers\": 4,\n",
      "  \"out_features\": [\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"out_indices\": [\n",
      "    4\n",
      "  ],\n",
      "  \"patch_size\": 4,\n",
      "  \"path_norm\": true,\n",
      "  \"qkv_bias\": true,\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0.dev0\",\n",
      "  \"use_absolute_embeddings\": false,\n",
      "  \"window_size\": 7\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:2575] 2023-10-05 12:06:24,785 >> loading weights file model.safetensors from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/model.safetensors\n",
      "[INFO|modeling_utils.py:3283] 2023-10-05 12:06:24,954 >> All model checkpoint weights were used when initializing SwinForImageClassification.\n",
      "\n",
      "[WARNING|modeling_utils.py:3304] 2023-10-05 12:06:24,954 >> Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-10-05 12:06:25,139 >> loading configuration file preprocessor_config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/preprocessor_config.json\n",
      "[WARNING|image_processing_auto.py:331] 2023-10-05 12:06:25,139 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "[INFO|image_processing_utils.py:542] 2023-10-05 12:06:25,142 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "[INFO|image_processing_utils.py:359] 2023-10-05 12:06:25,142 >> Image processor ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:1680] 2023-10-05 12:06:25,886 >> ***** Running training *****\n",
      "[INFO|trainer.py:1681] 2023-10-05 12:06:25,886 >>   Num examples = 3,891\n",
      "[INFO|trainer.py:1682] 2023-10-05 12:06:25,886 >>   Num Epochs = 100\n",
      "[INFO|trainer.py:1683] 2023-10-05 12:06:25,886 >>   Instantaneous batch size per device = 64\n",
      "[INFO|trainer.py:1684] 2023-10-05 12:06:25,886 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1685] 2023-10-05 12:06:25,886 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1686] 2023-10-05 12:06:25,886 >>   Total optimization steps = 6,100\n",
      "[INFO|trainer.py:1687] 2023-10-05 12:06:25,886 >>   Number of trainable parameters = 27,522,430\n",
      "  0%|                                                  | 0/6100 [00:00<?, ?it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 1.1316, 'learning_rate': 1.99672131147541e-05, 'epoch': 0.16}          \n",
      "{'loss': 1.0198, 'learning_rate': 1.99344262295082e-05, 'epoch': 0.33}          \n",
      "{'loss': 0.9459, 'learning_rate': 1.9901639344262297e-05, 'epoch': 0.49}        \n",
      "{'loss': 0.8957, 'learning_rate': 1.9868852459016394e-05, 'epoch': 0.66}        \n",
      "{'loss': 0.8708, 'learning_rate': 1.9836065573770492e-05, 'epoch': 0.82}        \n",
      "{'loss': 0.8671, 'learning_rate': 1.9803278688524592e-05, 'epoch': 0.98}        \n",
      "  1%|▍                                        | 61/6100 [00:43<58:27,  1.72it/s][INFO|trainer.py:3074] 2023-10-05 12:07:09,454 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:07:09,454 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:07:09,454 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.38it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.07it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.54it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.40it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.30it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.26it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.24it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7440253496170044, 'eval_accuracy': 0.745269286754003, 'eval_runtime': 5.1681, 'eval_samples_per_second': 132.93, 'eval_steps_per_second': 2.128, 'epoch': 1.0}\n",
      "  1%|▍                                        | 61/6100 [00:48<58:27,  1.72it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:07:14,622 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-61\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:07:14,623 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-61/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:07:14,738 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-61/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:07:14,738 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-61/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.9063, 'learning_rate': 1.977049180327869e-05, 'epoch': 1.15}         \n",
      "{'loss': 0.7965, 'learning_rate': 1.973770491803279e-05, 'epoch': 1.31}         \n",
      "{'loss': 0.8351, 'learning_rate': 1.9704918032786884e-05, 'epoch': 1.48}        \n",
      "{'loss': 0.789, 'learning_rate': 1.9672131147540985e-05, 'epoch': 1.64}         \n",
      "{'loss': 0.7983, 'learning_rate': 1.9639344262295083e-05, 'epoch': 1.8}         \n",
      "{'loss': 0.7986, 'learning_rate': 1.9606557377049183e-05, 'epoch': 1.97}        \n",
      "  2%|▊                                       | 122/6100 [01:26<45:51,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:07:52,574 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:07:52,574 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:07:52,574 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.03it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.49it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.96it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7334322929382324, 'eval_accuracy': 0.727802037845706, 'eval_runtime': 4.4876, 'eval_samples_per_second': 153.087, 'eval_steps_per_second': 2.451, 'epoch': 2.0}\n",
      "  2%|▊                                       | 122/6100 [01:31<45:51,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.29it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:07:57,062 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-122\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:07:57,062 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-122/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:07:57,174 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-122/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:07:57,174 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-122/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.8107, 'learning_rate': 1.957377049180328e-05, 'epoch': 2.13}         \n",
      "{'loss': 0.8002, 'learning_rate': 1.9540983606557378e-05, 'epoch': 2.3}         \n",
      "{'loss': 0.7795, 'learning_rate': 1.9508196721311475e-05, 'epoch': 2.46}        \n",
      "{'loss': 0.8062, 'learning_rate': 1.9475409836065576e-05, 'epoch': 2.62}        \n",
      "{'loss': 0.791, 'learning_rate': 1.9442622950819673e-05, 'epoch': 2.79}         \n",
      "{'loss': 0.813, 'learning_rate': 1.9409836065573774e-05, 'epoch': 2.95}         \n",
      "  3%|█▏                                      | 183/6100 [02:07<45:28,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:08:33,848 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:08:33,848 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:08:33,848 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.80it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.62it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7442091107368469, 'eval_accuracy': 0.7510917030567685, 'eval_runtime': 4.5845, 'eval_samples_per_second': 149.854, 'eval_steps_per_second': 2.399, 'epoch': 3.0}\n",
      "  3%|█▏                                      | 183/6100 [02:12<45:28,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:08:38,433 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-183\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:08:38,433 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-183/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:08:38,540 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-183/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:08:38,541 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-183/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.725, 'learning_rate': 1.937704918032787e-05, 'epoch': 3.11}          \n",
      "{'loss': 0.7812, 'learning_rate': 1.934426229508197e-05, 'epoch': 3.28}         \n",
      "{'loss': 0.7855, 'learning_rate': 1.9311475409836066e-05, 'epoch': 3.44}        \n",
      "{'loss': 0.7364, 'learning_rate': 1.9278688524590167e-05, 'epoch': 3.61}        \n",
      "{'loss': 0.801, 'learning_rate': 1.9245901639344264e-05, 'epoch': 3.77}         \n",
      "{'loss': 0.7185, 'learning_rate': 1.921311475409836e-05, 'epoch': 3.93}         \n",
      "  4%|█▌                                      | 244/6100 [02:50<47:43,  2.05it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:09:16,354 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:09:16,354 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:09:16,354 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.40it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.05it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.90it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6783137917518616, 'eval_accuracy': 0.7656477438136827, 'eval_runtime': 6.2425, 'eval_samples_per_second': 110.053, 'eval_steps_per_second': 1.762, 'epoch': 4.0}\n",
      "  4%|█▌                                      | 244/6100 [02:56<47:43,  2.05it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:09:22,597 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-244\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:09:22,598 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-244/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:09:22,756 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-244/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:09:22,757 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-244/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:09:23,004 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-61] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7258, 'learning_rate': 1.918032786885246e-05, 'epoch': 4.1}          \n",
      "{'loss': 0.7378, 'learning_rate': 1.914754098360656e-05, 'epoch': 4.26}         \n",
      "{'loss': 0.7408, 'learning_rate': 1.9114754098360657e-05, 'epoch': 4.43}        \n",
      "{'loss': 0.7106, 'learning_rate': 1.9081967213114754e-05, 'epoch': 4.59}        \n",
      "{'loss': 0.7246, 'learning_rate': 1.9049180327868855e-05, 'epoch': 4.75}        \n",
      "{'loss': 0.7274, 'learning_rate': 1.9016393442622952e-05, 'epoch': 4.92}        \n",
      "  5%|██                                      | 305/6100 [03:35<54:15,  1.78it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:10:01,073 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:10:01,073 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:10:01,073 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.62it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.46it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6815394163131714, 'eval_accuracy': 0.7656477438136827, 'eval_runtime': 6.2141, 'eval_samples_per_second': 110.555, 'eval_steps_per_second': 1.77, 'epoch': 5.0}\n",
      "  5%|██                                      | 305/6100 [03:41<54:15,  1.78it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:10:07,288 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-305\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:10:07,288 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-305/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:10:07,420 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-305/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:10:07,421 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-305/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:10:07,662 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-122] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7059, 'learning_rate': 1.898360655737705e-05, 'epoch': 5.08}         \n",
      "{'loss': 0.6882, 'learning_rate': 1.895081967213115e-05, 'epoch': 5.25}         \n",
      "{'loss': 0.7116, 'learning_rate': 1.8918032786885248e-05, 'epoch': 5.41}        \n",
      "{'loss': 0.7386, 'learning_rate': 1.8885245901639345e-05, 'epoch': 5.57}        \n",
      "{'loss': 0.7578, 'learning_rate': 1.8852459016393446e-05, 'epoch': 5.74}        \n",
      "{'loss': 0.7701, 'learning_rate': 1.8819672131147543e-05, 'epoch': 5.9}         \n",
      "  6%|██▍                                     | 366/6100 [04:19<53:49,  1.78it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:10:45,530 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:10:45,530 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:10:45,530 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  1.99it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.85it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.78it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6704757213592529, 'eval_accuracy': 0.7641921397379913, 'eval_runtime': 6.3448, 'eval_samples_per_second': 108.277, 'eval_steps_per_second': 1.734, 'epoch': 6.0}\n",
      "  6%|██▍                                     | 366/6100 [04:25<53:49,  1.78it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:10:51,876 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-366\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:10:51,877 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-366/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:10:52,022 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-366/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:10:52,023 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-366/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:10:52,262 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-183] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7791, 'learning_rate': 1.878688524590164e-05, 'epoch': 6.07}         \n",
      "{'loss': 0.7416, 'learning_rate': 1.8754098360655738e-05, 'epoch': 6.23}        \n",
      "{'loss': 0.6949, 'learning_rate': 1.872131147540984e-05, 'epoch': 6.39}         \n",
      "{'loss': 0.7333, 'learning_rate': 1.8688524590163936e-05, 'epoch': 6.56}        \n",
      "{'loss': 0.6454, 'learning_rate': 1.8655737704918033e-05, 'epoch': 6.72}        \n",
      "{'loss': 0.7017, 'learning_rate': 1.862295081967213e-05, 'epoch': 6.89}         \n",
      "  7%|██▊                                     | 427/6100 [05:03<43:37,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:11:29,009 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:11:29,009 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:11:29,009 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.75it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.37it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6968235969543457, 'eval_accuracy': 0.7671033478893741, 'eval_runtime': 4.5828, 'eval_samples_per_second': 149.91, 'eval_steps_per_second': 2.4, 'epoch': 7.0}\n",
      "  7%|██▊                                     | 427/6100 [05:07<43:37,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.24it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:11:33,592 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-427\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:11:33,593 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-427/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:11:33,706 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-427/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:11:33,707 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-427/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:11:33,882 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-244] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6896, 'learning_rate': 1.859016393442623e-05, 'epoch': 7.05}         \n",
      "{'loss': 0.6655, 'learning_rate': 1.855737704918033e-05, 'epoch': 7.21}         \n",
      "{'loss': 0.7146, 'learning_rate': 1.852459016393443e-05, 'epoch': 7.38}         \n",
      "{'loss': 0.666, 'learning_rate': 1.8491803278688527e-05, 'epoch': 7.54}         \n",
      "{'loss': 0.7333, 'learning_rate': 1.8459016393442624e-05, 'epoch': 7.7}         \n",
      "{'loss': 0.7481, 'learning_rate': 1.842622950819672e-05, 'epoch': 7.87}         \n",
      "  8%|███▏                                    | 488/6100 [05:44<43:18,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:12:10,495 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:12:10,495 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:12:10,495 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.69it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.40it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.75it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.65it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6776266098022461, 'eval_accuracy': 0.7656477438136827, 'eval_runtime': 4.539, 'eval_samples_per_second': 151.353, 'eval_steps_per_second': 2.423, 'epoch': 8.0}\n",
      "  8%|███▏                                    | 488/6100 [05:49<43:18,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.25it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:12:15,034 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-488\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:12:15,035 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-488/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:12:15,154 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-488/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:12:15,154 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-488/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:12:15,329 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-305] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6822, 'learning_rate': 1.8393442622950822e-05, 'epoch': 8.03}        \n",
      "{'loss': 0.7149, 'learning_rate': 1.836065573770492e-05, 'epoch': 8.2}          \n",
      "{'loss': 0.7131, 'learning_rate': 1.832786885245902e-05, 'epoch': 8.36}         \n",
      "{'loss': 0.7158, 'learning_rate': 1.8295081967213114e-05, 'epoch': 8.52}        \n",
      "{'loss': 0.6443, 'learning_rate': 1.8262295081967215e-05, 'epoch': 8.69}        \n",
      "{'loss': 0.7243, 'learning_rate': 1.8229508196721312e-05, 'epoch': 8.85}        \n",
      "  9%|███▌                                    | 549/6100 [06:26<42:45,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:12:52,851 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:12:52,851 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:12:52,851 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.52it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.92it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6502252817153931, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 6.1659, 'eval_samples_per_second': 111.419, 'eval_steps_per_second': 1.784, 'epoch': 9.0}\n",
      "  9%|███▌                                    | 549/6100 [06:33<42:45,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:12:59,018 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-549\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:12:59,019 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-549/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:12:59,176 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-549/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:12:59,176 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-549/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:12:59,416 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-366] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6748, 'learning_rate': 1.8196721311475413e-05, 'epoch': 9.02}        \n",
      "{'loss': 0.6936, 'learning_rate': 1.816393442622951e-05, 'epoch': 9.18}         \n",
      "{'loss': 0.7183, 'learning_rate': 1.8131147540983608e-05, 'epoch': 9.34}        \n",
      "{'loss': 0.6992, 'learning_rate': 1.8098360655737705e-05, 'epoch': 9.51}        \n",
      "{'loss': 0.682, 'learning_rate': 1.8065573770491806e-05, 'epoch': 9.67}         \n",
      "{'loss': 0.6222, 'learning_rate': 1.8032786885245903e-05, 'epoch': 9.84}        \n",
      "{'loss': 0.6981, 'learning_rate': 1.8e-05, 'epoch': 10.0}                       \n",
      " 10%|████                                    | 610/6100 [07:11<50:50,  1.80it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:13:37,650 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:13:37,650 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:13:37,650 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.73it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.687023937702179, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 6.2876, 'eval_samples_per_second': 109.263, 'eval_steps_per_second': 1.749, 'epoch': 10.0}\n",
      " 10%|████                                    | 610/6100 [07:18<50:50,  1.80it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:13:43,938 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-610\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:13:43,940 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-610/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:13:44,115 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-610/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:13:44,115 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-610/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:13:44,355 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-427] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6424, 'learning_rate': 1.79672131147541e-05, 'epoch': 10.16}         \n",
      "{'loss': 0.7226, 'learning_rate': 1.79344262295082e-05, 'epoch': 10.33}         \n",
      "{'loss': 0.6926, 'learning_rate': 1.7901639344262296e-05, 'epoch': 10.49}       \n",
      "{'loss': 0.6628, 'learning_rate': 1.7868852459016393e-05, 'epoch': 10.66}       \n",
      "{'loss': 0.6769, 'learning_rate': 1.7836065573770494e-05, 'epoch': 10.82}       \n",
      "{'loss': 0.6812, 'learning_rate': 1.780327868852459e-05, 'epoch': 10.98}        \n",
      " 11%|████▍                                   | 671/6100 [07:56<50:40,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:14:22,271 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:14:22,271 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:14:22,271 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.24it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.31it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.34it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.32it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.33it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.33it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.644746720790863, 'eval_accuracy': 0.7816593886462883, 'eval_runtime': 5.2379, 'eval_samples_per_second': 131.16, 'eval_steps_per_second': 2.1, 'epoch': 11.0}\n",
      " 11%|████▍                                   | 671/6100 [08:01<50:40,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.17it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:14:27,509 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-671\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:14:27,510 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-671/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:14:27,625 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-671/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:14:27,626 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-671/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:14:27,798 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-488] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.635, 'learning_rate': 1.7770491803278692e-05, 'epoch': 11.15}        \n",
      "{'loss': 0.5764, 'learning_rate': 1.7737704918032786e-05, 'epoch': 11.31}       \n",
      "{'loss': 0.6709, 'learning_rate': 1.7704918032786887e-05, 'epoch': 11.48}       \n",
      "{'loss': 0.6914, 'learning_rate': 1.7672131147540984e-05, 'epoch': 11.64}       \n",
      "{'loss': 0.7374, 'learning_rate': 1.7639344262295085e-05, 'epoch': 11.8}        \n",
      "{'loss': 0.6867, 'learning_rate': 1.7606557377049182e-05, 'epoch': 11.97}       \n",
      " 12%|████▊                                   | 732/6100 [08:39<40:54,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:15:04,916 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:15:04,916 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:15:04,916 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.70it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6438639760017395, 'eval_accuracy': 0.7802037845705968, 'eval_runtime': 4.523, 'eval_samples_per_second': 151.889, 'eval_steps_per_second': 2.432, 'epoch': 12.0}\n",
      " 12%|████▊                                   | 732/6100 [08:43<40:54,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.27it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:15:09,440 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-732\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:15:09,440 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-732/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:15:09,606 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-732/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:15:09,607 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-732/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:15:09,775 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-549] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.731, 'learning_rate': 1.757377049180328e-05, 'epoch': 12.13}         \n",
      "{'loss': 0.6986, 'learning_rate': 1.7540983606557377e-05, 'epoch': 12.3}        \n",
      "{'loss': 0.6646, 'learning_rate': 1.7508196721311478e-05, 'epoch': 12.46}       \n",
      "{'loss': 0.5829, 'learning_rate': 1.7475409836065575e-05, 'epoch': 12.62}       \n",
      "{'loss': 0.6587, 'learning_rate': 1.7442622950819676e-05, 'epoch': 12.79}       \n",
      "{'loss': 0.6833, 'learning_rate': 1.740983606557377e-05, 'epoch': 12.95}        \n",
      " 13%|█████▏                                  | 793/6100 [09:21<41:14,  2.14it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:15:46,987 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:15:46,987 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:15:46,987 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.82it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.58it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.47it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.675788164138794, 'eval_accuracy': 0.7802037845705968, 'eval_runtime': 4.6045, 'eval_samples_per_second': 149.201, 'eval_steps_per_second': 2.389, 'epoch': 13.0}\n",
      " 13%|█████▏                                  | 793/6100 [09:25<41:14,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.28it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:15:51,592 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-793\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:15:51,592 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-793/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:15:51,705 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-793/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:15:51,706 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-793/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:15:51,882 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-610] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.701, 'learning_rate': 1.737704918032787e-05, 'epoch': 13.11}         \n",
      "{'loss': 0.7005, 'learning_rate': 1.7344262295081968e-05, 'epoch': 13.28}       \n",
      "{'loss': 0.6129, 'learning_rate': 1.731147540983607e-05, 'epoch': 13.44}        \n",
      "{'loss': 0.6657, 'learning_rate': 1.7278688524590166e-05, 'epoch': 13.61}       \n",
      "{'loss': 0.6605, 'learning_rate': 1.7245901639344263e-05, 'epoch': 13.77}       \n",
      "{'loss': 0.5966, 'learning_rate': 1.721311475409836e-05, 'epoch': 13.93}        \n",
      " 14%|█████▌                                  | 854/6100 [10:03<40:39,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:16:29,614 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:16:29,614 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:16:29,614 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.55it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.47it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.93it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6643763184547424, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 6.0189, 'eval_samples_per_second': 114.141, 'eval_steps_per_second': 1.828, 'epoch': 14.0}\n",
      " 14%|█████▌                                  | 854/6100 [10:09<40:39,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:16:35,633 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-854\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:16:35,634 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-854/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:16:35,787 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-854/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:16:35,787 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-854/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:16:36,033 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-671] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6555, 'learning_rate': 1.718032786885246e-05, 'epoch': 14.1}         \n",
      "{'loss': 0.6234, 'learning_rate': 1.714754098360656e-05, 'epoch': 14.26}        \n",
      "{'loss': 0.6202, 'learning_rate': 1.711475409836066e-05, 'epoch': 14.43}        \n",
      "{'loss': 0.6123, 'learning_rate': 1.7081967213114757e-05, 'epoch': 14.59}       \n",
      "{'loss': 0.6786, 'learning_rate': 1.7049180327868854e-05, 'epoch': 14.75}       \n",
      "{'loss': 0.6746, 'learning_rate': 1.701639344262295e-05, 'epoch': 14.92}        \n",
      " 15%|██████                                  | 915/6100 [10:48<45:13,  1.91it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:17:14,095 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:17:14,095 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:17:14,095 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6431153416633606, 'eval_accuracy': 0.7947598253275109, 'eval_runtime': 6.1728, 'eval_samples_per_second': 111.295, 'eval_steps_per_second': 1.782, 'epoch': 15.0}\n",
      " 15%|██████                                  | 915/6100 [10:54<45:13,  1.91it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:17:20,268 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-915\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:17:20,269 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-915/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:17:20,432 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-915/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:17:20,433 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-915/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:17:20,672 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-732] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6303, 'learning_rate': 1.6983606557377052e-05, 'epoch': 15.08}       \n",
      "{'loss': 0.6362, 'learning_rate': 1.695081967213115e-05, 'epoch': 15.25}        \n",
      "{'loss': 0.6151, 'learning_rate': 1.6918032786885247e-05, 'epoch': 15.41}       \n",
      "{'loss': 0.7019, 'learning_rate': 1.6885245901639347e-05, 'epoch': 15.57}       \n",
      "{'loss': 0.6216, 'learning_rate': 1.6852459016393445e-05, 'epoch': 15.74}       \n",
      "{'loss': 0.6342, 'learning_rate': 1.6819672131147542e-05, 'epoch': 15.9}        \n",
      " 16%|██████▍                                 | 976/6100 [11:32<47:26,  1.80it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:17:58,472 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:17:58,472 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:17:58,472 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7149138450622559, 'eval_accuracy': 0.7700145560407569, 'eval_runtime': 6.2031, 'eval_samples_per_second': 110.751, 'eval_steps_per_second': 1.773, 'epoch': 16.0}\n",
      " 16%|██████▍                                 | 976/6100 [11:38<47:26,  1.80it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:18:04,675 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-976\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:18:04,676 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-976/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:18:04,835 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-976/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:18:04,835 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-976/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:18:05,079 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-793] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6652, 'learning_rate': 1.678688524590164e-05, 'epoch': 16.07}        \n",
      "{'loss': 0.6677, 'learning_rate': 1.675409836065574e-05, 'epoch': 16.23}        \n",
      "{'loss': 0.5781, 'learning_rate': 1.6721311475409837e-05, 'epoch': 16.39}       \n",
      "{'loss': 0.6416, 'learning_rate': 1.6688524590163935e-05, 'epoch': 16.56}       \n",
      "{'loss': 0.7143, 'learning_rate': 1.6655737704918032e-05, 'epoch': 16.72}       \n",
      "{'loss': 0.5716, 'learning_rate': 1.6622950819672133e-05, 'epoch': 16.89}       \n",
      " 17%|██████▋                                | 1037/6100 [12:16<46:49,  1.80it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:18:42,836 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:18:42,836 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:18:42,836 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.44it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.84it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.643324613571167, 'eval_accuracy': 0.7874818049490538, 'eval_runtime': 6.2142, 'eval_samples_per_second': 110.554, 'eval_steps_per_second': 1.77, 'epoch': 17.0}\n",
      " 17%|██████▋                                | 1037/6100 [12:23<46:49,  1.80it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:18:49,052 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1037\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:18:49,053 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1037/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:18:49,219 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1037/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:18:49,219 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1037/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:18:49,467 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-854] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6289, 'learning_rate': 1.659016393442623e-05, 'epoch': 17.05}        \n",
      "{'loss': 0.5677, 'learning_rate': 1.655737704918033e-05, 'epoch': 17.21}        \n",
      "{'loss': 0.5836, 'learning_rate': 1.6524590163934428e-05, 'epoch': 17.38}       \n",
      "{'loss': 0.6404, 'learning_rate': 1.6491803278688526e-05, 'epoch': 17.54}       \n",
      "{'loss': 0.5987, 'learning_rate': 1.6459016393442623e-05, 'epoch': 17.7}        \n",
      "{'loss': 0.6151, 'learning_rate': 1.6426229508196724e-05, 'epoch': 17.87}       \n",
      " 18%|███████                                | 1098/6100 [13:00<39:35,  2.11it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:19:26,428 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:19:26,428 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:19:26,428 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.78it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.71it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6706465482711792, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 4.3917, 'eval_samples_per_second': 156.433, 'eval_steps_per_second': 2.505, 'epoch': 18.0}\n",
      " 18%|███████                                | 1098/6100 [13:04<39:35,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:19:30,820 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1098\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:19:30,821 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1098/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:19:30,925 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1098/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:19:30,925 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1098/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:19:31,091 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-976] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6482, 'learning_rate': 1.639344262295082e-05, 'epoch': 18.03}        \n",
      "{'loss': 0.5841, 'learning_rate': 1.6360655737704922e-05, 'epoch': 18.2}        \n",
      "{'loss': 0.6336, 'learning_rate': 1.6327868852459016e-05, 'epoch': 18.36}       \n",
      "{'loss': 0.5767, 'learning_rate': 1.6295081967213116e-05, 'epoch': 18.52}       \n",
      "{'loss': 0.6235, 'learning_rate': 1.6262295081967214e-05, 'epoch': 18.69}       \n",
      "{'loss': 0.6707, 'learning_rate': 1.6229508196721314e-05, 'epoch': 18.85}       \n",
      " 19%|███████▍                               | 1159/6100 [13:43<38:19,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:20:09,877 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:20:09,878 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:20:09,878 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.51it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.68it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6431100964546204, 'eval_accuracy': 0.7802037845705968, 'eval_runtime': 4.4612, 'eval_samples_per_second': 153.996, 'eval_steps_per_second': 2.466, 'epoch': 19.0}\n",
      " 19%|███████▍                               | 1159/6100 [13:48<38:19,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.24it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:20:14,339 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1159\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:20:14,340 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1159/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:20:14,461 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1159/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:20:14,462 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1159/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:20:14,637 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-915] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6277, 'learning_rate': 1.6196721311475412e-05, 'epoch': 19.02}       \n",
      "{'loss': 0.5577, 'learning_rate': 1.616393442622951e-05, 'epoch': 19.18}        \n",
      "{'loss': 0.5947, 'learning_rate': 1.6131147540983607e-05, 'epoch': 19.34}       \n",
      "{'loss': 0.5686, 'learning_rate': 1.6098360655737707e-05, 'epoch': 19.51}       \n",
      "{'loss': 0.5873, 'learning_rate': 1.6065573770491805e-05, 'epoch': 19.67}       \n",
      "{'loss': 0.5645, 'learning_rate': 1.6032786885245902e-05, 'epoch': 19.84}       \n",
      "{'loss': 0.6852, 'learning_rate': 1.6000000000000003e-05, 'epoch': 20.0}        \n",
      " 20%|███████▊                               | 1220/6100 [14:26<37:37,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:20:52,628 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:20:52,628 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:20:52,628 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.72it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.32it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.59it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.46it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.659214437007904, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.5926, 'eval_samples_per_second': 149.589, 'eval_steps_per_second': 2.395, 'epoch': 20.0}\n",
      " 20%|███████▊                               | 1220/6100 [14:31<37:37,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.21it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:20:57,221 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1220\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:20:57,221 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1220/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:20:57,332 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1220/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:20:57,332 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1220/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:20:57,512 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1037] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6028, 'learning_rate': 1.59672131147541e-05, 'epoch': 20.16}         \n",
      "{'loss': 0.5797, 'learning_rate': 1.5934426229508197e-05, 'epoch': 20.33}       \n",
      "{'loss': 0.5569, 'learning_rate': 1.5901639344262295e-05, 'epoch': 20.49}       \n",
      "{'loss': 0.5793, 'learning_rate': 1.5868852459016395e-05, 'epoch': 20.66}       \n",
      "{'loss': 0.5828, 'learning_rate': 1.5836065573770493e-05, 'epoch': 20.82}       \n",
      "{'loss': 0.5997, 'learning_rate': 1.580327868852459e-05, 'epoch': 20.98}        \n",
      " 21%|████████▏                              | 1281/6100 [15:09<36:24,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:21:35,376 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:21:35,376 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:21:35,376 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.91it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.97it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.19it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.06it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:01,  1.92it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.01it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6935475468635559, 'eval_accuracy': 0.7540029112081513, 'eval_runtime': 5.0912, 'eval_samples_per_second': 134.939, 'eval_steps_per_second': 2.161, 'epoch': 21.0}\n",
      " 21%|████████▏                              | 1281/6100 [15:14<36:24,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.64it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:21:40,468 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1281\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:21:40,469 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1281/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:21:40,623 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1281/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:21:40,623 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1281/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:21:40,861 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1098] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5909, 'learning_rate': 1.5770491803278687e-05, 'epoch': 21.15}       \n",
      "{'loss': 0.5254, 'learning_rate': 1.5737704918032788e-05, 'epoch': 21.31}       \n",
      "{'loss': 0.6022, 'learning_rate': 1.5704918032786886e-05, 'epoch': 21.48}       \n",
      "{'loss': 0.6857, 'learning_rate': 1.5672131147540986e-05, 'epoch': 21.64}       \n",
      "{'loss': 0.5589, 'learning_rate': 1.5639344262295084e-05, 'epoch': 21.8}        \n",
      "{'loss': 0.6075, 'learning_rate': 1.560655737704918e-05, 'epoch': 21.97}        \n",
      " 22%|████████▌                              | 1342/6100 [15:52<43:29,  1.82it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:22:18,676 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:22:18,677 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:22:18,677 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.57it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.78it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.65451979637146, 'eval_accuracy': 0.7758369723435226, 'eval_runtime': 6.2289, 'eval_samples_per_second': 110.292, 'eval_steps_per_second': 1.766, 'epoch': 22.0}\n",
      " 22%|████████▌                              | 1342/6100 [15:59<43:29,  1.82it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:22:24,906 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1342\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:22:24,907 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1342/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:22:25,065 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1342/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:22:25,066 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1342/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:22:25,309 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1220] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6006, 'learning_rate': 1.5573770491803278e-05, 'epoch': 22.13}       \n",
      "{'loss': 0.5494, 'learning_rate': 1.554098360655738e-05, 'epoch': 22.3}         \n",
      "{'loss': 0.5536, 'learning_rate': 1.5508196721311476e-05, 'epoch': 22.46}       \n",
      "{'loss': 0.6585, 'learning_rate': 1.5475409836065577e-05, 'epoch': 22.62}       \n",
      "{'loss': 0.556, 'learning_rate': 1.544262295081967e-05, 'epoch': 22.79}         \n",
      "{'loss': 0.5837, 'learning_rate': 1.5409836065573772e-05, 'epoch': 22.95}       \n",
      " 23%|████████▉                              | 1403/6100 [16:37<43:54,  1.78it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:23:03,129 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:23:03,129 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:23:03,129 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6559869647026062, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 6.1525, 'eval_samples_per_second': 111.662, 'eval_steps_per_second': 1.788, 'epoch': 23.0}\n",
      " 23%|████████▉                              | 1403/6100 [16:43<43:54,  1.78it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.89it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:23:09,282 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1403\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:23:09,283 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1403/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:23:09,418 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1403/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:23:09,419 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1403/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:23:09,669 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1281] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5785, 'learning_rate': 1.537704918032787e-05, 'epoch': 23.11}        \n",
      "{'loss': 0.5494, 'learning_rate': 1.534426229508197e-05, 'epoch': 23.28}        \n",
      "{'loss': 0.554, 'learning_rate': 1.5311475409836067e-05, 'epoch': 23.44}        \n",
      "{'loss': 0.5449, 'learning_rate': 1.5278688524590165e-05, 'epoch': 23.61}       \n",
      "{'loss': 0.579, 'learning_rate': 1.5245901639344264e-05, 'epoch': 23.77}        \n",
      "{'loss': 0.582, 'learning_rate': 1.5213114754098361e-05, 'epoch': 23.93}        \n",
      " 24%|█████████▎                             | 1464/6100 [17:20<36:49,  2.10it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:23:46,704 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:23:46,704 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:23:46,704 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.02it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.72it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6285605430603027, 'eval_accuracy': 0.784570596797671, 'eval_runtime': 4.4675, 'eval_samples_per_second': 153.778, 'eval_steps_per_second': 2.462, 'epoch': 24.0}\n",
      " 24%|█████████▎                             | 1464/6100 [17:25<36:49,  2.10it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:23:51,172 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1464\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:23:51,172 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1464/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:23:51,290 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1464/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:23:51,291 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1464/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:23:51,470 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1159] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6087, 'learning_rate': 1.518032786885246e-05, 'epoch': 24.1}         \n",
      "{'loss': 0.5507, 'learning_rate': 1.5147540983606559e-05, 'epoch': 24.26}       \n",
      "{'loss': 0.5458, 'learning_rate': 1.5114754098360658e-05, 'epoch': 24.43}       \n",
      "{'loss': 0.5312, 'learning_rate': 1.5081967213114754e-05, 'epoch': 24.59}       \n",
      "{'loss': 0.553, 'learning_rate': 1.5049180327868853e-05, 'epoch': 24.75}        \n",
      "{'loss': 0.6072, 'learning_rate': 1.5016393442622952e-05, 'epoch': 24.92}       \n",
      " 25%|█████████▊                             | 1525/6100 [18:03<35:29,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:24:29,660 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:24:29,660 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:24:29,660 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.80it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6584755182266235, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.5827, 'eval_samples_per_second': 149.911, 'eval_steps_per_second': 2.4, 'epoch': 25.0}\n",
      " 25%|█████████▊                             | 1525/6100 [18:08<35:29,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.24it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:24:34,243 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1525\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:24:34,244 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1525/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:24:34,358 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1525/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:24:34,359 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1525/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:24:34,531 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1342] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5283, 'learning_rate': 1.498360655737705e-05, 'epoch': 25.08}        \n",
      "{'loss': 0.4846, 'learning_rate': 1.495081967213115e-05, 'epoch': 25.25}        \n",
      "{'loss': 0.5684, 'learning_rate': 1.4918032786885249e-05, 'epoch': 25.41}       \n",
      "{'loss': 0.5679, 'learning_rate': 1.4885245901639344e-05, 'epoch': 25.57}       \n",
      "{'loss': 0.5683, 'learning_rate': 1.4852459016393443e-05, 'epoch': 25.74}       \n",
      "{'loss': 0.5925, 'learning_rate': 1.4819672131147543e-05, 'epoch': 25.9}        \n",
      " 26%|██████████▏                            | 1586/6100 [18:48<35:01,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:25:14,212 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:25:14,212 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:25:14,212 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.94it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.50it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6391500234603882, 'eval_accuracy': 0.7874818049490538, 'eval_runtime': 4.5463, 'eval_samples_per_second': 151.113, 'eval_steps_per_second': 2.42, 'epoch': 26.0}\n",
      " 26%|██████████▏                            | 1586/6100 [18:52<35:01,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.23it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:25:18,758 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1586\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:25:18,759 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1586/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:25:18,879 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1586/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:25:18,879 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1586/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:25:19,053 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1403] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4824, 'learning_rate': 1.4786885245901642e-05, 'epoch': 26.07}       \n",
      "{'loss': 0.5343, 'learning_rate': 1.4754098360655739e-05, 'epoch': 26.23}       \n",
      "{'loss': 0.5271, 'learning_rate': 1.4721311475409836e-05, 'epoch': 26.39}       \n",
      "{'loss': 0.5283, 'learning_rate': 1.4688524590163935e-05, 'epoch': 26.56}       \n",
      "{'loss': 0.5328, 'learning_rate': 1.4655737704918034e-05, 'epoch': 26.72}       \n",
      "{'loss': 0.5746, 'learning_rate': 1.4622950819672133e-05, 'epoch': 26.89}       \n",
      " 27%|██████████▌                            | 1647/6100 [19:30<34:13,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:25:56,189 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:25:56,189 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:25:56,189 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.27it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  2.98it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.59it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.42it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.36it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.33it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.640012800693512, 'eval_accuracy': 0.7933042212518195, 'eval_runtime': 4.6856, 'eval_samples_per_second': 146.62, 'eval_steps_per_second': 2.348, 'epoch': 27.0}\n",
      " 27%|██████████▌                            | 1647/6100 [19:34<34:13,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.15it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:26:00,875 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1647\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:26:00,876 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1647/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:26:00,990 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1647/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:26:00,991 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1647/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:26:01,168 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1525] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5524, 'learning_rate': 1.459016393442623e-05, 'epoch': 27.05}        \n",
      "{'loss': 0.4589, 'learning_rate': 1.455737704918033e-05, 'epoch': 27.21}        \n",
      "{'loss': 0.5492, 'learning_rate': 1.4524590163934427e-05, 'epoch': 27.38}       \n",
      "{'loss': 0.5532, 'learning_rate': 1.4491803278688526e-05, 'epoch': 27.54}       \n",
      "{'loss': 0.5617, 'learning_rate': 1.4459016393442623e-05, 'epoch': 27.7}        \n",
      "{'loss': 0.5724, 'learning_rate': 1.4426229508196722e-05, 'epoch': 27.87}       \n",
      " 28%|██████████▉                            | 1708/6100 [20:13<38:06,  1.92it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:26:39,151 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:26:39,151 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:26:39,151 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7053677439689636, 'eval_accuracy': 0.784570596797671, 'eval_runtime': 6.2364, 'eval_samples_per_second': 110.16, 'eval_steps_per_second': 1.764, 'epoch': 28.0}\n",
      " 28%|██████████▉                            | 1708/6100 [20:19<38:06,  1.92it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:26:45,388 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1708\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:26:45,389 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1708/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:26:45,545 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1708/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:26:45,546 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1708/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:26:45,795 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1586] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5261, 'learning_rate': 1.4393442622950822e-05, 'epoch': 28.03}       \n",
      "{'loss': 0.5325, 'learning_rate': 1.4360655737704919e-05, 'epoch': 28.2}        \n",
      "{'loss': 0.5586, 'learning_rate': 1.4327868852459016e-05, 'epoch': 28.36}       \n",
      "{'loss': 0.4962, 'learning_rate': 1.4295081967213115e-05, 'epoch': 28.52}       \n",
      "{'loss': 0.4778, 'learning_rate': 1.4262295081967214e-05, 'epoch': 28.69}       \n",
      "{'loss': 0.5371, 'learning_rate': 1.4229508196721313e-05, 'epoch': 28.85}       \n",
      " 29%|███████████▎                           | 1769/6100 [20:58<41:06,  1.76it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:27:23,985 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:27:23,986 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:27:23,986 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6631751656532288, 'eval_accuracy': 0.7685589519650655, 'eval_runtime': 6.2387, 'eval_samples_per_second': 110.119, 'eval_steps_per_second': 1.763, 'epoch': 29.0}\n",
      " 29%|███████████▎                           | 1769/6100 [21:04<41:06,  1.76it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:27:30,225 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1769\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:27:30,226 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1769/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:27:30,383 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1769/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:27:30,383 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1769/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:27:30,624 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1647] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5658, 'learning_rate': 1.4196721311475412e-05, 'epoch': 29.02}       \n",
      "{'loss': 0.527, 'learning_rate': 1.4163934426229508e-05, 'epoch': 29.18}        \n",
      "{'loss': 0.4843, 'learning_rate': 1.4131147540983607e-05, 'epoch': 29.34}       \n",
      "{'loss': 0.5247, 'learning_rate': 1.4098360655737706e-05, 'epoch': 29.51}       \n",
      "{'loss': 0.5444, 'learning_rate': 1.4065573770491805e-05, 'epoch': 29.67}       \n",
      "{'loss': 0.5289, 'learning_rate': 1.4032786885245904e-05, 'epoch': 29.84}       \n",
      "{'loss': 0.568, 'learning_rate': 1.4e-05, 'epoch': 30.0}                        \n",
      " 30%|███████████▋                           | 1830/6100 [21:42<40:20,  1.76it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:28:08,668 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:28:08,668 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:28:08,668 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.29it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  1.99it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.88it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.84it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.98it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.08it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.18it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.673910915851593, 'eval_accuracy': 0.7918486171761281, 'eval_runtime': 5.7133, 'eval_samples_per_second': 120.245, 'eval_steps_per_second': 1.925, 'epoch': 30.0}\n",
      " 30%|███████████▋                           | 1830/6100 [21:48<40:20,  1.76it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.30it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:28:14,382 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1830\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:28:14,383 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1830/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:28:14,500 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1830/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:28:14,501 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1830/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:28:14,674 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1708] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5228, 'learning_rate': 1.3967213114754099e-05, 'epoch': 30.16}       \n",
      "{'loss': 0.4959, 'learning_rate': 1.3934426229508198e-05, 'epoch': 30.33}       \n",
      "{'loss': 0.4789, 'learning_rate': 1.3901639344262297e-05, 'epoch': 30.49}       \n",
      "{'loss': 0.4912, 'learning_rate': 1.3868852459016396e-05, 'epoch': 30.66}       \n",
      "{'loss': 0.5215, 'learning_rate': 1.3836065573770492e-05, 'epoch': 30.82}       \n",
      "{'loss': 0.5444, 'learning_rate': 1.380327868852459e-05, 'epoch': 30.98}        \n",
      " 31%|████████████                           | 1891/6100 [22:25<32:28,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:28:51,763 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:28:51,763 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:28:51,763 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6648625135421753, 'eval_accuracy': 0.7831149927219796, 'eval_runtime': 4.5978, 'eval_samples_per_second': 149.418, 'eval_steps_per_second': 2.392, 'epoch': 31.0}\n",
      " 31%|████████████                           | 1891/6100 [22:30<32:28,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.18it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:28:56,361 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1891\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:28:56,362 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1891/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:28:56,475 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1891/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:28:56,476 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1891/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:28:56,655 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1769] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4695, 'learning_rate': 1.377049180327869e-05, 'epoch': 31.15}        \n",
      "{'loss': 0.4996, 'learning_rate': 1.3737704918032789e-05, 'epoch': 31.31}       \n",
      "{'loss': 0.5487, 'learning_rate': 1.3704918032786888e-05, 'epoch': 31.48}       \n",
      "{'loss': 0.4822, 'learning_rate': 1.3672131147540985e-05, 'epoch': 31.64}       \n",
      "{'loss': 0.5043, 'learning_rate': 1.3639344262295082e-05, 'epoch': 31.8}        \n",
      "{'loss': 0.4551, 'learning_rate': 1.3606557377049181e-05, 'epoch': 31.97}       \n",
      " 32%|████████████▍                          | 1952/6100 [23:10<32:12,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:29:36,180 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:29:36,180 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:29:36,180 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.96it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.33it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6648269891738892, 'eval_accuracy': 0.7831149927219796, 'eval_runtime': 4.5274, 'eval_samples_per_second': 151.744, 'eval_steps_per_second': 2.43, 'epoch': 32.0}\n",
      " 32%|████████████▍                          | 1952/6100 [23:14<32:12,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.25it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:29:40,707 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1952\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:29:40,708 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1952/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:29:40,835 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1952/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:29:40,836 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1952/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:29:41,007 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1830] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.538, 'learning_rate': 1.357377049180328e-05, 'epoch': 32.13}         \n",
      "{'loss': 0.4831, 'learning_rate': 1.3540983606557378e-05, 'epoch': 32.3}        \n",
      "{'loss': 0.4582, 'learning_rate': 1.3508196721311477e-05, 'epoch': 32.46}       \n",
      "{'loss': 0.5772, 'learning_rate': 1.3475409836065574e-05, 'epoch': 32.62}       \n",
      "{'loss': 0.5221, 'learning_rate': 1.3442622950819673e-05, 'epoch': 32.79}       \n",
      "{'loss': 0.5241, 'learning_rate': 1.340983606557377e-05, 'epoch': 32.95}        \n",
      " 33%|████████████▊                          | 2013/6100 [23:52<31:50,  2.14it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:30:18,245 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:30:18,245 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:30:18,245 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.68it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.61it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.33it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.29it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6439855694770813, 'eval_accuracy': 0.7933042212518195, 'eval_runtime': 4.6475, 'eval_samples_per_second': 147.822, 'eval_steps_per_second': 2.367, 'epoch': 33.0}\n",
      " 33%|████████████▊                          | 2013/6100 [23:57<31:50,  2.14it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.13it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:30:22,893 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2013\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:30:22,894 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2013/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:30:23,012 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2013/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:30:23,013 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2013/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:30:23,188 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1891] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4708, 'learning_rate': 1.337704918032787e-05, 'epoch': 33.11}        \n",
      "{'loss': 0.4777, 'learning_rate': 1.3344262295081969e-05, 'epoch': 33.28}       \n",
      "{'loss': 0.5017, 'learning_rate': 1.3311475409836068e-05, 'epoch': 33.44}       \n",
      "{'loss': 0.529, 'learning_rate': 1.3278688524590165e-05, 'epoch': 33.61}        \n",
      "{'loss': 0.5491, 'learning_rate': 1.3245901639344262e-05, 'epoch': 33.77}       \n",
      "{'loss': 0.4831, 'learning_rate': 1.3213114754098361e-05, 'epoch': 33.93}       \n",
      " 34%|█████████████▎                         | 2074/6100 [24:35<31:29,  2.13it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:31:01,362 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:31:01,362 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:31:01,362 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  2.91it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.27it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.07it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.97it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.88it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.82it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.82it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.700412929058075, 'eval_accuracy': 0.777292576419214, 'eval_runtime': 5.685, 'eval_samples_per_second': 120.845, 'eval_steps_per_second': 1.935, 'epoch': 34.0}\n",
      " 34%|█████████████▎                         | 2074/6100 [24:41<31:29,  2.13it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:31:07,047 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2074\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:31:07,049 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2074/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:31:07,219 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2074/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:31:07,220 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2074/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:31:07,463 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1952] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4377, 'learning_rate': 1.318032786885246e-05, 'epoch': 34.1}         \n",
      "{'loss': 0.492, 'learning_rate': 1.314754098360656e-05, 'epoch': 34.26}         \n",
      "{'loss': 0.484, 'learning_rate': 1.3114754098360655e-05, 'epoch': 34.43}        \n",
      "{'loss': 0.5016, 'learning_rate': 1.3081967213114754e-05, 'epoch': 34.59}       \n",
      "{'loss': 0.52, 'learning_rate': 1.3049180327868853e-05, 'epoch': 34.75}         \n",
      "{'loss': 0.5096, 'learning_rate': 1.3016393442622952e-05, 'epoch': 34.92}       \n",
      " 35%|█████████████▋                         | 2135/6100 [25:19<36:55,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:31:45,247 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:31:45,247 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:31:45,247 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7068610787391663, 'eval_accuracy': 0.7656477438136827, 'eval_runtime': 6.2058, 'eval_samples_per_second': 110.703, 'eval_steps_per_second': 1.773, 'epoch': 35.0}\n",
      " 35%|█████████████▋                         | 2135/6100 [25:25<36:55,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:31:51,454 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2135\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:31:51,454 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2135/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:31:51,610 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2135/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:31:51,611 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2135/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:31:51,851 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2013] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4812, 'learning_rate': 1.2983606557377051e-05, 'epoch': 35.08}       \n",
      "{'loss': 0.4736, 'learning_rate': 1.295081967213115e-05, 'epoch': 35.25}        \n",
      "{'loss': 0.4754, 'learning_rate': 1.2918032786885246e-05, 'epoch': 35.41}       \n",
      "{'loss': 0.4068, 'learning_rate': 1.2885245901639345e-05, 'epoch': 35.57}       \n",
      "{'loss': 0.4482, 'learning_rate': 1.2852459016393444e-05, 'epoch': 35.74}       \n",
      "{'loss': 0.4956, 'learning_rate': 1.2819672131147543e-05, 'epoch': 35.9}        \n",
      " 36%|██████████████                         | 2196/6100 [26:03<36:41,  1.77it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:32:29,883 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:32:29,883 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:32:29,883 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.55it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.48it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.44it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.43it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.35it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.31it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.28it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6827777028083801, 'eval_accuracy': 0.7903930131004366, 'eval_runtime': 5.1361, 'eval_samples_per_second': 133.758, 'eval_steps_per_second': 2.142, 'epoch': 36.0}\n",
      " 36%|██████████████                         | 2196/6100 [26:09<36:41,  1.77it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.16it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:32:35,019 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2196\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:32:35,020 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2196/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:32:35,137 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2196/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:32:35,139 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2196/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:32:35,317 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2074] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4326, 'learning_rate': 1.2786885245901642e-05, 'epoch': 36.07}       \n",
      "{'loss': 0.4771, 'learning_rate': 1.2754098360655738e-05, 'epoch': 36.23}       \n",
      "{'loss': 0.4249, 'learning_rate': 1.2721311475409837e-05, 'epoch': 36.39}       \n",
      "{'loss': 0.4485, 'learning_rate': 1.2688524590163936e-05, 'epoch': 36.56}       \n",
      "{'loss': 0.5376, 'learning_rate': 1.2655737704918035e-05, 'epoch': 36.72}       \n",
      "{'loss': 0.4816, 'learning_rate': 1.2622950819672132e-05, 'epoch': 36.89}       \n",
      " 37%|██████████████▍                        | 2257/6100 [26:47<30:41,  2.09it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:33:13,610 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:33:13,610 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:33:13,610 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.00it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6762523651123047, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.506, 'eval_samples_per_second': 152.463, 'eval_steps_per_second': 2.441, 'epoch': 37.0}\n",
      " 37%|██████████████▍                        | 2257/6100 [26:52<30:41,  2.09it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:33:18,116 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2257\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:33:18,117 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2257/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:33:18,217 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2257/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:33:18,217 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2257/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:33:18,391 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2135] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4472, 'learning_rate': 1.2590163934426231e-05, 'epoch': 37.05}       \n",
      "{'loss': 0.4593, 'learning_rate': 1.2557377049180329e-05, 'epoch': 37.21}       \n",
      "{'loss': 0.4408, 'learning_rate': 1.2524590163934428e-05, 'epoch': 37.38}       \n",
      "{'loss': 0.4523, 'learning_rate': 1.2491803278688525e-05, 'epoch': 37.54}       \n",
      "{'loss': 0.4605, 'learning_rate': 1.2459016393442624e-05, 'epoch': 37.7}        \n",
      "{'loss': 0.4863, 'learning_rate': 1.2426229508196723e-05, 'epoch': 37.87}       \n",
      " 38%|██████████████▊                        | 2318/6100 [27:31<28:50,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:33:57,348 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:33:57,348 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:33:57,348 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.00it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.53it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.34it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6562838554382324, 'eval_accuracy': 0.7933042212518195, 'eval_runtime': 4.5406, 'eval_samples_per_second': 151.302, 'eval_steps_per_second': 2.423, 'epoch': 38.0}\n",
      " 38%|██████████████▊                        | 2318/6100 [27:36<28:50,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.21it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:34:01,889 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2318\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:34:01,890 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2318/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:34:02,005 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2318/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:34:02,006 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2318/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:34:02,180 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2196] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4509, 'learning_rate': 1.239344262295082e-05, 'epoch': 38.03}        \n",
      "{'loss': 0.4074, 'learning_rate': 1.236065573770492e-05, 'epoch': 38.2}         \n",
      "{'loss': 0.4989, 'learning_rate': 1.2327868852459017e-05, 'epoch': 38.36}       \n",
      "{'loss': 0.4537, 'learning_rate': 1.2295081967213116e-05, 'epoch': 38.52}       \n",
      "{'loss': 0.4253, 'learning_rate': 1.2262295081967215e-05, 'epoch': 38.69}       \n",
      "{'loss': 0.4101, 'learning_rate': 1.2229508196721312e-05, 'epoch': 38.85}       \n",
      " 39%|███████████████▏                       | 2379/6100 [28:14<28:51,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:34:40,661 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:34:40,661 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:34:40,661 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.53it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.95it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6797528862953186, 'eval_accuracy': 0.7831149927219796, 'eval_runtime': 4.5564, 'eval_samples_per_second': 150.778, 'eval_steps_per_second': 2.414, 'epoch': 39.0}\n",
      " 39%|███████████████▏                       | 2379/6100 [28:19<28:51,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:34:45,218 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2379\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:34:45,219 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2379/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:34:45,330 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2379/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:34:45,331 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2379/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:34:45,505 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2257] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5284, 'learning_rate': 1.219672131147541e-05, 'epoch': 39.02}        \n",
      "{'loss': 0.4623, 'learning_rate': 1.2163934426229509e-05, 'epoch': 39.18}       \n",
      "{'loss': 0.4781, 'learning_rate': 1.2131147540983608e-05, 'epoch': 39.34}       \n",
      "{'loss': 0.4687, 'learning_rate': 1.2098360655737707e-05, 'epoch': 39.51}       \n",
      "{'loss': 0.4448, 'learning_rate': 1.2065573770491806e-05, 'epoch': 39.67}       \n",
      "{'loss': 0.3958, 'learning_rate': 1.2032786885245901e-05, 'epoch': 39.84}       \n",
      "{'loss': 0.495, 'learning_rate': 1.2e-05, 'epoch': 40.0}                        \n",
      " 40%|███████████████▌                       | 2440/6100 [28:57<27:38,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:35:23,547 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:35:23,547 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:35:23,548 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.97it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.70it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.58it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6957675814628601, 'eval_accuracy': 0.7714701601164483, 'eval_runtime': 4.5628, 'eval_samples_per_second': 150.565, 'eval_steps_per_second': 2.411, 'epoch': 40.0}\n",
      " 40%|███████████████▌                       | 2440/6100 [29:02<27:38,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.16it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:35:28,111 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2440\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:35:28,112 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2440/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:35:28,229 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2440/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:35:28,230 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2440/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:35:28,412 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2318] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4529, 'learning_rate': 1.19672131147541e-05, 'epoch': 40.16}         \n",
      "{'loss': 0.4312, 'learning_rate': 1.1934426229508198e-05, 'epoch': 40.33}       \n",
      "{'loss': 0.4299, 'learning_rate': 1.1901639344262297e-05, 'epoch': 40.49}       \n",
      "{'loss': 0.4092, 'learning_rate': 1.1868852459016393e-05, 'epoch': 40.66}       \n",
      "{'loss': 0.474, 'learning_rate': 1.1836065573770492e-05, 'epoch': 40.82}        \n",
      "{'loss': 0.4418, 'learning_rate': 1.1803278688524591e-05, 'epoch': 40.98}       \n",
      " 41%|███████████████▉                       | 2501/6100 [29:41<27:31,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:36:07,385 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:36:07,385 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:36:07,385 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.80it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7043818235397339, 'eval_accuracy': 0.7700145560407569, 'eval_runtime': 4.5358, 'eval_samples_per_second': 151.46, 'eval_steps_per_second': 2.425, 'epoch': 41.0}\n",
      " 41%|███████████████▉                       | 2501/6100 [29:46<27:31,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:36:11,921 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2501\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:36:11,922 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2501/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:36:12,032 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2501/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:36:12,033 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2501/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:36:12,209 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2379] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4714, 'learning_rate': 1.177049180327869e-05, 'epoch': 41.15}        \n",
      "{'loss': 0.4588, 'learning_rate': 1.173770491803279e-05, 'epoch': 41.31}        \n",
      "{'loss': 0.4088, 'learning_rate': 1.1704918032786887e-05, 'epoch': 41.48}       \n",
      "{'loss': 0.4135, 'learning_rate': 1.1672131147540984e-05, 'epoch': 41.64}       \n",
      "{'loss': 0.4529, 'learning_rate': 1.1639344262295083e-05, 'epoch': 41.8}        \n",
      "{'loss': 0.4514, 'learning_rate': 1.1606557377049182e-05, 'epoch': 41.97}       \n",
      " 42%|████████████████▍                      | 2562/6100 [30:24<27:02,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:36:50,452 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:36:50,452 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:36:50,452 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.53it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.74it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.56it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.50it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.33it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.05it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6937069296836853, 'eval_accuracy': 0.759825327510917, 'eval_runtime': 4.9622, 'eval_samples_per_second': 138.445, 'eval_steps_per_second': 2.217, 'epoch': 42.0}\n",
      " 42%|████████████████▍                      | 2562/6100 [30:29<27:02,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.06it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:36:55,415 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2562\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:36:55,416 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2562/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:36:55,575 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2562/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:36:55,576 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2562/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:36:55,821 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2440] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4297, 'learning_rate': 1.157377049180328e-05, 'epoch': 42.13}        \n",
      "{'loss': 0.4755, 'learning_rate': 1.1540983606557378e-05, 'epoch': 42.3}        \n",
      "{'loss': 0.4257, 'learning_rate': 1.1508196721311476e-05, 'epoch': 42.46}       \n",
      "{'loss': 0.4625, 'learning_rate': 1.1475409836065575e-05, 'epoch': 42.62}       \n",
      "{'loss': 0.4496, 'learning_rate': 1.1442622950819672e-05, 'epoch': 42.79}       \n",
      "{'loss': 0.4018, 'learning_rate': 1.1409836065573771e-05, 'epoch': 42.95}       \n",
      " 43%|████████████████▊                      | 2623/6100 [31:08<28:27,  2.04it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:37:33,984 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:37:33,984 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:37:33,984 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.05it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.710725724697113, 'eval_accuracy': 0.777292576419214, 'eval_runtime': 6.2549, 'eval_samples_per_second': 109.834, 'eval_steps_per_second': 1.759, 'epoch': 43.0}\n",
      " 43%|████████████████▊                      | 2623/6100 [31:14<28:27,  2.04it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:37:40,240 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2623\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:37:40,241 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2623/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:37:40,392 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2623/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:37:40,393 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2623/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:37:40,636 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2501] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4527, 'learning_rate': 1.137704918032787e-05, 'epoch': 43.11}        \n",
      "{'loss': 0.4276, 'learning_rate': 1.134426229508197e-05, 'epoch': 43.28}        \n",
      "{'loss': 0.442, 'learning_rate': 1.1311475409836066e-05, 'epoch': 43.44}        \n",
      "{'loss': 0.4809, 'learning_rate': 1.1278688524590164e-05, 'epoch': 43.61}       \n",
      "{'loss': 0.435, 'learning_rate': 1.1245901639344263e-05, 'epoch': 43.77}        \n",
      "{'loss': 0.4108, 'learning_rate': 1.1213114754098362e-05, 'epoch': 43.93}       \n",
      " 44%|█████████████████▏                     | 2684/6100 [31:52<32:18,  1.76it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:38:18,640 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:38:18,640 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:38:18,640 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7418193221092224, 'eval_accuracy': 0.7510917030567685, 'eval_runtime': 6.2454, 'eval_samples_per_second': 110.0, 'eval_steps_per_second': 1.761, 'epoch': 44.0}\n",
      " 44%|█████████████████▏                     | 2684/6100 [31:58<32:18,  1.76it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:38:24,887 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2684\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:38:24,888 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2684/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:38:25,064 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2684/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:38:25,065 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2684/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:38:25,307 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2562] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.425, 'learning_rate': 1.1180327868852461e-05, 'epoch': 44.1}         \n",
      "{'loss': 0.4582, 'learning_rate': 1.1147540983606557e-05, 'epoch': 44.26}       \n",
      "{'loss': 0.4201, 'learning_rate': 1.1114754098360656e-05, 'epoch': 44.43}       \n",
      "{'loss': 0.4156, 'learning_rate': 1.1081967213114755e-05, 'epoch': 44.59}       \n",
      "{'loss': 0.428, 'learning_rate': 1.1049180327868854e-05, 'epoch': 44.75}        \n",
      "{'loss': 0.4603, 'learning_rate': 1.1016393442622953e-05, 'epoch': 44.92}       \n",
      " 45%|█████████████████▌                     | 2745/6100 [32:37<31:15,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:39:03,082 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:39:03,082 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:39:03,082 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.05it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7414473295211792, 'eval_accuracy': 0.7816593886462883, 'eval_runtime': 6.2023, 'eval_samples_per_second': 110.765, 'eval_steps_per_second': 1.774, 'epoch': 45.0}\n",
      " 45%|█████████████████▌                     | 2745/6100 [32:43<31:15,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:39:09,290 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2745\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:39:09,291 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2745/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:39:09,445 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2745/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:39:09,445 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2745/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:39:09,689 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2623] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3999, 'learning_rate': 1.0983606557377052e-05, 'epoch': 45.08}       \n",
      "{'loss': 0.3885, 'learning_rate': 1.0950819672131147e-05, 'epoch': 45.25}       \n",
      "{'loss': 0.4297, 'learning_rate': 1.0918032786885246e-05, 'epoch': 45.41}       \n",
      "{'loss': 0.4088, 'learning_rate': 1.0885245901639345e-05, 'epoch': 45.57}       \n",
      "{'loss': 0.4568, 'learning_rate': 1.0852459016393445e-05, 'epoch': 45.74}       \n",
      "{'loss': 0.3888, 'learning_rate': 1.0819672131147544e-05, 'epoch': 45.9}        \n",
      " 46%|█████████████████▉                     | 2806/6100 [33:21<31:04,  1.77it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:39:47,846 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:39:47,846 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:39:47,846 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7109038233757019, 'eval_accuracy': 0.777292576419214, 'eval_runtime': 6.2764, 'eval_samples_per_second': 109.458, 'eval_steps_per_second': 1.753, 'epoch': 46.0}\n",
      " 46%|█████████████████▉                     | 2806/6100 [33:28<31:04,  1.77it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:39:54,124 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2806\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:39:54,125 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2806/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:39:54,290 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2806/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:39:54,291 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2806/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:39:54,540 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2684] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4414, 'learning_rate': 1.078688524590164e-05, 'epoch': 46.07}        \n",
      "{'loss': 0.366, 'learning_rate': 1.0754098360655738e-05, 'epoch': 46.23}        \n",
      "{'loss': 0.4068, 'learning_rate': 1.0721311475409837e-05, 'epoch': 46.39}       \n",
      "{'loss': 0.432, 'learning_rate': 1.0688524590163936e-05, 'epoch': 46.56}        \n",
      "{'loss': 0.448, 'learning_rate': 1.0655737704918034e-05, 'epoch': 46.72}        \n",
      "{'loss': 0.4398, 'learning_rate': 1.0622950819672131e-05, 'epoch': 46.89}       \n",
      " 47%|██████████████████▎                    | 2867/6100 [34:06<27:37,  1.95it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:40:32,582 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:40:32,582 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:40:32,582 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7353067994117737, 'eval_accuracy': 0.7641921397379913, 'eval_runtime': 4.5892, 'eval_samples_per_second': 149.701, 'eval_steps_per_second': 2.397, 'epoch': 47.0}\n",
      " 47%|██████████████████▎                    | 2867/6100 [34:11<27:37,  1.95it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:40:37,172 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2867\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:40:37,172 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2867/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:40:37,289 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2867/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:40:37,290 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2867/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:40:37,462 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2745] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3891, 'learning_rate': 1.059016393442623e-05, 'epoch': 47.05}        \n",
      "{'loss': 0.381, 'learning_rate': 1.0557377049180329e-05, 'epoch': 47.21}        \n",
      "{'loss': 0.4189, 'learning_rate': 1.0524590163934426e-05, 'epoch': 47.38}       \n",
      "{'loss': 0.3902, 'learning_rate': 1.0491803278688525e-05, 'epoch': 47.54}       \n",
      "{'loss': 0.3675, 'learning_rate': 1.0459016393442624e-05, 'epoch': 47.7}        \n",
      "{'loss': 0.4226, 'learning_rate': 1.0426229508196722e-05, 'epoch': 47.87}       \n",
      " 48%|██████████████████▋                    | 2928/6100 [34:48<24:11,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:41:14,778 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:41:14,778 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:41:14,778 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.46it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6982101202011108, 'eval_accuracy': 0.7671033478893741, 'eval_runtime': 4.5445, 'eval_samples_per_second': 151.172, 'eval_steps_per_second': 2.421, 'epoch': 48.0}\n",
      " 48%|██████████████████▋                    | 2928/6100 [34:53<24:11,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:41:19,323 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2928\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:41:19,324 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2928/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:41:19,443 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2928/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:41:19,443 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2928/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:41:19,625 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2806] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4343, 'learning_rate': 1.0393442622950821e-05, 'epoch': 48.03}       \n",
      "{'loss': 0.3869, 'learning_rate': 1.0360655737704918e-05, 'epoch': 48.2}        \n",
      "{'loss': 0.3892, 'learning_rate': 1.0327868852459017e-05, 'epoch': 48.36}       \n",
      "{'loss': 0.4078, 'learning_rate': 1.0295081967213116e-05, 'epoch': 48.52}       \n",
      "{'loss': 0.3608, 'learning_rate': 1.0262295081967214e-05, 'epoch': 48.69}       \n",
      "{'loss': 0.4551, 'learning_rate': 1.0229508196721311e-05, 'epoch': 48.85}       \n",
      " 49%|███████████████████                    | 2989/6100 [35:31<24:08,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:41:57,831 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:41:57,831 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:41:57,831 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.74it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.62it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7337098717689514, 'eval_accuracy': 0.7758369723435226, 'eval_runtime': 4.5588, 'eval_samples_per_second': 150.697, 'eval_steps_per_second': 2.413, 'epoch': 49.0}\n",
      " 49%|███████████████████                    | 2989/6100 [35:36<24:08,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:42:02,390 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2989\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:42:02,390 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2989/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:42:02,501 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2989/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:42:02,501 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2989/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:42:02,680 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2867] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3554, 'learning_rate': 1.019672131147541e-05, 'epoch': 49.02}        \n",
      "{'loss': 0.384, 'learning_rate': 1.0163934426229509e-05, 'epoch': 49.18}        \n",
      "{'loss': 0.4103, 'learning_rate': 1.0131147540983608e-05, 'epoch': 49.34}       \n",
      "{'loss': 0.4233, 'learning_rate': 1.0098360655737707e-05, 'epoch': 49.51}       \n",
      "{'loss': 0.3888, 'learning_rate': 1.0065573770491803e-05, 'epoch': 49.67}       \n",
      "{'loss': 0.3925, 'learning_rate': 1.0032786885245902e-05, 'epoch': 49.84}       \n",
      "{'loss': 0.3797, 'learning_rate': 1e-05, 'epoch': 50.0}                         \n",
      " 50%|███████████████████▌                   | 3050/6100 [36:14<23:19,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:42:40,253 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:42:40,253 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:42:40,253 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.96it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  2.82it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.31it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.05it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.94it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.89it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.85it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7308195233345032, 'eval_accuracy': 0.7612809315866085, 'eval_runtime': 5.6298, 'eval_samples_per_second': 122.03, 'eval_steps_per_second': 1.954, 'epoch': 50.0}\n",
      " 50%|███████████████████▌                   | 3050/6100 [36:19<23:19,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:42:45,883 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3050\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:42:45,884 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3050/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:42:46,104 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3050/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:42:46,104 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3050/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:42:46,349 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2928] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3374, 'learning_rate': 9.9672131147541e-06, 'epoch': 50.16}          \n",
      "{'loss': 0.4041, 'learning_rate': 9.934426229508197e-06, 'epoch': 50.33}        \n",
      "{'loss': 0.4503, 'learning_rate': 9.901639344262296e-06, 'epoch': 50.49}        \n",
      "{'loss': 0.3866, 'learning_rate': 9.868852459016395e-06, 'epoch': 50.66}        \n",
      "{'loss': 0.4025, 'learning_rate': 9.836065573770493e-06, 'epoch': 50.82}        \n",
      "{'loss': 0.3678, 'learning_rate': 9.803278688524592e-06, 'epoch': 50.98}        \n",
      " 51%|███████████████████▉                   | 3111/6100 [36:58<27:47,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:43:24,599 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:43:24,599 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:43:24,599 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.09it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7417690753936768, 'eval_accuracy': 0.7700145560407569, 'eval_runtime': 6.2257, 'eval_samples_per_second': 110.35, 'eval_steps_per_second': 1.767, 'epoch': 51.0}\n",
      " 51%|███████████████████▉                   | 3111/6100 [37:04<27:47,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:43:30,825 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3111\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:43:30,826 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3111/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:43:30,989 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3111/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:43:30,989 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3111/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:43:31,237 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-2989] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3912, 'learning_rate': 9.770491803278689e-06, 'epoch': 51.15}        \n",
      "{'loss': 0.4172, 'learning_rate': 9.737704918032788e-06, 'epoch': 51.31}        \n",
      "{'loss': 0.3958, 'learning_rate': 9.704918032786887e-06, 'epoch': 51.48}        \n",
      "{'loss': 0.3551, 'learning_rate': 9.672131147540984e-06, 'epoch': 51.64}        \n",
      "{'loss': 0.3973, 'learning_rate': 9.639344262295083e-06, 'epoch': 51.8}         \n",
      "{'loss': 0.3839, 'learning_rate': 9.60655737704918e-06, 'epoch': 51.97}         \n",
      " 52%|████████████████████▎                  | 3172/6100 [37:43<27:33,  1.77it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:44:09,390 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:44:09,390 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:44:09,390 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.51it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.18it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.84it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7162298560142517, 'eval_accuracy': 0.7671033478893741, 'eval_runtime': 6.1787, 'eval_samples_per_second': 111.189, 'eval_steps_per_second': 1.78, 'epoch': 52.0}\n",
      " 52%|████████████████████▎                  | 3172/6100 [37:49<27:33,  1.77it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:44:15,569 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3172\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:44:15,570 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3172/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:44:15,730 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3172/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:44:15,731 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3172/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:44:15,975 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3050] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4506, 'learning_rate': 9.57377049180328e-06, 'epoch': 52.13}         \n",
      "{'loss': 0.4027, 'learning_rate': 9.540983606557377e-06, 'epoch': 52.3}         \n",
      "{'loss': 0.3729, 'learning_rate': 9.508196721311476e-06, 'epoch': 52.46}        \n",
      "{'loss': 0.4254, 'learning_rate': 9.475409836065575e-06, 'epoch': 52.62}        \n",
      "{'loss': 0.4075, 'learning_rate': 9.442622950819673e-06, 'epoch': 52.79}        \n",
      "{'loss': 0.3948, 'learning_rate': 9.409836065573772e-06, 'epoch': 52.95}        \n",
      " 53%|████████████████████▋                  | 3233/6100 [38:28<26:57,  1.77it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:44:54,131 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:44:54,131 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:44:54,131 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7197901606559753, 'eval_accuracy': 0.7685589519650655, 'eval_runtime': 6.2172, 'eval_samples_per_second': 110.5, 'eval_steps_per_second': 1.769, 'epoch': 53.0}\n",
      " 53%|████████████████████▋                  | 3233/6100 [38:34<26:57,  1.77it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:45:00,349 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3233\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:45:00,350 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3233/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:45:00,526 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3233/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:45:00,527 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3233/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:45:00,775 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3111] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3502, 'learning_rate': 9.377049180327869e-06, 'epoch': 53.11}        \n",
      "{'loss': 0.3564, 'learning_rate': 9.344262295081968e-06, 'epoch': 53.28}        \n",
      "{'loss': 0.3754, 'learning_rate': 9.311475409836065e-06, 'epoch': 53.44}        \n",
      "{'loss': 0.3769, 'learning_rate': 9.278688524590164e-06, 'epoch': 53.61}        \n",
      "{'loss': 0.3941, 'learning_rate': 9.245901639344263e-06, 'epoch': 53.77}        \n",
      "{'loss': 0.3585, 'learning_rate': 9.21311475409836e-06, 'epoch': 53.93}         \n",
      " 54%|█████████████████████                  | 3294/6100 [39:12<24:43,  1.89it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:45:38,692 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:45:38,693 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:45:38,693 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.24it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.94it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.70it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7730490565299988, 'eval_accuracy': 0.7583697234352256, 'eval_runtime': 4.5274, 'eval_samples_per_second': 151.742, 'eval_steps_per_second': 2.43, 'epoch': 54.0}\n",
      " 54%|█████████████████████                  | 3294/6100 [39:17<24:43,  1.89it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:45:43,221 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3294\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:45:43,221 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3294/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:45:43,331 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3294/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:45:43,332 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3294/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:45:43,509 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3172] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3756, 'learning_rate': 9.18032786885246e-06, 'epoch': 54.1}          \n",
      "{'loss': 0.3719, 'learning_rate': 9.147540983606557e-06, 'epoch': 54.26}        \n",
      "{'loss': 0.3624, 'learning_rate': 9.114754098360656e-06, 'epoch': 54.43}        \n",
      "{'loss': 0.35, 'learning_rate': 9.081967213114755e-06, 'epoch': 54.59}          \n",
      "{'loss': 0.3896, 'learning_rate': 9.049180327868853e-06, 'epoch': 54.75}        \n",
      "{'loss': 0.4474, 'learning_rate': 9.016393442622952e-06, 'epoch': 54.92}        \n",
      " 55%|█████████████████████▍                 | 3355/6100 [39:56<21:12,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:46:21,942 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:46:21,942 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:46:21,942 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.78it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.62it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7530468106269836, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 4.6197, 'eval_samples_per_second': 148.711, 'eval_steps_per_second': 2.381, 'epoch': 55.0}\n",
      " 55%|█████████████████████▍                 | 3355/6100 [40:00<21:12,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:46:26,562 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3355\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:46:26,563 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3355/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:46:26,680 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3355/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:46:26,681 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3355/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:46:26,859 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3233] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3798, 'learning_rate': 8.98360655737705e-06, 'epoch': 55.08}         \n",
      "{'loss': 0.3627, 'learning_rate': 8.950819672131148e-06, 'epoch': 55.25}        \n",
      "{'loss': 0.3415, 'learning_rate': 8.918032786885247e-06, 'epoch': 55.41}        \n",
      "{'loss': 0.4071, 'learning_rate': 8.885245901639346e-06, 'epoch': 55.57}        \n",
      "{'loss': 0.3598, 'learning_rate': 8.852459016393443e-06, 'epoch': 55.74}        \n",
      "{'loss': 0.362, 'learning_rate': 8.819672131147542e-06, 'epoch': 55.9}          \n",
      " 56%|█████████████████████▊                 | 3416/6100 [40:38<20:25,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:47:04,696 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:47:04,696 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:47:04,696 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.01it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.56it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8066487908363342, 'eval_accuracy': 0.7714701601164483, 'eval_runtime': 4.4379, 'eval_samples_per_second': 154.802, 'eval_steps_per_second': 2.479, 'epoch': 56.0}\n",
      " 56%|█████████████████████▊                 | 3416/6100 [40:43<20:25,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.59it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:47:09,134 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3416\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:47:09,135 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3416/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:47:09,228 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3416/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:47:09,229 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3416/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:47:09,404 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3294] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3196, 'learning_rate': 8.78688524590164e-06, 'epoch': 56.07}         \n",
      "{'loss': 0.3614, 'learning_rate': 8.754098360655739e-06, 'epoch': 56.23}        \n",
      "{'loss': 0.3449, 'learning_rate': 8.721311475409838e-06, 'epoch': 56.39}        \n",
      "{'loss': 0.3514, 'learning_rate': 8.688524590163935e-06, 'epoch': 56.56}        \n",
      "{'loss': 0.3842, 'learning_rate': 8.655737704918034e-06, 'epoch': 56.72}        \n",
      "{'loss': 0.4006, 'learning_rate': 8.622950819672132e-06, 'epoch': 56.89}        \n",
      " 57%|██████████████████████▏                | 3477/6100 [41:21<20:06,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:47:47,755 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:47:47,755 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:47:47,755 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7618260979652405, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 4.5366, 'eval_samples_per_second': 151.435, 'eval_steps_per_second': 2.425, 'epoch': 57.0}\n",
      " 57%|██████████████████████▏                | 3477/6100 [41:26<20:06,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.23it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:47:52,292 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3477\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:47:52,292 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3477/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:47:52,389 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3477/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:47:52,390 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3477/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:47:52,573 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3355] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3548, 'learning_rate': 8.59016393442623e-06, 'epoch': 57.05}         \n",
      "{'loss': 0.3752, 'learning_rate': 8.55737704918033e-06, 'epoch': 57.21}         \n",
      "{'loss': 0.3676, 'learning_rate': 8.524590163934427e-06, 'epoch': 57.38}        \n",
      "{'loss': 0.364, 'learning_rate': 8.491803278688526e-06, 'epoch': 57.54}         \n",
      "{'loss': 0.3116, 'learning_rate': 8.459016393442623e-06, 'epoch': 57.7}         \n",
      "{'loss': 0.3916, 'learning_rate': 8.426229508196722e-06, 'epoch': 57.87}        \n",
      " 58%|██████████████████████▌                | 3538/6100 [42:05<19:33,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:48:30,961 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:48:30,961 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:48:30,961 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.58it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.22it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.01it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:01,  1.91it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.98it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7779002785682678, 'eval_accuracy': 0.7889374090247453, 'eval_runtime': 5.1274, 'eval_samples_per_second': 133.987, 'eval_steps_per_second': 2.145, 'epoch': 58.0}\n",
      " 58%|██████████████████████▌                | 3538/6100 [42:10<19:33,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.61it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:48:36,089 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3538\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:48:36,092 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3538/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:48:36,248 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3538/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:48:36,248 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3538/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:48:36,495 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3416] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3158, 'learning_rate': 8.39344262295082e-06, 'epoch': 58.03}         \n",
      "{'loss': 0.3257, 'learning_rate': 8.360655737704919e-06, 'epoch': 58.2}         \n",
      "{'loss': 0.3573, 'learning_rate': 8.327868852459016e-06, 'epoch': 58.36}        \n",
      "{'loss': 0.3322, 'learning_rate': 8.295081967213115e-06, 'epoch': 58.52}        \n",
      "{'loss': 0.3469, 'learning_rate': 8.262295081967214e-06, 'epoch': 58.69}        \n",
      "{'loss': 0.3308, 'learning_rate': 8.229508196721311e-06, 'epoch': 58.85}        \n",
      " 59%|███████████████████████                | 3599/6100 [42:48<22:44,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:49:14,514 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:49:14,514 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:49:14,514 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.59it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.55it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.17it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7782381176948547, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 6.1507, 'eval_samples_per_second': 111.695, 'eval_steps_per_second': 1.788, 'epoch': 59.0}\n",
      " 59%|███████████████████████                | 3599/6100 [42:54<22:44,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:49:20,666 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3599\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:49:20,667 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3599/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:49:20,826 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3599/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:49:20,827 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3599/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:49:21,076 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3477] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3348, 'learning_rate': 8.19672131147541e-06, 'epoch': 59.02}         \n",
      "{'loss': 0.4287, 'learning_rate': 8.163934426229508e-06, 'epoch': 59.18}        \n",
      "{'loss': 0.3757, 'learning_rate': 8.131147540983607e-06, 'epoch': 59.34}        \n",
      "{'loss': 0.3246, 'learning_rate': 8.098360655737706e-06, 'epoch': 59.51}        \n",
      "{'loss': 0.3125, 'learning_rate': 8.065573770491803e-06, 'epoch': 59.67}        \n",
      "{'loss': 0.3468, 'learning_rate': 8.032786885245902e-06, 'epoch': 59.84}        \n",
      "{'loss': 0.3895, 'learning_rate': 8.000000000000001e-06, 'epoch': 60.0}         \n",
      " 60%|███████████████████████▍               | 3660/6100 [43:33<22:48,  1.78it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:49:58,968 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:49:58,968 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:49:58,968 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.60it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.51it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.83it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.96it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7708855867385864, 'eval_accuracy': 0.7816593886462883, 'eval_runtime': 5.8132, 'eval_samples_per_second': 118.178, 'eval_steps_per_second': 1.892, 'epoch': 60.0}\n",
      " 60%|███████████████████████▍               | 3660/6100 [43:38<22:48,  1.78it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.19it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:50:04,781 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3660\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:50:04,782 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3660/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:50:04,883 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3660/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:50:04,884 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3660/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:50:05,061 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3538] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3121, 'learning_rate': 7.967213114754099e-06, 'epoch': 60.16}        \n",
      "{'loss': 0.3905, 'learning_rate': 7.934426229508198e-06, 'epoch': 60.33}        \n",
      "{'loss': 0.3372, 'learning_rate': 7.901639344262295e-06, 'epoch': 60.49}        \n",
      "{'loss': 0.3833, 'learning_rate': 7.868852459016394e-06, 'epoch': 60.66}        \n",
      "{'loss': 0.3572, 'learning_rate': 7.836065573770493e-06, 'epoch': 60.82}        \n",
      "{'loss': 0.3828, 'learning_rate': 7.80327868852459e-06, 'epoch': 60.98}         \n",
      " 61%|███████████████████████▊               | 3721/6100 [44:17<22:09,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:50:43,118 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:50:43,118 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:50:43,118 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.26it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.02it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.89it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:01,  2.02it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.09it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.13it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.31it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7583817839622498, 'eval_accuracy': 0.7700145560407569, 'eval_runtime': 5.676, 'eval_samples_per_second': 121.036, 'eval_steps_per_second': 1.938, 'epoch': 61.0}\n",
      " 61%|███████████████████████▊               | 3721/6100 [44:22<22:09,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.00it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:50:48,794 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3721\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:50:48,795 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3721/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:50:48,921 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3721/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:50:48,922 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3721/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:50:49,093 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3599] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3452, 'learning_rate': 7.77049180327869e-06, 'epoch': 61.15}         \n",
      "{'loss': 0.3514, 'learning_rate': 7.737704918032789e-06, 'epoch': 61.31}        \n",
      "{'loss': 0.3616, 'learning_rate': 7.704918032786886e-06, 'epoch': 61.48}        \n",
      "{'loss': 0.3272, 'learning_rate': 7.672131147540985e-06, 'epoch': 61.64}        \n",
      "{'loss': 0.3602, 'learning_rate': 7.639344262295082e-06, 'epoch': 61.8}         \n",
      "{'loss': 0.3291, 'learning_rate': 7.6065573770491804e-06, 'epoch': 61.97}       \n",
      " 62%|████████████████████████▏              | 3782/6100 [45:00<17:53,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:51:26,373 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:51:26,373 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:51:26,373 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.57it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7963081002235413, 'eval_accuracy': 0.777292576419214, 'eval_runtime': 4.4654, 'eval_samples_per_second': 153.85, 'eval_steps_per_second': 2.463, 'epoch': 62.0}\n",
      " 62%|████████████████████████▏              | 3782/6100 [45:04<17:53,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:51:30,839 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3782\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:51:30,840 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3782/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:51:30,964 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3782/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:51:30,964 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3782/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:51:31,143 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3660] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3452, 'learning_rate': 7.5737704918032795e-06, 'epoch': 62.13}       \n",
      "{'loss': 0.3493, 'learning_rate': 7.540983606557377e-06, 'epoch': 62.3}         \n",
      "{'loss': 0.3712, 'learning_rate': 7.508196721311476e-06, 'epoch': 62.46}        \n",
      "{'loss': 0.3653, 'learning_rate': 7.475409836065575e-06, 'epoch': 62.62}        \n",
      "{'loss': 0.3477, 'learning_rate': 7.442622950819672e-06, 'epoch': 62.79}        \n",
      "{'loss': 0.324, 'learning_rate': 7.409836065573771e-06, 'epoch': 62.95}         \n",
      " 63%|████████████████████████▌              | 3843/6100 [45:43<17:24,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:52:09,821 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:52:09,821 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:52:09,821 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  3.02it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7733623385429382, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.4781, 'eval_samples_per_second': 153.413, 'eval_steps_per_second': 2.456, 'epoch': 63.0}\n",
      " 63%|████████████████████████▌              | 3843/6100 [45:48<17:24,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:52:14,300 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3843\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:52:14,300 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3843/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:52:14,414 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3843/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:52:14,415 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3843/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2887] 2023-10-05 12:52:14,596 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3721] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3372, 'learning_rate': 7.3770491803278695e-06, 'epoch': 63.11}       \n",
      "{'loss': 0.3057, 'learning_rate': 7.344262295081968e-06, 'epoch': 63.28}        \n",
      "{'loss': 0.4126, 'learning_rate': 7.311475409836067e-06, 'epoch': 63.44}        \n",
      "{'loss': 0.3196, 'learning_rate': 7.278688524590165e-06, 'epoch': 63.61}        \n",
      "{'loss': 0.2734, 'learning_rate': 7.245901639344263e-06, 'epoch': 63.77}        \n",
      "{'loss': 0.3342, 'learning_rate': 7.213114754098361e-06, 'epoch': 63.93}        \n",
      " 64%|████████████████████████▉              | 3904/6100 [46:27<17:03,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:52:53,154 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:52:53,154 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:52:53,154 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.48it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8160716891288757, 'eval_accuracy': 0.7671033478893741, 'eval_runtime': 4.5266, 'eval_samples_per_second': 151.771, 'eval_steps_per_second': 2.43, 'epoch': 64.0}\n",
      " 64%|████████████████████████▉              | 3904/6100 [46:31<17:03,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:52:57,681 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3904\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:52:57,681 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3904/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:52:57,782 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3904/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:52:57,782 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3904/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:52:57,958 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3782] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.319, 'learning_rate': 7.1803278688524594e-06, 'epoch': 64.1}         \n",
      "{'loss': 0.3167, 'learning_rate': 7.147540983606558e-06, 'epoch': 64.26}        \n",
      "{'loss': 0.355, 'learning_rate': 7.114754098360657e-06, 'epoch': 64.43}         \n",
      "{'loss': 0.3398, 'learning_rate': 7.081967213114754e-06, 'epoch': 64.59}        \n",
      "{'loss': 0.3372, 'learning_rate': 7.049180327868853e-06, 'epoch': 64.75}        \n",
      "{'loss': 0.3129, 'learning_rate': 7.016393442622952e-06, 'epoch': 64.92}        \n",
      " 65%|█████████████████████████▎             | 3965/6100 [47:10<16:20,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:53:36,470 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:53:36,470 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:53:36,470 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.72it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.72it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.34it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7708957195281982, 'eval_accuracy': 0.7700145560407569, 'eval_runtime': 4.5759, 'eval_samples_per_second': 150.133, 'eval_steps_per_second': 2.404, 'epoch': 65.0}\n",
      " 65%|█████████████████████████▎             | 3965/6100 [47:15<16:20,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:53:41,046 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3965\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:53:41,047 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3965/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:53:41,159 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3965/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:53:41,159 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3965/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:53:41,342 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3843] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3425, 'learning_rate': 6.983606557377049e-06, 'epoch': 65.08}        \n",
      "{'loss': 0.2988, 'learning_rate': 6.9508196721311484e-06, 'epoch': 65.25}       \n",
      "{'loss': 0.3552, 'learning_rate': 6.918032786885246e-06, 'epoch': 65.41}        \n",
      "{'loss': 0.2945, 'learning_rate': 6.885245901639345e-06, 'epoch': 65.57}        \n",
      "{'loss': 0.3207, 'learning_rate': 6.852459016393444e-06, 'epoch': 65.74}        \n",
      "{'loss': 0.3018, 'learning_rate': 6.819672131147541e-06, 'epoch': 65.9}         \n",
      " 66%|█████████████████████████▋             | 4026/6100 [47:53<16:23,  2.11it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:54:19,192 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:54:19,192 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:54:19,192 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.40it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.17it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.82it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.92it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7983976006507874, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 6.079, 'eval_samples_per_second': 113.012, 'eval_steps_per_second': 1.81, 'epoch': 66.0}\n",
      " 66%|█████████████████████████▋             | 4026/6100 [47:59<16:23,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:54:25,272 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4026\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:54:25,273 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4026/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:54:25,417 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4026/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:54:25,418 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4026/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:54:25,671 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3904] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3486, 'learning_rate': 6.78688524590164e-06, 'epoch': 66.07}         \n",
      "{'loss': 0.3299, 'learning_rate': 6.7540983606557384e-06, 'epoch': 66.23}       \n",
      "{'loss': 0.3258, 'learning_rate': 6.721311475409837e-06, 'epoch': 66.39}        \n",
      "{'loss': 0.3292, 'learning_rate': 6.688524590163935e-06, 'epoch': 66.56}        \n",
      "{'loss': 0.2909, 'learning_rate': 6.655737704918034e-06, 'epoch': 66.72}        \n",
      "{'loss': 0.3569, 'learning_rate': 6.622950819672131e-06, 'epoch': 66.89}        \n",
      " 67%|██████████████████████████▏            | 4087/6100 [48:37<18:30,  1.81it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:55:03,587 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:55:03,588 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:55:03,588 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.809836208820343, 'eval_accuracy': 0.7627365356622998, 'eval_runtime': 6.2394, 'eval_samples_per_second': 110.107, 'eval_steps_per_second': 1.763, 'epoch': 67.0}\n",
      " 67%|██████████████████████████▏            | 4087/6100 [48:43<18:30,  1.81it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:55:09,828 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4087\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:55:09,830 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4087/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:55:09,992 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4087/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:55:09,992 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4087/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:55:10,235 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-3965] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3436, 'learning_rate': 6.59016393442623e-06, 'epoch': 67.05}         \n",
      "{'loss': 0.3495, 'learning_rate': 6.5573770491803276e-06, 'epoch': 67.21}       \n",
      "{'loss': 0.3182, 'learning_rate': 6.524590163934427e-06, 'epoch': 67.38}        \n",
      "{'loss': 0.3505, 'learning_rate': 6.491803278688526e-06, 'epoch': 67.54}        \n",
      "{'loss': 0.3353, 'learning_rate': 6.459016393442623e-06, 'epoch': 67.7}         \n",
      "{'loss': 0.3389, 'learning_rate': 6.426229508196722e-06, 'epoch': 67.87}        \n",
      " 68%|██████████████████████████▌            | 4148/6100 [49:22<17:12,  1.89it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:55:48,250 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:55:48,250 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:55:48,250 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.02it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.94it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.77it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.62it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8333185911178589, 'eval_accuracy': 0.7700145560407569, 'eval_runtime': 4.4823, 'eval_samples_per_second': 153.269, 'eval_steps_per_second': 2.454, 'epoch': 68.0}\n",
      " 68%|██████████████████████████▌            | 4148/6100 [49:26<17:12,  1.89it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:55:52,733 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4148\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:55:52,734 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4148/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:55:52,845 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4148/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:55:52,845 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4148/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:55:53,023 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4026] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3542, 'learning_rate': 6.393442622950821e-06, 'epoch': 68.03}        \n",
      "{'loss': 0.3422, 'learning_rate': 6.360655737704918e-06, 'epoch': 68.2}         \n",
      "{'loss': 0.3766, 'learning_rate': 6.327868852459017e-06, 'epoch': 68.36}        \n",
      "{'loss': 0.3253, 'learning_rate': 6.295081967213116e-06, 'epoch': 68.52}        \n",
      "{'loss': 0.3242, 'learning_rate': 6.262295081967214e-06, 'epoch': 68.69}        \n",
      "{'loss': 0.3088, 'learning_rate': 6.229508196721312e-06, 'epoch': 68.85}        \n",
      " 69%|██████████████████████████▉            | 4209/6100 [50:04<14:36,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:56:30,884 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:56:30,884 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:56:30,884 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.35it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7664514183998108, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 4.5191, 'eval_samples_per_second': 152.023, 'eval_steps_per_second': 2.434, 'epoch': 69.0}\n",
      " 69%|██████████████████████████▉            | 4209/6100 [50:09<14:36,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.25it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:56:35,403 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4209\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:56:35,404 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4209/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:56:35,520 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4209/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:56:35,521 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4209/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:56:35,700 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4087] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2626, 'learning_rate': 6.19672131147541e-06, 'epoch': 69.02}         \n",
      "{'loss': 0.2855, 'learning_rate': 6.163934426229508e-06, 'epoch': 69.18}        \n",
      "{'loss': 0.3084, 'learning_rate': 6.131147540983607e-06, 'epoch': 69.34}        \n",
      "{'loss': 0.3108, 'learning_rate': 6.098360655737705e-06, 'epoch': 69.51}        \n",
      "{'loss': 0.347, 'learning_rate': 6.065573770491804e-06, 'epoch': 69.67}         \n",
      "{'loss': 0.3051, 'learning_rate': 6.032786885245903e-06, 'epoch': 69.84}        \n",
      "{'loss': 0.3309, 'learning_rate': 6e-06, 'epoch': 70.0}                         \n",
      " 70%|███████████████████████████▎           | 4270/6100 [50:48<14:04,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:57:14,733 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:57:14,733 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:57:14,733 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.67it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7765897512435913, 'eval_accuracy': 0.7816593886462883, 'eval_runtime': 4.5702, 'eval_samples_per_second': 150.322, 'eval_steps_per_second': 2.407, 'epoch': 70.0}\n",
      " 70%|███████████████████████████▎           | 4270/6100 [50:53<14:04,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.20it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:57:19,303 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4270\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:57:19,304 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4270/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:57:19,421 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4270/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:57:19,422 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4270/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:57:19,601 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4148] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.29, 'learning_rate': 5.967213114754099e-06, 'epoch': 70.16}          \n",
      "{'loss': 0.2946, 'learning_rate': 5.9344262295081965e-06, 'epoch': 70.33}       \n",
      "{'loss': 0.3643, 'learning_rate': 5.9016393442622956e-06, 'epoch': 70.49}       \n",
      "{'loss': 0.3658, 'learning_rate': 5.868852459016395e-06, 'epoch': 70.66}        \n",
      "{'loss': 0.2983, 'learning_rate': 5.836065573770492e-06, 'epoch': 70.82}        \n",
      "{'loss': 0.2989, 'learning_rate': 5.803278688524591e-06, 'epoch': 70.98}        \n",
      " 71%|███████████████████████████▋           | 4331/6100 [51:31<13:37,  2.16it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:57:57,398 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:57:57,398 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:57:57,399 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.35it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.05it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.73it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.58it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.42it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.34it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7773221731185913, 'eval_accuracy': 0.7641921397379913, 'eval_runtime': 4.6758, 'eval_samples_per_second': 146.926, 'eval_steps_per_second': 2.353, 'epoch': 71.0}\n",
      " 71%|███████████████████████████▋           | 4331/6100 [51:36<13:37,  2.16it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.17it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:58:02,075 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4331\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:58:02,076 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4331/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:58:02,191 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4331/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:58:02,191 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4331/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:58:02,378 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4209] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2901, 'learning_rate': 5.770491803278689e-06, 'epoch': 71.15}        \n",
      "{'loss': 0.338, 'learning_rate': 5.737704918032787e-06, 'epoch': 71.31}         \n",
      "{'loss': 0.3581, 'learning_rate': 5.7049180327868855e-06, 'epoch': 71.48}       \n",
      "{'loss': 0.3079, 'learning_rate': 5.672131147540985e-06, 'epoch': 71.64}        \n",
      "{'loss': 0.2862, 'learning_rate': 5.639344262295082e-06, 'epoch': 71.8}         \n",
      "{'loss': 0.3503, 'learning_rate': 5.606557377049181e-06, 'epoch': 71.97}        \n",
      " 72%|████████████████████████████           | 4392/6100 [52:15<13:04,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:58:40,980 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:58:40,980 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:58:40,980 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.84it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.70it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.35it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.33it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.34it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7797752022743225, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 4.681, 'eval_samples_per_second': 146.763, 'eval_steps_per_second': 2.35, 'epoch': 72.0}\n",
      " 72%|████████████████████████████           | 4392/6100 [52:19<13:04,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.05it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:58:45,662 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4392\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:58:45,663 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4392/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:58:45,826 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4392/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:58:45,827 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4392/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:58:46,083 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4270] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3573, 'learning_rate': 5.573770491803278e-06, 'epoch': 72.13}        \n",
      "{'loss': 0.2898, 'learning_rate': 5.540983606557377e-06, 'epoch': 72.3}         \n",
      "{'loss': 0.3314, 'learning_rate': 5.508196721311476e-06, 'epoch': 72.46}        \n",
      "{'loss': 0.3405, 'learning_rate': 5.475409836065574e-06, 'epoch': 72.62}        \n",
      "{'loss': 0.3051, 'learning_rate': 5.442622950819673e-06, 'epoch': 72.79}        \n",
      "{'loss': 0.3352, 'learning_rate': 5.409836065573772e-06, 'epoch': 72.95}        \n",
      " 73%|████████████████████████████▍          | 4453/6100 [52:58<14:37,  1.88it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 12:59:24,311 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 12:59:24,311 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 12:59:24,311 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7864403128623962, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 6.136, 'eval_samples_per_second': 111.963, 'eval_steps_per_second': 1.793, 'epoch': 73.0}\n",
      " 73%|████████████████████████████▍          | 4453/6100 [53:04<14:37,  1.88it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 12:59:30,448 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4453\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 12:59:30,449 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4453/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 12:59:30,607 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4453/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 12:59:30,607 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4453/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 12:59:30,856 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4331] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3376, 'learning_rate': 5.377049180327869e-06, 'epoch': 73.11}        \n",
      "{'loss': 0.2814, 'learning_rate': 5.344262295081968e-06, 'epoch': 73.28}        \n",
      "{'loss': 0.3396, 'learning_rate': 5.3114754098360655e-06, 'epoch': 73.44}       \n",
      "{'loss': 0.3078, 'learning_rate': 5.2786885245901645e-06, 'epoch': 73.61}       \n",
      "{'loss': 0.314, 'learning_rate': 5.245901639344263e-06, 'epoch': 73.77}         \n",
      "{'loss': 0.326, 'learning_rate': 5.213114754098361e-06, 'epoch': 73.93}         \n",
      " 74%|████████████████████████████▊          | 4514/6100 [53:42<14:46,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:00:08,778 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:00:08,778 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:00:08,778 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.49it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.96it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.83it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.76it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.73it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8016108870506287, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 6.3036, 'eval_samples_per_second': 108.985, 'eval_steps_per_second': 1.745, 'epoch': 74.0}\n",
      " 74%|████████████████████████████▊          | 4514/6100 [53:49<14:46,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:00:15,082 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4514\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:00:15,084 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4514/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:00:15,239 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4514/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:00:15,239 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4514/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:00:15,491 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4392] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3006, 'learning_rate': 5.180327868852459e-06, 'epoch': 74.1}         \n",
      "{'loss': 0.2493, 'learning_rate': 5.147540983606558e-06, 'epoch': 74.26}        \n",
      "{'loss': 0.2976, 'learning_rate': 5.1147540983606555e-06, 'epoch': 74.43}       \n",
      "{'loss': 0.3294, 'learning_rate': 5.0819672131147545e-06, 'epoch': 74.59}       \n",
      "{'loss': 0.3324, 'learning_rate': 5.0491803278688535e-06, 'epoch': 74.75}       \n",
      "{'loss': 0.3216, 'learning_rate': 5.016393442622951e-06, 'epoch': 74.92}        \n",
      " 75%|█████████████████████████████▎         | 4575/6100 [54:27<14:09,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:00:53,332 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:00:53,332 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:00:53,332 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.34it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.07it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:01,  2.19it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.20it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.22it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7926816344261169, 'eval_accuracy': 0.784570596797671, 'eval_runtime': 5.4846, 'eval_samples_per_second': 125.261, 'eval_steps_per_second': 2.006, 'epoch': 75.0}\n",
      " 75%|█████████████████████████████▎         | 4575/6100 [54:32<14:09,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.11it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:00:58,817 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4575\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:00:58,818 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4575/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:00:58,935 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4575/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:00:58,935 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4575/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:00:59,106 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4453] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2977, 'learning_rate': 4.98360655737705e-06, 'epoch': 75.08}         \n",
      "{'loss': 0.3063, 'learning_rate': 4.950819672131148e-06, 'epoch': 75.25}        \n",
      "{'loss': 0.2875, 'learning_rate': 4.918032786885246e-06, 'epoch': 75.41}        \n",
      "{'loss': 0.2953, 'learning_rate': 4.8852459016393445e-06, 'epoch': 75.57}       \n",
      "{'loss': 0.3167, 'learning_rate': 4.8524590163934435e-06, 'epoch': 75.74}       \n",
      "{'loss': 0.2796, 'learning_rate': 4.819672131147542e-06, 'epoch': 75.9}         \n",
      " 76%|█████████████████████████████▋         | 4636/6100 [55:11<12:43,  1.92it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:01:37,710 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:01:37,710 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:01:37,710 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.88it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.72it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.65it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8223279714584351, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.5251, 'eval_samples_per_second': 151.82, 'eval_steps_per_second': 2.431, 'epoch': 76.0}\n",
      " 76%|█████████████████████████████▋         | 4636/6100 [55:16<12:43,  1.92it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:01:42,236 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4636\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:01:42,237 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4636/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:01:42,351 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4636/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:01:42,352 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4636/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:01:42,529 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4514] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3513, 'learning_rate': 4.78688524590164e-06, 'epoch': 76.07}         \n",
      "{'loss': 0.3036, 'learning_rate': 4.754098360655738e-06, 'epoch': 76.23}        \n",
      "{'loss': 0.295, 'learning_rate': 4.721311475409836e-06, 'epoch': 76.39}         \n",
      "{'loss': 0.3186, 'learning_rate': 4.6885245901639345e-06, 'epoch': 76.56}       \n",
      "{'loss': 0.3139, 'learning_rate': 4.655737704918033e-06, 'epoch': 76.72}        \n",
      "{'loss': 0.2933, 'learning_rate': 4.622950819672132e-06, 'epoch': 76.89}        \n",
      " 77%|██████████████████████████████         | 4697/6100 [55:54<10:45,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:02:20,638 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:02:20,639 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:02:20,639 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.22it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.62it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.47it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8105545043945312, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.6247, 'eval_samples_per_second': 148.552, 'eval_steps_per_second': 2.379, 'epoch': 77.0}\n",
      " 77%|██████████████████████████████         | 4697/6100 [55:59<10:45,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.15it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:02:25,263 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4697\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:02:25,264 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4697/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:02:25,373 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4697/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:02:25,374 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4697/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:02:25,551 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4575] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2975, 'learning_rate': 4.59016393442623e-06, 'epoch': 77.05}         \n",
      "{'loss': 0.3092, 'learning_rate': 4.557377049180328e-06, 'epoch': 77.21}        \n",
      "{'loss': 0.2719, 'learning_rate': 4.524590163934426e-06, 'epoch': 77.38}        \n",
      "{'loss': 0.2796, 'learning_rate': 4.491803278688525e-06, 'epoch': 77.54}        \n",
      "{'loss': 0.3, 'learning_rate': 4.4590163934426235e-06, 'epoch': 77.7}           \n",
      "{'loss': 0.2925, 'learning_rate': 4.426229508196722e-06, 'epoch': 77.87}        \n",
      " 78%|██████████████████████████████▍        | 4758/6100 [56:37<10:16,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:03:03,327 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:03:03,327 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:03:03,327 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  5.01it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.70it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.47it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7744613289833069, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 4.5016, 'eval_samples_per_second': 152.613, 'eval_steps_per_second': 2.444, 'epoch': 78.0}\n",
      " 78%|██████████████████████████████▍        | 4758/6100 [56:41<10:16,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.27it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:03:07,829 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4758\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:03:07,829 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4758/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:03:07,938 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4758/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:03:07,938 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4758/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:03:08,116 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4636] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2964, 'learning_rate': 4.39344262295082e-06, 'epoch': 78.03}         \n",
      "{'loss': 0.3217, 'learning_rate': 4.360655737704919e-06, 'epoch': 78.2}         \n",
      "{'loss': 0.2919, 'learning_rate': 4.327868852459017e-06, 'epoch': 78.36}        \n",
      "{'loss': 0.2918, 'learning_rate': 4.295081967213115e-06, 'epoch': 78.52}        \n",
      "{'loss': 0.288, 'learning_rate': 4.2622950819672135e-06, 'epoch': 78.69}        \n",
      "{'loss': 0.3431, 'learning_rate': 4.229508196721312e-06, 'epoch': 78.85}        \n",
      " 79%|██████████████████████████████▊        | 4819/6100 [57:20<09:47,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:03:46,362 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:03:46,362 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:03:46,362 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.73it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.17it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.61it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8105834722518921, 'eval_accuracy': 0.7714701601164483, 'eval_runtime': 4.677, 'eval_samples_per_second': 146.89, 'eval_steps_per_second': 2.352, 'epoch': 79.0}\n",
      " 79%|██████████████████████████████▊        | 4819/6100 [57:25<09:47,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.07it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:03:51,040 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4819\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:03:51,041 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4819/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:03:51,203 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4819/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:03:51,204 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4819/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:03:51,451 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4697] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2461, 'learning_rate': 4.19672131147541e-06, 'epoch': 79.02}         \n",
      "{'loss': 0.3262, 'learning_rate': 4.163934426229508e-06, 'epoch': 79.18}        \n",
      "{'loss': 0.2783, 'learning_rate': 4.131147540983607e-06, 'epoch': 79.34}        \n",
      "{'loss': 0.308, 'learning_rate': 4.098360655737705e-06, 'epoch': 79.51}         \n",
      "{'loss': 0.3301, 'learning_rate': 4.0655737704918034e-06, 'epoch': 79.67}       \n",
      "{'loss': 0.2869, 'learning_rate': 4.032786885245902e-06, 'epoch': 79.84}        \n",
      "{'loss': 0.286, 'learning_rate': 4.000000000000001e-06, 'epoch': 80.0}          \n",
      " 80%|███████████████████████████████▏       | 4880/6100 [58:03<11:10,  1.82it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:04:29,504 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:04:29,504 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:04:29,504 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.92it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.790058970451355, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 6.1667, 'eval_samples_per_second': 111.404, 'eval_steps_per_second': 1.784, 'epoch': 80.0}\n",
      " 80%|███████████████████████████████▏       | 4880/6100 [58:09<11:10,  1.82it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:04:35,671 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4880\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:04:35,672 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4880/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:04:35,839 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4880/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:04:35,839 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4880/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:04:36,085 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4758] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3022, 'learning_rate': 3.967213114754099e-06, 'epoch': 80.16}        \n",
      "{'loss': 0.2897, 'learning_rate': 3.934426229508197e-06, 'epoch': 80.33}        \n",
      "{'loss': 0.2491, 'learning_rate': 3.901639344262295e-06, 'epoch': 80.49}        \n",
      "{'loss': 0.2749, 'learning_rate': 3.868852459016394e-06, 'epoch': 80.66}        \n",
      "{'loss': 0.2848, 'learning_rate': 3.8360655737704925e-06, 'epoch': 80.82}       \n",
      "{'loss': 0.312, 'learning_rate': 3.8032786885245902e-06, 'epoch': 80.98}        \n",
      " 81%|███████████████████████████████▌       | 4941/6100 [58:48<10:54,  1.77it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:05:14,145 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:05:14,145 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:05:14,145 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.03it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.88it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7946283221244812, 'eval_accuracy': 0.7656477438136827, 'eval_runtime': 6.256, 'eval_samples_per_second': 109.815, 'eval_steps_per_second': 1.758, 'epoch': 81.0}\n",
      " 81%|███████████████████████████████▌       | 4941/6100 [58:54<10:54,  1.77it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:05:20,402 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4941\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:05:20,403 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4941/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:05:20,567 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4941/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:05:20,568 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4941/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:05:20,815 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4819] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.316, 'learning_rate': 3.7704918032786884e-06, 'epoch': 81.15}        \n",
      "{'loss': 0.3015, 'learning_rate': 3.7377049180327874e-06, 'epoch': 81.31}       \n",
      "{'loss': 0.2655, 'learning_rate': 3.7049180327868856e-06, 'epoch': 81.48}       \n",
      "{'loss': 0.3148, 'learning_rate': 3.672131147540984e-06, 'epoch': 81.64}        \n",
      "{'loss': 0.2866, 'learning_rate': 3.6393442622950824e-06, 'epoch': 81.8}        \n",
      "{'loss': 0.2733, 'learning_rate': 3.6065573770491806e-06, 'epoch': 81.97}       \n",
      " 82%|███████████████████████████████▉       | 5002/6100 [59:32<10:10,  1.80it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:05:58,802 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:05:58,802 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:05:58,802 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.48it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  2.00it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.87it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.83it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.79294353723526, 'eval_accuracy': 0.7714701601164483, 'eval_runtime': 6.127, 'eval_samples_per_second': 112.127, 'eval_steps_per_second': 1.795, 'epoch': 82.0}\n",
      " 82%|███████████████████████████████▉       | 5002/6100 [59:39<10:10,  1.80it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:06:04,930 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5002\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:06:04,931 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5002/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:06:05,084 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5002/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:06:05,085 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5002/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:06:05,333 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4880] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3029, 'learning_rate': 3.573770491803279e-06, 'epoch': 82.13}        \n",
      "{'loss': 0.3298, 'learning_rate': 3.540983606557377e-06, 'epoch': 82.3}         \n",
      "{'loss': 0.2334, 'learning_rate': 3.508196721311476e-06, 'epoch': 82.46}        \n",
      "{'loss': 0.2855, 'learning_rate': 3.4754098360655742e-06, 'epoch': 82.62}       \n",
      "{'loss': 0.3186, 'learning_rate': 3.4426229508196724e-06, 'epoch': 82.79}       \n",
      "{'loss': 0.3056, 'learning_rate': 3.4098360655737706e-06, 'epoch': 82.95}       \n",
      " 83%|██████████████████████████████▋      | 5063/6100 [1:00:16<09:03,  1.91it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:06:42,877 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:06:42,877 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:06:42,877 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.85it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.99it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.72it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.59it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8209109306335449, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.5713, 'eval_samples_per_second': 150.286, 'eval_steps_per_second': 2.406, 'epoch': 83.0}\n",
      " 83%|██████████████████████████████▋      | 5063/6100 [1:00:21<09:03,  1.91it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.17it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:06:47,449 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5063\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:06:47,450 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5063/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:06:47,560 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5063/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:06:47,560 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5063/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:06:47,745 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-4941] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2737, 'learning_rate': 3.3770491803278692e-06, 'epoch': 83.11}       \n",
      "{'loss': 0.3057, 'learning_rate': 3.3442622950819674e-06, 'epoch': 83.28}       \n",
      "{'loss': 0.3026, 'learning_rate': 3.3114754098360656e-06, 'epoch': 83.44}       \n",
      "{'loss': 0.2377, 'learning_rate': 3.2786885245901638e-06, 'epoch': 83.61}       \n",
      "{'loss': 0.3047, 'learning_rate': 3.245901639344263e-06, 'epoch': 83.77}        \n",
      "{'loss': 0.264, 'learning_rate': 3.213114754098361e-06, 'epoch': 83.93}         \n",
      " 84%|███████████████████████████████      | 5124/6100 [1:00:58<07:25,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:07:24,858 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:07:24,858 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:07:24,858 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.67it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.13it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.76it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.52it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.35it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.29it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.27it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8059059977531433, 'eval_accuracy': 0.7860262008733624, 'eval_runtime': 4.7125, 'eval_samples_per_second': 145.782, 'eval_steps_per_second': 2.334, 'epoch': 84.0}\n",
      " 84%|███████████████████████████████      | 5124/6100 [1:01:03<07:25,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.13it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:07:29,570 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5124\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:07:29,571 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5124/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:07:29,681 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5124/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:07:29,681 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5124/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:07:29,863 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5002] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2898, 'learning_rate': 3.180327868852459e-06, 'epoch': 84.1}         \n",
      "{'loss': 0.2896, 'learning_rate': 3.147540983606558e-06, 'epoch': 84.26}        \n",
      "{'loss': 0.261, 'learning_rate': 3.114754098360656e-06, 'epoch': 84.43}         \n",
      "{'loss': 0.2978, 'learning_rate': 3.081967213114754e-06, 'epoch': 84.59}        \n",
      "{'loss': 0.2929, 'learning_rate': 3.0491803278688524e-06, 'epoch': 84.75}       \n",
      "{'loss': 0.2359, 'learning_rate': 3.0163934426229514e-06, 'epoch': 84.92}       \n",
      " 85%|███████████████████████████████▍     | 5185/6100 [1:01:42<06:57,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:08:08,154 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:08:08,154 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:08:08,154 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.72it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.42it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.98it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.66it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.58it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.50it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8386242985725403, 'eval_accuracy': 0.7831149927219796, 'eval_runtime': 4.5427, 'eval_samples_per_second': 151.233, 'eval_steps_per_second': 2.421, 'epoch': 85.0}\n",
      " 85%|███████████████████████████████▍     | 5185/6100 [1:01:46<06:57,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.22it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:08:12,697 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5185\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:08:12,698 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5185/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:08:12,819 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5185/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:08:12,820 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5185/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:08:13,000 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5063] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2721, 'learning_rate': 2.9836065573770496e-06, 'epoch': 85.08}       \n",
      "{'loss': 0.2493, 'learning_rate': 2.9508196721311478e-06, 'epoch': 85.25}       \n",
      "{'loss': 0.2712, 'learning_rate': 2.918032786885246e-06, 'epoch': 85.41}        \n",
      "{'loss': 0.2668, 'learning_rate': 2.8852459016393446e-06, 'epoch': 85.57}       \n",
      "{'loss': 0.2656, 'learning_rate': 2.8524590163934428e-06, 'epoch': 85.74}       \n",
      "{'loss': 0.2797, 'learning_rate': 2.819672131147541e-06, 'epoch': 85.9}         \n",
      " 86%|███████████████████████████████▊     | 5246/6100 [1:02:26<06:31,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:08:52,277 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:08:52,277 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:08:52,277 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.50it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.75it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.46it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8227276802062988, 'eval_accuracy': 0.7787481804949054, 'eval_runtime': 4.6074, 'eval_samples_per_second': 149.108, 'eval_steps_per_second': 2.387, 'epoch': 86.0}\n",
      " 86%|███████████████████████████████▊     | 5246/6100 [1:02:30<06:31,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.19it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:08:56,885 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5246\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:08:56,886 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5246/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:08:57,011 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5246/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:08:57,011 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5246/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:08:57,191 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5124] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2802, 'learning_rate': 2.786885245901639e-06, 'epoch': 86.07}        \n",
      "{'loss': 0.286, 'learning_rate': 2.754098360655738e-06, 'epoch': 86.23}         \n",
      "{'loss': 0.2678, 'learning_rate': 2.7213114754098364e-06, 'epoch': 86.39}       \n",
      "{'loss': 0.2852, 'learning_rate': 2.6885245901639346e-06, 'epoch': 86.56}       \n",
      "{'loss': 0.3326, 'learning_rate': 2.6557377049180328e-06, 'epoch': 86.72}       \n",
      "{'loss': 0.2742, 'learning_rate': 2.6229508196721314e-06, 'epoch': 86.89}       \n",
      " 87%|████████████████████████████████▏    | 5307/6100 [1:03:09<06:02,  2.19it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:09:35,387 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:09:35,387 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:09:35,387 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.60it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.38it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.91it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.14it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8224078416824341, 'eval_accuracy': 0.7831149927219796, 'eval_runtime': 4.7955, 'eval_samples_per_second': 143.26, 'eval_steps_per_second': 2.294, 'epoch': 87.0}\n",
      " 87%|████████████████████████████████▏    | 5307/6100 [1:03:14<06:02,  2.19it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.83it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:09:40,183 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5307\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:09:40,184 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5307/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:09:40,342 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5307/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:09:40,343 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5307/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:09:40,597 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5185] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3149, 'learning_rate': 2.5901639344262296e-06, 'epoch': 87.05}       \n",
      "{'loss': 0.2675, 'learning_rate': 2.5573770491803277e-06, 'epoch': 87.21}       \n",
      "{'loss': 0.2395, 'learning_rate': 2.5245901639344268e-06, 'epoch': 87.38}       \n",
      "{'loss': 0.2864, 'learning_rate': 2.491803278688525e-06, 'epoch': 87.54}        \n",
      "{'loss': 0.2787, 'learning_rate': 2.459016393442623e-06, 'epoch': 87.7}         \n",
      "{'loss': 0.2918, 'learning_rate': 2.4262295081967218e-06, 'epoch': 87.87}       \n",
      " 88%|████████████████████████████████▌    | 5368/6100 [1:03:53<06:04,  2.01it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:10:18,949 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:10:18,950 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:10:18,950 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.57it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.52it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8150547742843628, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 6.1447, 'eval_samples_per_second': 111.804, 'eval_steps_per_second': 1.79, 'epoch': 88.0}\n",
      " 88%|████████████████████████████████▌    | 5368/6100 [1:03:59<06:04,  2.01it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:10:25,095 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5368\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:10:25,096 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5368/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:10:25,250 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5368/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:10:25,250 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5368/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:10:25,498 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5246] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2634, 'learning_rate': 2.39344262295082e-06, 'epoch': 88.03}         \n",
      "{'loss': 0.2606, 'learning_rate': 2.360655737704918e-06, 'epoch': 88.2}         \n",
      "{'loss': 0.2538, 'learning_rate': 2.3278688524590163e-06, 'epoch': 88.36}       \n",
      "{'loss': 0.2909, 'learning_rate': 2.295081967213115e-06, 'epoch': 88.52}        \n",
      "{'loss': 0.2938, 'learning_rate': 2.262295081967213e-06, 'epoch': 88.69}        \n",
      "{'loss': 0.2568, 'learning_rate': 2.2295081967213117e-06, 'epoch': 88.85}       \n",
      " 89%|████████████████████████████████▉    | 5429/6100 [1:04:37<06:15,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:11:03,661 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:11:03,661 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:11:03,661 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.39it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.08it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.91it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.84it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8429090976715088, 'eval_accuracy': 0.7714701601164483, 'eval_runtime': 6.2184, 'eval_samples_per_second': 110.479, 'eval_steps_per_second': 1.769, 'epoch': 89.0}\n",
      " 89%|████████████████████████████████▉    | 5429/6100 [1:04:43<06:15,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:11:09,880 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5429\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:11:09,881 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5429/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:11:10,040 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5429/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:11:10,040 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5429/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:11:10,285 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5307] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2779, 'learning_rate': 2.19672131147541e-06, 'epoch': 89.02}         \n",
      "{'loss': 0.2584, 'learning_rate': 2.1639344262295085e-06, 'epoch': 89.18}       \n",
      "{'loss': 0.2975, 'learning_rate': 2.1311475409836067e-06, 'epoch': 89.34}       \n",
      "{'loss': 0.2928, 'learning_rate': 2.098360655737705e-06, 'epoch': 89.51}        \n",
      "{'loss': 0.2705, 'learning_rate': 2.0655737704918035e-06, 'epoch': 89.67}       \n",
      "{'loss': 0.2187, 'learning_rate': 2.0327868852459017e-06, 'epoch': 89.84}       \n",
      "{'loss': 0.2866, 'learning_rate': 2.0000000000000003e-06, 'epoch': 90.0}        \n",
      " 90%|█████████████████████████████████▎   | 5490/6100 [1:05:22<05:39,  1.80it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:11:48,116 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:11:48,116 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:11:48,116 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.38it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.93it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8159478902816772, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 6.2589, 'eval_samples_per_second': 109.764, 'eval_steps_per_second': 1.757, 'epoch': 90.0}\n",
      " 90%|█████████████████████████████████▎   | 5490/6100 [1:05:28<05:39,  1.80it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:11:54,375 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5490\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:11:54,376 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5490/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:11:54,534 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5490/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:11:54,534 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5490/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:11:54,785 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5368] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.283, 'learning_rate': 1.9672131147540985e-06, 'epoch': 90.16}        \n",
      "{'loss': 0.2297, 'learning_rate': 1.934426229508197e-06, 'epoch': 90.33}        \n",
      "{'loss': 0.2877, 'learning_rate': 1.9016393442622951e-06, 'epoch': 90.49}       \n",
      "{'loss': 0.2739, 'learning_rate': 1.8688524590163937e-06, 'epoch': 90.66}       \n",
      "{'loss': 0.2785, 'learning_rate': 1.836065573770492e-06, 'epoch': 90.82}        \n",
      "{'loss': 0.2582, 'learning_rate': 1.8032786885245903e-06, 'epoch': 90.98}       \n",
      " 91%|█████████████████████████████████▋   | 5551/6100 [1:06:06<05:06,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:12:32,694 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:12:32,694 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:12:32,694 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.38it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8485468029975891, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 6.1519, 'eval_samples_per_second': 111.673, 'eval_steps_per_second': 1.788, 'epoch': 91.0}\n",
      " 91%|█████████████████████████████████▋   | 5551/6100 [1:06:12<05:06,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:12:38,846 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5551\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:12:38,848 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5551/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:12:39,012 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5551/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:12:39,013 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5551/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:12:39,259 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5429] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2753, 'learning_rate': 1.7704918032786885e-06, 'epoch': 91.15}       \n",
      "{'loss': 0.2797, 'learning_rate': 1.7377049180327871e-06, 'epoch': 91.31}       \n",
      "{'loss': 0.2268, 'learning_rate': 1.7049180327868853e-06, 'epoch': 91.48}       \n",
      "{'loss': 0.2952, 'learning_rate': 1.6721311475409837e-06, 'epoch': 91.64}       \n",
      "{'loss': 0.3145, 'learning_rate': 1.6393442622950819e-06, 'epoch': 91.8}        \n",
      "{'loss': 0.2485, 'learning_rate': 1.6065573770491805e-06, 'epoch': 91.97}       \n",
      " 92%|██████████████████████████████████   | 5612/6100 [1:06:51<04:32,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:13:17,181 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:13:17,181 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:13:17,181 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.38it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.43it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.41it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.37it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8355858325958252, 'eval_accuracy': 0.7758369723435226, 'eval_runtime': 5.0985, 'eval_samples_per_second': 134.744, 'eval_steps_per_second': 2.157, 'epoch': 92.0}\n",
      " 92%|██████████████████████████████████   | 5612/6100 [1:06:56<04:32,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.30it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:13:22,280 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5612\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:13:22,281 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5612/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:13:22,396 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5612/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:13:22,397 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5612/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:13:22,572 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5490] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2471, 'learning_rate': 1.573770491803279e-06, 'epoch': 92.13}        \n",
      "{'loss': 0.3096, 'learning_rate': 1.540983606557377e-06, 'epoch': 92.3}         \n",
      "{'loss': 0.2695, 'learning_rate': 1.5081967213114757e-06, 'epoch': 92.46}       \n",
      "{'loss': 0.2795, 'learning_rate': 1.4754098360655739e-06, 'epoch': 92.62}       \n",
      "{'loss': 0.274, 'learning_rate': 1.4426229508196723e-06, 'epoch': 92.79}        \n",
      "{'loss': 0.2771, 'learning_rate': 1.4098360655737705e-06, 'epoch': 92.95}       \n",
      " 93%|██████████████████████████████████▍  | 5673/6100 [1:07:35<03:31,  2.02it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:14:00,987 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:14:00,987 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:14:00,987 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.53it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.29it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.87it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.62it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8503347635269165, 'eval_accuracy': 0.7831149927219796, 'eval_runtime': 4.4779, 'eval_samples_per_second': 153.421, 'eval_steps_per_second': 2.457, 'epoch': 93.0}\n",
      " 93%|██████████████████████████████████▍  | 5673/6100 [1:07:39<03:31,  2.02it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.57it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:14:05,466 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5673\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:14:05,467 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5673/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:14:05,585 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5673/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:14:05,585 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5673/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:14:05,770 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5551] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3079, 'learning_rate': 1.377049180327869e-06, 'epoch': 93.11}        \n",
      "{'loss': 0.2785, 'learning_rate': 1.3442622950819673e-06, 'epoch': 93.28}       \n",
      "{'loss': 0.3136, 'learning_rate': 1.3114754098360657e-06, 'epoch': 93.44}       \n",
      "{'loss': 0.2804, 'learning_rate': 1.2786885245901639e-06, 'epoch': 93.61}       \n",
      "{'loss': 0.2779, 'learning_rate': 1.2459016393442625e-06, 'epoch': 93.77}       \n",
      "{'loss': 0.2416, 'learning_rate': 1.2131147540983609e-06, 'epoch': 93.93}       \n",
      " 94%|██████████████████████████████████▊  | 5734/6100 [1:08:17<02:50,  2.15it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:14:43,272 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:14:43,272 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:14:43,272 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.54it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.23it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8367322683334351, 'eval_accuracy': 0.7714701601164483, 'eval_runtime': 4.5096, 'eval_samples_per_second': 152.343, 'eval_steps_per_second': 2.439, 'epoch': 94.0}\n",
      " 94%|██████████████████████████████████▊  | 5734/6100 [1:08:21<02:50,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:14:47,782 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5734\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:14:47,783 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5734/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:14:47,899 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5734/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:14:47,900 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5734/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:14:48,077 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5612] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2852, 'learning_rate': 1.180327868852459e-06, 'epoch': 94.1}         \n",
      "{'loss': 0.2847, 'learning_rate': 1.1475409836065575e-06, 'epoch': 94.26}       \n",
      "{'loss': 0.2541, 'learning_rate': 1.1147540983606559e-06, 'epoch': 94.43}       \n",
      "{'loss': 0.3046, 'learning_rate': 1.0819672131147543e-06, 'epoch': 94.59}       \n",
      "{'loss': 0.2756, 'learning_rate': 1.0491803278688525e-06, 'epoch': 94.75}       \n",
      "{'loss': 0.2699, 'learning_rate': 1.0163934426229509e-06, 'epoch': 94.92}       \n",
      " 95%|███████████████████████████████████▏ | 5795/6100 [1:08:59<02:19,  2.18it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:15:25,782 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:15:25,782 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:15:25,782 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.93it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.90it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.61it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.51it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8282941579818726, 'eval_accuracy': 0.7729257641921398, 'eval_runtime': 4.5026, 'eval_samples_per_second': 152.577, 'eval_steps_per_second': 2.443, 'epoch': 95.0}\n",
      " 95%|███████████████████████████████████▏ | 5795/6100 [1:09:04<02:19,  2.18it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.26it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:15:30,285 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5795\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:15:30,286 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5795/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:15:30,397 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5795/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:15:30,398 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5795/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:15:30,582 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5673] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2535, 'learning_rate': 9.836065573770493e-07, 'epoch': 95.08}        \n",
      "{'loss': 0.2421, 'learning_rate': 9.508196721311476e-07, 'epoch': 95.25}        \n",
      "{'loss': 0.2923, 'learning_rate': 9.18032786885246e-07, 'epoch': 95.41}         \n",
      "{'loss': 0.2605, 'learning_rate': 8.852459016393443e-07, 'epoch': 95.57}        \n",
      "{'loss': 0.2503, 'learning_rate': 8.524590163934427e-07, 'epoch': 95.74}        \n",
      "{'loss': 0.2568, 'learning_rate': 8.196721311475409e-07, 'epoch': 95.9}         \n",
      " 96%|███████████████████████████████████▌ | 5856/6100 [1:09:43<01:55,  2.12it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:16:09,541 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:16:09,541 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:16:09,541 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.59it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.21it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.81it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.19it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8277336359024048, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 4.808, 'eval_samples_per_second': 142.885, 'eval_steps_per_second': 2.288, 'epoch': 96.0}\n",
      " 96%|███████████████████████████████████▌ | 5856/6100 [1:09:48<01:55,  2.12it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.84it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:16:14,350 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5856\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:16:14,350 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5856/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:16:14,508 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5856/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:16:14,509 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5856/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:16:14,767 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5734] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.3177, 'learning_rate': 7.868852459016395e-07, 'epoch': 96.07}        \n",
      "{'loss': 0.2889, 'learning_rate': 7.540983606557379e-07, 'epoch': 96.23}        \n",
      "{'loss': 0.3305, 'learning_rate': 7.213114754098361e-07, 'epoch': 96.39}        \n",
      "{'loss': 0.2395, 'learning_rate': 6.885245901639345e-07, 'epoch': 96.56}        \n",
      "{'loss': 0.3003, 'learning_rate': 6.557377049180328e-07, 'epoch': 96.72}        \n",
      "{'loss': 0.2611, 'learning_rate': 6.229508196721312e-07, 'epoch': 96.89}        \n",
      " 97%|███████████████████████████████████▉ | 5917/6100 [1:10:27<01:41,  1.81it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:16:53,057 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:16:53,057 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:16:53,057 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.43it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.43it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.05it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.82it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.80it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.73it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.81it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8271996378898621, 'eval_accuracy': 0.7714701601164483, 'eval_runtime': 6.3182, 'eval_samples_per_second': 108.734, 'eval_steps_per_second': 1.741, 'epoch': 97.0}\n",
      " 97%|███████████████████████████████████▉ | 5917/6100 [1:10:33<01:41,  1.81it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.41it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:16:59,376 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5917\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:16:59,377 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5917/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:16:59,536 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5917/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:16:59,537 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5917/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:16:59,787 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5795] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2865, 'learning_rate': 5.901639344262295e-07, 'epoch': 97.05}        \n",
      "{'loss': 0.2184, 'learning_rate': 5.573770491803279e-07, 'epoch': 97.21}        \n",
      "{'loss': 0.2613, 'learning_rate': 5.245901639344262e-07, 'epoch': 97.38}        \n",
      "{'loss': 0.2779, 'learning_rate': 4.918032786885246e-07, 'epoch': 97.54}        \n",
      "{'loss': 0.2225, 'learning_rate': 4.59016393442623e-07, 'epoch': 97.7}          \n",
      "{'loss': 0.2473, 'learning_rate': 4.262295081967213e-07, 'epoch': 97.87}        \n",
      " 98%|████████████████████████████████████▎| 5978/6100 [1:11:11<01:08,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:17:37,789 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:17:37,790 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:17:37,790 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.40it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.70it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.72it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.83it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8338974714279175, 'eval_accuracy': 0.7758369723435226, 'eval_runtime': 6.2822, 'eval_samples_per_second': 109.356, 'eval_steps_per_second': 1.751, 'epoch': 98.0}\n",
      " 98%|████████████████████████████████████▎| 5978/6100 [1:11:18<01:08,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.44it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:17:44,072 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5978\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:17:44,073 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5978/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:17:44,247 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5978/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:17:44,248 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5978/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:17:44,501 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5856] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2743, 'learning_rate': 3.934426229508197e-07, 'epoch': 98.03}        \n",
      "{'loss': 0.3317, 'learning_rate': 3.6065573770491807e-07, 'epoch': 98.2}        \n",
      "{'loss': 0.2662, 'learning_rate': 3.278688524590164e-07, 'epoch': 98.36}        \n",
      "{'loss': 0.2846, 'learning_rate': 2.9508196721311477e-07, 'epoch': 98.52}       \n",
      "{'loss': 0.2336, 'learning_rate': 2.622950819672131e-07, 'epoch': 98.69}        \n",
      "{'loss': 0.2947, 'learning_rate': 2.295081967213115e-07, 'epoch': 98.85}        \n",
      " 99%|████████████████████████████████████▋| 6039/6100 [1:11:56<00:33,  1.80it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:18:22,327 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:18:22,327 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:18:22,327 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.46it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.82it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.83310467004776, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 6.1496, 'eval_samples_per_second': 111.714, 'eval_steps_per_second': 1.789, 'epoch': 99.0}\n",
      " 99%|████████████████████████████████████▋| 6039/6100 [1:12:02<00:33,  1.80it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:18:28,478 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6039\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:18:28,479 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6039/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:18:28,652 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6039/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:18:28,652 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6039/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:18:28,904 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5917] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.2932, 'learning_rate': 1.9672131147540986e-07, 'epoch': 99.02}       \n",
      "{'loss': 0.2785, 'learning_rate': 1.639344262295082e-07, 'epoch': 99.18}        \n",
      "{'loss': 0.2152, 'learning_rate': 1.3114754098360656e-07, 'epoch': 99.34}       \n",
      "{'loss': 0.3382, 'learning_rate': 9.836065573770493e-08, 'epoch': 99.51}        \n",
      "{'loss': 0.2642, 'learning_rate': 6.557377049180328e-08, 'epoch': 99.67}        \n",
      "{'loss': 0.2598, 'learning_rate': 3.278688524590164e-08, 'epoch': 99.84}        \n",
      "{'loss': 0.3066, 'learning_rate': 0.0, 'epoch': 100.0}                          \n",
      "100%|█████████████████████████████████████| 6100/6100 [1:12:40<00:00,  1.79it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:19:06,646 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:19:06,646 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:19:06,646 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.39it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.09it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.73it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.85it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8308762907981873, 'eval_accuracy': 0.7743813682678311, 'eval_runtime': 6.2183, 'eval_samples_per_second': 110.481, 'eval_steps_per_second': 1.769, 'epoch': 100.0}\n",
      "100%|█████████████████████████████████████| 6100/6100 [1:12:46<00:00,  1.79it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:19:12,865 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6100\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:19:12,867 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6100/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:19:13,028 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6100/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:19:13,029 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-6100/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:19:13,277 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-5978] due to args.save_total_limit\n",
      "[INFO|trainer.py:1916] 2023-10-05 13:19:13,311 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2051] 2023-10-05 13:19:13,311 >> Loading best model from outputs_all/swin_combine_pseudo_30%_Fold_7/checkpoint-1464 (score: 0.6285605430603027).\n",
      "{'train_runtime': 4367.5039, 'train_samples_per_second': 89.09, 'train_steps_per_second': 1.397, 'train_loss': 0.4430094235842345, 'epoch': 100.0}\n",
      "100%|█████████████████████████████████████| 6100/6100 [1:12:47<00:00,  1.40it/s]\n",
      "[INFO|trainer.py:2800] 2023-10-05 13:19:13,391 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_7\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:19:13,392 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_7/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:19:13,521 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_7/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:19:13,521 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_7/preprocessor_config.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      100.0\n",
      "  train_loss               =      0.443\n",
      "  train_runtime            = 1:12:47.50\n",
      "  train_samples_per_second =      89.09\n",
      "  train_steps_per_second   =      1.397\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:19:13,534 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:19:13,534 >>   Num examples = 687\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:19:13,534 >>   Batch size = 64\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =      100.0\n",
      "  eval_accuracy           =     0.7846\n",
      "  eval_loss               =     0.6286\n",
      "  eval_runtime            = 0:00:05.31\n",
      "  eval_samples_per_second =    129.143\n",
      "  eval_steps_per_second   =      2.068\n",
      "10/05/2023 13:19:22 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: False\n",
      "10/05/2023 13:19:22 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=2,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs_all/swin_combine_pseudo_30%_Fold_8/runs/Oct05_13-19-21_thanawit-Z690-Pro-RS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=100.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=outputs_all/swin_combine_pseudo_30%_Fold_8,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs_all/swin_combine_pseudo_30%_Fold_8,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|███████████████| 4565/4565 [00:00<00:00, 8801.94it/s]\n",
      "10/05/2023 13:19:24 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-d8553ce6f837c847/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 94.49it/s]\n",
      "10/05/2023 13:19:24 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-d8553ce6f837c847/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-ebc716a06e698c3e.arrow\n",
      "10/05/2023 13:19:24 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-d8553ce6f837c847/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-f21ad7f1a3033805.arrow and /home/thanawit/.cache/huggingface/datasets/imagefolder/combine_pseudo_labeled-d8553ce6f837c847/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-b29ab9d48895c0b5.arrow\n",
      "[INFO|configuration_utils.py:669] 2023-10-05 13:19:26,444 >> loading configuration file config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-10-05 13:19:26,445 >> Model config SwinConfig {\n",
      "  \"_name_or_path\": \"microsoft/swin-tiny-patch4-window7-224\",\n",
      "  \"architectures\": [\n",
      "    \"SwinForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    6,\n",
      "    2\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"embed_dim\": 96,\n",
      "  \"encoder_stride\": 32,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Atypical\",\n",
      "    \"1\": \"Indeterminate\",\n",
      "    \"2\": \"Negative\",\n",
      "    \"3\": \"Typical\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Atypical\": \"0\",\n",
      "    \"Indeterminate\": \"1\",\n",
      "    \"Negative\": \"2\",\n",
      "    \"Typical\": \"3\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mlp_ratio\": 4.0,\n",
      "  \"model_type\": \"swin\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_heads\": [\n",
      "    3,\n",
      "    6,\n",
      "    12,\n",
      "    24\n",
      "  ],\n",
      "  \"num_layers\": 4,\n",
      "  \"out_features\": [\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"out_indices\": [\n",
      "    4\n",
      "  ],\n",
      "  \"patch_size\": 4,\n",
      "  \"path_norm\": true,\n",
      "  \"qkv_bias\": true,\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0.dev0\",\n",
      "  \"use_absolute_embeddings\": false,\n",
      "  \"window_size\": 7\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2575] 2023-10-05 13:19:26,447 >> loading weights file model.safetensors from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/model.safetensors\n",
      "[INFO|modeling_utils.py:3283] 2023-10-05 13:19:26,612 >> All model checkpoint weights were used when initializing SwinForImageClassification.\n",
      "\n",
      "[WARNING|modeling_utils.py:3304] 2023-10-05 13:19:26,613 >> Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-10-05 13:19:27,101 >> loading configuration file preprocessor_config.json from cache at /home/thanawit/.cache/huggingface/hub/models--microsoft--swin-tiny-patch4-window7-224/snapshots/d00d478bfaf1f417d34a1186673ad4b4be264c51/preprocessor_config.json\n",
      "[WARNING|image_processing_auto.py:331] 2023-10-05 13:19:27,102 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "[INFO|image_processing_utils.py:542] 2023-10-05 13:19:27,107 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "[INFO|image_processing_utils.py:359] 2023-10-05 13:19:27,107 >> Image processor ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:1680] 2023-10-05 13:19:27,854 >> ***** Running training *****\n",
      "[INFO|trainer.py:1681] 2023-10-05 13:19:27,854 >>   Num examples = 3,880\n",
      "[INFO|trainer.py:1682] 2023-10-05 13:19:27,854 >>   Num Epochs = 100\n",
      "[INFO|trainer.py:1683] 2023-10-05 13:19:27,854 >>   Instantaneous batch size per device = 64\n",
      "[INFO|trainer.py:1684] 2023-10-05 13:19:27,854 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1685] 2023-10-05 13:19:27,854 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1686] 2023-10-05 13:19:27,854 >>   Total optimization steps = 6,100\n",
      "[INFO|trainer.py:1687] 2023-10-05 13:19:27,854 >>   Number of trainable parameters = 27,522,430\n",
      "  0%|                                                  | 0/6100 [00:00<?, ?it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 1.1879, 'learning_rate': 1.99672131147541e-05, 'epoch': 0.16}          \n",
      "{'loss': 0.9229, 'learning_rate': 1.99344262295082e-05, 'epoch': 0.33}          \n",
      "{'loss': 0.9149, 'learning_rate': 1.9901639344262297e-05, 'epoch': 0.49}        \n",
      "{'loss': 0.8553, 'learning_rate': 1.9868852459016394e-05, 'epoch': 0.66}        \n",
      "{'loss': 0.8085, 'learning_rate': 1.9836065573770492e-05, 'epoch': 0.82}        \n",
      "{'loss': 0.8106, 'learning_rate': 1.9803278688524592e-05, 'epoch': 0.98}        \n",
      "  1%|▍                                        | 61/6100 [00:40<45:49,  2.20it/s][INFO|trainer.py:3074] 2023-10-05 13:20:08,213 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:20:08,213 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:20:08,213 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.31it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.03it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.68it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.44it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.36it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.35it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.29it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.26it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7467151284217834, 'eval_accuracy': 0.7489051094890511, 'eval_runtime': 4.8744, 'eval_samples_per_second': 140.529, 'eval_steps_per_second': 2.257, 'epoch': 1.0}\n",
      "  1%|▍                                        | 61/6100 [00:45<45:49,  2.20it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.09it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:20:13,087 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-61\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:20:13,088 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-61/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:20:13,197 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-61/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:20:13,197 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-61/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.836, 'learning_rate': 1.977049180327869e-05, 'epoch': 1.15}          \n",
      "{'loss': 0.7759, 'learning_rate': 1.973770491803279e-05, 'epoch': 1.31}         \n",
      "{'loss': 0.814, 'learning_rate': 1.9704918032786884e-05, 'epoch': 1.48}         \n",
      "{'loss': 0.7336, 'learning_rate': 1.9672131147540985e-05, 'epoch': 1.64}        \n",
      "{'loss': 0.8047, 'learning_rate': 1.9639344262295083e-05, 'epoch': 1.8}         \n",
      "{'loss': 0.778, 'learning_rate': 1.9606557377049183e-05, 'epoch': 1.97}         \n",
      "  2%|▊                                       | 122/6100 [01:22<44:17,  2.25it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:20:50,518 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:20:50,518 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:20:50,518 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.32it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.63it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.21it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.00it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.681287407875061, 'eval_accuracy': 0.7708029197080292, 'eval_runtime': 5.8096, 'eval_samples_per_second': 117.909, 'eval_steps_per_second': 1.893, 'epoch': 2.0}\n",
      "  2%|▊                                       | 122/6100 [01:28<44:17,  2.25it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:20:56,328 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-122\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:20:56,329 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-122/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:20:56,486 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-122/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:20:56,487 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-122/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7191, 'learning_rate': 1.957377049180328e-05, 'epoch': 2.13}         \n",
      "{'loss': 0.7844, 'learning_rate': 1.9540983606557378e-05, 'epoch': 2.3}         \n",
      "{'loss': 0.8008, 'learning_rate': 1.9508196721311475e-05, 'epoch': 2.46}        \n",
      "{'loss': 0.7434, 'learning_rate': 1.9475409836065576e-05, 'epoch': 2.62}        \n",
      "{'loss': 0.8035, 'learning_rate': 1.9442622950819673e-05, 'epoch': 2.79}        \n",
      "{'loss': 0.6737, 'learning_rate': 1.9409836065573774e-05, 'epoch': 2.95}        \n",
      "  3%|█▏                                      | 183/6100 [02:06<49:46,  1.98it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:21:34,238 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:21:34,238 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:21:34,238 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.63it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.52it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.82it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7306169867515564, 'eval_accuracy': 0.7518248175182481, 'eval_runtime': 6.1154, 'eval_samples_per_second': 112.012, 'eval_steps_per_second': 1.799, 'epoch': 3.0}\n",
      "  3%|█▏                                      | 183/6100 [02:12<49:46,  1.98it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:21:40,354 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-183\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:21:40,354 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-183/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:21:40,514 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-183/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:21:40,515 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-183/preprocessor_config.json\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7247, 'learning_rate': 1.937704918032787e-05, 'epoch': 3.11}         \n",
      "{'loss': 0.8159, 'learning_rate': 1.934426229508197e-05, 'epoch': 3.28}         \n",
      "{'loss': 0.691, 'learning_rate': 1.9311475409836066e-05, 'epoch': 3.44}         \n",
      "{'loss': 0.7622, 'learning_rate': 1.9278688524590167e-05, 'epoch': 3.61}        \n",
      "{'loss': 0.7707, 'learning_rate': 1.9245901639344264e-05, 'epoch': 3.77}        \n",
      "{'loss': 0.7259, 'learning_rate': 1.921311475409836e-05, 'epoch': 3.93}         \n",
      "  4%|█▌                                      | 244/6100 [02:50<52:37,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:22:18,622 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:22:18,622 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:22:18,622 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.24it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.10it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.84it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.92it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7058640718460083, 'eval_accuracy': 0.7401459854014598, 'eval_runtime': 6.1212, 'eval_samples_per_second': 111.905, 'eval_steps_per_second': 1.797, 'epoch': 4.0}\n",
      "  4%|█▌                                      | 244/6100 [02:56<52:37,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:22:24,743 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-244\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:22:24,745 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-244/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:22:24,900 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-244/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:22:24,900 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-244/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:22:25,149 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-61] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6628, 'learning_rate': 1.918032786885246e-05, 'epoch': 4.1}          \n",
      "{'loss': 0.7718, 'learning_rate': 1.914754098360656e-05, 'epoch': 4.26}         \n",
      "{'loss': 0.6827, 'learning_rate': 1.9114754098360657e-05, 'epoch': 4.43}        \n",
      "{'loss': 0.6886, 'learning_rate': 1.9081967213114754e-05, 'epoch': 4.59}        \n",
      "{'loss': 0.7421, 'learning_rate': 1.9049180327868855e-05, 'epoch': 4.75}        \n",
      "{'loss': 0.7322, 'learning_rate': 1.9016393442622952e-05, 'epoch': 4.92}        \n",
      "  5%|██                                      | 305/6100 [03:34<51:23,  1.88it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:23:02,824 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:23:02,824 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:23:02,824 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.51it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.49it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.18it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6567560434341431, 'eval_accuracy': 0.7883211678832117, 'eval_runtime': 6.1522, 'eval_samples_per_second': 111.343, 'eval_steps_per_second': 1.788, 'epoch': 5.0}\n",
      "  5%|██                                      | 305/6100 [03:41<51:23,  1.88it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.87it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:23:08,977 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-305\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:23:08,978 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-305/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:23:09,127 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-305/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:23:09,127 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-305/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:23:09,372 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-122] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7442, 'learning_rate': 1.898360655737705e-05, 'epoch': 5.08}         \n",
      "{'loss': 0.7187, 'learning_rate': 1.895081967213115e-05, 'epoch': 5.25}         \n",
      "{'loss': 0.6923, 'learning_rate': 1.8918032786885248e-05, 'epoch': 5.41}        \n",
      "{'loss': 0.7101, 'learning_rate': 1.8885245901639345e-05, 'epoch': 5.57}        \n",
      "{'loss': 0.7536, 'learning_rate': 1.8852459016393446e-05, 'epoch': 5.74}        \n",
      "{'loss': 0.6718, 'learning_rate': 1.8819672131147543e-05, 'epoch': 5.9}         \n",
      "  6%|██▍                                     | 366/6100 [04:18<45:14,  2.11it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:23:46,713 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:23:46,713 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:23:46,713 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.60it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.20it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.48it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.58it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6931917071342468, 'eval_accuracy': 0.7693430656934307, 'eval_runtime': 4.4929, 'eval_samples_per_second': 152.463, 'eval_steps_per_second': 2.448, 'epoch': 6.0}\n",
      "  6%|██▍                                     | 366/6100 [04:23<45:14,  2.11it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.32it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:23:51,207 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-366\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:23:51,208 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-366/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:23:51,320 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-366/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:23:51,320 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-366/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:23:51,490 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-183] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7109, 'learning_rate': 1.878688524590164e-05, 'epoch': 6.07}         \n",
      "{'loss': 0.6816, 'learning_rate': 1.8754098360655738e-05, 'epoch': 6.23}        \n",
      "{'loss': 0.7532, 'learning_rate': 1.872131147540984e-05, 'epoch': 6.39}         \n",
      "{'loss': 0.7092, 'learning_rate': 1.8688524590163936e-05, 'epoch': 6.56}        \n",
      "{'loss': 0.6967, 'learning_rate': 1.8655737704918033e-05, 'epoch': 6.72}        \n",
      "{'loss': 0.6556, 'learning_rate': 1.862295081967213e-05, 'epoch': 6.89}         \n",
      "  7%|██▊                                     | 427/6100 [05:00<41:14,  2.29it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:24:28,541 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:24:28,541 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:24:28,541 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.74it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.37it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.94it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.52it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6404824256896973, 'eval_accuracy': 0.7795620437956204, 'eval_runtime': 4.5282, 'eval_samples_per_second': 151.273, 'eval_steps_per_second': 2.429, 'epoch': 7.0}\n",
      "  7%|██▊                                     | 427/6100 [05:05<41:14,  2.29it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.52it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:24:33,069 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-427\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:24:33,070 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-427/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:24:33,184 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-427/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:24:33,184 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-427/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:24:33,357 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-244] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6591, 'learning_rate': 1.859016393442623e-05, 'epoch': 7.05}         \n",
      "{'loss': 0.6686, 'learning_rate': 1.855737704918033e-05, 'epoch': 7.21}         \n",
      "{'loss': 0.7083, 'learning_rate': 1.852459016393443e-05, 'epoch': 7.38}         \n",
      "{'loss': 0.6844, 'learning_rate': 1.8491803278688527e-05, 'epoch': 7.54}        \n",
      "{'loss': 0.688, 'learning_rate': 1.8459016393442624e-05, 'epoch': 7.7}          \n",
      "{'loss': 0.6559, 'learning_rate': 1.842622950819672e-05, 'epoch': 7.87}         \n",
      "  8%|███▏                                    | 488/6100 [05:43<40:50,  2.29it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:25:11,523 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:25:11,523 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:25:11,523 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.73it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.30it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.83it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.63it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.46it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.40it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.37it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6714891195297241, 'eval_accuracy': 0.7605839416058394, 'eval_runtime': 4.6237, 'eval_samples_per_second': 148.149, 'eval_steps_per_second': 2.379, 'epoch': 8.0}\n",
      "  8%|███▏                                    | 488/6100 [05:48<40:50,  2.29it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.47it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:25:16,147 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-488\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:25:16,148 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-488/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:25:16,261 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-488/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:25:16,262 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-488/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:25:16,439 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-305] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.7196, 'learning_rate': 1.8393442622950822e-05, 'epoch': 8.03}        \n",
      "{'loss': 0.653, 'learning_rate': 1.836065573770492e-05, 'epoch': 8.2}           \n",
      "{'loss': 0.6219, 'learning_rate': 1.832786885245902e-05, 'epoch': 8.36}         \n",
      "{'loss': 0.6958, 'learning_rate': 1.8295081967213114e-05, 'epoch': 8.52}        \n",
      "{'loss': 0.6806, 'learning_rate': 1.8262295081967215e-05, 'epoch': 8.69}        \n",
      "{'loss': 0.7158, 'learning_rate': 1.8229508196721312e-05, 'epoch': 8.85}        \n",
      "  9%|███▌                                    | 549/6100 [06:27<40:45,  2.27it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:25:55,757 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:25:55,757 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:25:55,757 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.57it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.49it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6488457322120667, 'eval_accuracy': 0.7781021897810219, 'eval_runtime': 4.5234, 'eval_samples_per_second': 151.433, 'eval_steps_per_second': 2.432, 'epoch': 9.0}\n",
      "  9%|███▌                                    | 549/6100 [06:32<40:45,  2.27it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:26:00,280 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-549\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:26:00,281 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-549/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:26:00,389 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-549/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:26:00,390 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-549/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:26:00,562 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-366] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6848, 'learning_rate': 1.8196721311475413e-05, 'epoch': 9.02}        \n",
      "{'loss': 0.6652, 'learning_rate': 1.816393442622951e-05, 'epoch': 9.18}         \n",
      "{'loss': 0.6359, 'learning_rate': 1.8131147540983608e-05, 'epoch': 9.34}        \n",
      "{'loss': 0.66, 'learning_rate': 1.8098360655737705e-05, 'epoch': 9.51}          \n",
      "{'loss': 0.6418, 'learning_rate': 1.8065573770491806e-05, 'epoch': 9.67}        \n",
      "{'loss': 0.6404, 'learning_rate': 1.8032786885245903e-05, 'epoch': 9.84}        \n",
      "{'loss': 0.688, 'learning_rate': 1.8e-05, 'epoch': 10.0}                        \n",
      " 10%|████                                    | 610/6100 [07:09<40:08,  2.28it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:26:37,266 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:26:37,266 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:26:37,266 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.68it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.16it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.48it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.13it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.00it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.89it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.83it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  1.94it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6395093202590942, 'eval_accuracy': 0.7781021897810219, 'eval_runtime': 5.5501, 'eval_samples_per_second': 123.422, 'eval_steps_per_second': 1.982, 'epoch': 10.0}\n",
      " 10%|████                                    | 610/6100 [07:14<40:08,  2.28it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:26:42,817 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-610\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:26:42,818 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-610/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:26:42,975 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-610/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:26:42,975 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-610/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:26:43,219 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-427] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6669, 'learning_rate': 1.79672131147541e-05, 'epoch': 10.16}         \n",
      "{'loss': 0.6337, 'learning_rate': 1.79344262295082e-05, 'epoch': 10.33}         \n",
      "{'loss': 0.6478, 'learning_rate': 1.7901639344262296e-05, 'epoch': 10.49}       \n",
      "{'loss': 0.6493, 'learning_rate': 1.7868852459016393e-05, 'epoch': 10.66}       \n",
      "{'loss': 0.6872, 'learning_rate': 1.7836065573770494e-05, 'epoch': 10.82}       \n",
      "{'loss': 0.6316, 'learning_rate': 1.780327868852459e-05, 'epoch': 10.98}        \n",
      " 11%|████▍                                   | 671/6100 [07:52<48:39,  1.86it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:27:20,807 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:27:20,807 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:27:20,807 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.47it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.71it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6398679614067078, 'eval_accuracy': 0.7781021897810219, 'eval_runtime': 6.2124, 'eval_samples_per_second': 110.263, 'eval_steps_per_second': 1.771, 'epoch': 11.0}\n",
      " 11%|████▍                                   | 671/6100 [07:59<48:39,  1.86it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:27:27,020 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-671\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:27:27,021 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-671/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:27:27,181 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-671/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:27:27,181 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-671/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:27:27,426 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-488] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6081, 'learning_rate': 1.7770491803278692e-05, 'epoch': 11.15}       \n",
      "{'loss': 0.6615, 'learning_rate': 1.7737704918032786e-05, 'epoch': 11.31}       \n",
      "{'loss': 0.5975, 'learning_rate': 1.7704918032786887e-05, 'epoch': 11.48}       \n",
      "{'loss': 0.6463, 'learning_rate': 1.7672131147540984e-05, 'epoch': 11.64}       \n",
      "{'loss': 0.6255, 'learning_rate': 1.7639344262295085e-05, 'epoch': 11.8}        \n",
      "{'loss': 0.6031, 'learning_rate': 1.7606557377049182e-05, 'epoch': 11.97}       \n",
      " 12%|████▊                                   | 732/6100 [08:37<47:25,  1.89it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:28:04,942 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:28:04,942 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:28:04,942 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.48it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.48it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.18it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.83it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.92it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6398983001708984, 'eval_accuracy': 0.7649635036496351, 'eval_runtime': 6.0883, 'eval_samples_per_second': 112.512, 'eval_steps_per_second': 1.807, 'epoch': 12.0}\n",
      " 12%|████▊                                   | 732/6100 [08:43<47:25,  1.89it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:28:11,031 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-732\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:28:11,032 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-732/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:28:11,188 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-732/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:28:11,189 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-732/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:28:11,432 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-549] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6231, 'learning_rate': 1.757377049180328e-05, 'epoch': 12.13}        \n",
      "{'loss': 0.6418, 'learning_rate': 1.7540983606557377e-05, 'epoch': 12.3}        \n",
      "{'loss': 0.6267, 'learning_rate': 1.7508196721311478e-05, 'epoch': 12.46}       \n",
      "{'loss': 0.6338, 'learning_rate': 1.7475409836065575e-05, 'epoch': 12.62}       \n",
      "{'loss': 0.6126, 'learning_rate': 1.7442622950819676e-05, 'epoch': 12.79}       \n",
      "{'loss': 0.7426, 'learning_rate': 1.740983606557377e-05, 'epoch': 12.95}        \n",
      " 13%|█████▏                                  | 793/6100 [09:21<47:05,  1.88it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:28:49,352 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:28:49,352 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:28:49,352 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.32it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.01it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6572670936584473, 'eval_accuracy': 0.7751824817518248, 'eval_runtime': 6.1683, 'eval_samples_per_second': 111.052, 'eval_steps_per_second': 1.783, 'epoch': 13.0}\n",
      " 13%|█████▏                                  | 793/6100 [09:27<47:05,  1.88it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.45it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:28:55,521 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-793\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:28:55,522 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-793/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:28:55,680 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-793/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:28:55,680 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-793/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:28:55,928 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-671] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5928, 'learning_rate': 1.737704918032787e-05, 'epoch': 13.11}        \n",
      "{'loss': 0.7128, 'learning_rate': 1.7344262295081968e-05, 'epoch': 13.28}       \n",
      "{'loss': 0.6369, 'learning_rate': 1.731147540983607e-05, 'epoch': 13.44}        \n",
      "{'loss': 0.6131, 'learning_rate': 1.7278688524590166e-05, 'epoch': 13.61}       \n",
      "{'loss': 0.6227, 'learning_rate': 1.7245901639344263e-05, 'epoch': 13.77}       \n",
      "{'loss': 0.6705, 'learning_rate': 1.721311475409836e-05, 'epoch': 13.93}        \n",
      " 14%|█████▌                                  | 854/6100 [10:05<46:50,  1.87it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:29:33,627 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:29:33,627 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:29:33,627 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.38it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.15it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.97it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.88it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6648292541503906, 'eval_accuracy': 0.7649635036496351, 'eval_runtime': 6.2086, 'eval_samples_per_second': 110.332, 'eval_steps_per_second': 1.772, 'epoch': 14.0}\n",
      " 14%|█████▌                                  | 854/6100 [10:11<46:50,  1.87it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:29:39,836 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-854\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:29:39,839 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-854/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:29:39,995 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-854/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:29:39,996 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-854/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:29:40,187 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-732] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.646, 'learning_rate': 1.718032786885246e-05, 'epoch': 14.1}          \n",
      "{'loss': 0.5337, 'learning_rate': 1.714754098360656e-05, 'epoch': 14.26}        \n",
      "{'loss': 0.6069, 'learning_rate': 1.711475409836066e-05, 'epoch': 14.43}        \n",
      "{'loss': 0.6428, 'learning_rate': 1.7081967213114757e-05, 'epoch': 14.59}       \n",
      "{'loss': 0.643, 'learning_rate': 1.7049180327868854e-05, 'epoch': 14.75}        \n",
      "{'loss': 0.6557, 'learning_rate': 1.701639344262295e-05, 'epoch': 14.92}        \n",
      " 15%|██████                                  | 915/6100 [10:50<47:14,  1.83it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:30:17,888 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:30:17,888 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:30:17,888 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.52it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.11it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.86it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.79it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.76it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6668922901153564, 'eval_accuracy': 0.7693430656934307, 'eval_runtime': 6.1996, 'eval_samples_per_second': 110.491, 'eval_steps_per_second': 1.774, 'epoch': 15.0}\n",
      " 15%|██████                                  | 915/6100 [10:56<47:14,  1.83it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:30:24,088 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-915\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:30:24,089 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-915/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:30:24,247 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-915/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:30:24,247 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-915/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:30:24,484 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-793] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6388, 'learning_rate': 1.6983606557377052e-05, 'epoch': 15.08}       \n",
      "{'loss': 0.646, 'learning_rate': 1.695081967213115e-05, 'epoch': 15.25}         \n",
      "{'loss': 0.6503, 'learning_rate': 1.6918032786885247e-05, 'epoch': 15.41}       \n",
      "{'loss': 0.6143, 'learning_rate': 1.6885245901639347e-05, 'epoch': 15.57}       \n",
      "{'loss': 0.6055, 'learning_rate': 1.6852459016393445e-05, 'epoch': 15.74}       \n",
      "{'loss': 0.598, 'learning_rate': 1.6819672131147542e-05, 'epoch': 15.9}         \n",
      " 16%|██████▍                                 | 976/6100 [11:34<46:00,  1.86it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:31:02,150 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:31:02,150 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:31:02,150 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.56it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.21it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:02,  2.00it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.93it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.95it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.07it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.16it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.35it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6521661877632141, 'eval_accuracy': 0.7824817518248175, 'eval_runtime': 5.5502, 'eval_samples_per_second': 123.418, 'eval_steps_per_second': 1.982, 'epoch': 16.0}\n",
      " 16%|██████▍                                 | 976/6100 [11:39<46:00,  1.86it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  3.06it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:31:07,701 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-976\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:31:07,701 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-976/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:31:07,808 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-976/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:31:07,809 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-976/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:31:07,978 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-854] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6194, 'learning_rate': 1.678688524590164e-05, 'epoch': 16.07}        \n",
      "{'loss': 0.5843, 'learning_rate': 1.675409836065574e-05, 'epoch': 16.23}        \n",
      "{'loss': 0.5946, 'learning_rate': 1.6721311475409837e-05, 'epoch': 16.39}       \n",
      "{'loss': 0.5867, 'learning_rate': 1.6688524590163935e-05, 'epoch': 16.56}       \n",
      "{'loss': 0.6506, 'learning_rate': 1.6655737704918032e-05, 'epoch': 16.72}       \n",
      "{'loss': 0.6357, 'learning_rate': 1.6622950819672133e-05, 'epoch': 16.89}       \n",
      " 17%|██████▋                                | 1037/6100 [12:16<37:05,  2.28it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:31:44,697 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:31:44,697 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:31:44,697 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.81it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.25it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.86it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.72it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.62it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.43it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6542856693267822, 'eval_accuracy': 0.7751824817518248, 'eval_runtime': 4.4908, 'eval_samples_per_second': 152.535, 'eval_steps_per_second': 2.449, 'epoch': 17.0}\n",
      " 17%|██████▋                                | 1037/6100 [12:21<37:05,  2.28it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.55it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:31:49,188 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1037\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:31:49,189 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1037/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:31:49,298 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1037/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:31:49,298 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1037/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:31:49,472 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-915] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5633, 'learning_rate': 1.659016393442623e-05, 'epoch': 17.05}        \n",
      "{'loss': 0.5496, 'learning_rate': 1.655737704918033e-05, 'epoch': 17.21}        \n",
      "{'loss': 0.6308, 'learning_rate': 1.6524590163934428e-05, 'epoch': 17.38}       \n",
      "{'loss': 0.6223, 'learning_rate': 1.6491803278688526e-05, 'epoch': 17.54}       \n",
      "{'loss': 0.6199, 'learning_rate': 1.6459016393442623e-05, 'epoch': 17.7}        \n",
      "{'loss': 0.5827, 'learning_rate': 1.6426229508196724e-05, 'epoch': 17.87}       \n",
      " 18%|███████                                | 1098/6100 [13:01<37:45,  2.21it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:32:29,043 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:32:29,043 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:32:29,043 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.73it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.31it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.84it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.46it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.627119779586792, 'eval_accuracy': 0.7766423357664234, 'eval_runtime': 4.4618, 'eval_samples_per_second': 153.526, 'eval_steps_per_second': 2.465, 'epoch': 18.0}\n",
      " 18%|███████                                | 1098/6100 [13:05<37:45,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.62it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:32:33,505 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1098\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:32:33,505 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1098/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:32:33,616 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1098/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:32:33,616 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1098/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:32:33,791 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-610] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.628, 'learning_rate': 1.639344262295082e-05, 'epoch': 18.03}         \n",
      "{'loss': 0.5627, 'learning_rate': 1.6360655737704922e-05, 'epoch': 18.2}        \n",
      "{'loss': 0.6306, 'learning_rate': 1.6327868852459016e-05, 'epoch': 18.36}       \n",
      "{'loss': 0.5544, 'learning_rate': 1.6295081967213116e-05, 'epoch': 18.52}       \n",
      "{'loss': 0.6392, 'learning_rate': 1.6262295081967214e-05, 'epoch': 18.69}       \n",
      "{'loss': 0.5834, 'learning_rate': 1.6229508196721314e-05, 'epoch': 18.85}       \n",
      " 19%|███████▍                               | 1159/6100 [13:43<36:31,  2.25it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:33:11,162 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:33:11,162 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:33:11,162 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.60it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.27it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.92it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.69it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.55it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.45it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6350620985031128, 'eval_accuracy': 0.781021897810219, 'eval_runtime': 4.5668, 'eval_samples_per_second': 149.996, 'eval_steps_per_second': 2.409, 'epoch': 19.0}\n",
      " 19%|███████▍                               | 1159/6100 [13:47<36:31,  2.25it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:33:15,729 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1159\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:33:15,730 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1159/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:33:15,843 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1159/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:33:15,844 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1159/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2887] 2023-10-05 13:33:16,027 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-976] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5892, 'learning_rate': 1.6196721311475412e-05, 'epoch': 19.02}       \n",
      "{'loss': 0.5629, 'learning_rate': 1.616393442622951e-05, 'epoch': 19.18}        \n",
      "{'loss': 0.5566, 'learning_rate': 1.6131147540983607e-05, 'epoch': 19.34}       \n",
      "{'loss': 0.5827, 'learning_rate': 1.6098360655737707e-05, 'epoch': 19.51}       \n",
      "{'loss': 0.5997, 'learning_rate': 1.6065573770491805e-05, 'epoch': 19.67}       \n",
      "{'loss': 0.5672, 'learning_rate': 1.6032786885245902e-05, 'epoch': 19.84}       \n",
      "{'loss': 0.6595, 'learning_rate': 1.6000000000000003e-05, 'epoch': 20.0}        \n",
      " 20%|███████▊                               | 1220/6100 [14:25<35:48,  2.27it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:33:53,091 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:33:53,091 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:33:53,091 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.27it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.10it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.75it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.60it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.53it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.16it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.00it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:04<00:00,  2.08it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6292120218276978, 'eval_accuracy': 0.7766423357664234, 'eval_runtime': 5.0332, 'eval_samples_per_second': 136.096, 'eval_steps_per_second': 2.185, 'epoch': 20.0}\n",
      " 20%|███████▊                               | 1220/6100 [14:30<35:48,  2.27it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.73it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:33:58,125 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1220\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:33:58,126 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1220/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:33:58,282 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1220/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:33:58,283 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1220/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:33:58,522 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1037] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5561, 'learning_rate': 1.59672131147541e-05, 'epoch': 20.16}         \n",
      "{'loss': 0.5756, 'learning_rate': 1.5934426229508197e-05, 'epoch': 20.33}       \n",
      "{'loss': 0.6184, 'learning_rate': 1.5901639344262295e-05, 'epoch': 20.49}       \n",
      "{'loss': 0.5153, 'learning_rate': 1.5868852459016395e-05, 'epoch': 20.66}       \n",
      "{'loss': 0.6618, 'learning_rate': 1.5836065573770493e-05, 'epoch': 20.82}       \n",
      "{'loss': 0.6201, 'learning_rate': 1.580327868852459e-05, 'epoch': 20.98}        \n",
      " 21%|████████▏                              | 1281/6100 [15:08<36:59,  2.17it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:34:36,082 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:34:36,082 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:34:36,082 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.49it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.47it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.13it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.94it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.89it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.78it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6284821033477783, 'eval_accuracy': 0.7824817518248175, 'eval_runtime': 6.1484, 'eval_samples_per_second': 111.411, 'eval_steps_per_second': 1.789, 'epoch': 21.0}\n",
      " 21%|████████▏                              | 1281/6100 [15:14<36:59,  2.17it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:34:42,231 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1281\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:34:42,232 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1281/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:34:42,389 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1281/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:34:42,390 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1281/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:34:42,630 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1159] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.557, 'learning_rate': 1.5770491803278687e-05, 'epoch': 21.15}        \n",
      "{'loss': 0.5869, 'learning_rate': 1.5737704918032788e-05, 'epoch': 21.31}       \n",
      "{'loss': 0.6196, 'learning_rate': 1.5704918032786886e-05, 'epoch': 21.48}       \n",
      "{'loss': 0.5448, 'learning_rate': 1.5672131147540986e-05, 'epoch': 21.64}       \n",
      "{'loss': 0.566, 'learning_rate': 1.5639344262295084e-05, 'epoch': 21.8}         \n",
      "{'loss': 0.6317, 'learning_rate': 1.560655737704918e-05, 'epoch': 21.97}        \n",
      " 22%|████████▌                              | 1342/6100 [15:52<42:52,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:35:20,310 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:35:20,310 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:35:20,310 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.45it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.44it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.06it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.98it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.85it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.81it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6375440359115601, 'eval_accuracy': 0.7751824817518248, 'eval_runtime': 6.1247, 'eval_samples_per_second': 111.842, 'eval_steps_per_second': 1.796, 'epoch': 22.0}\n",
      " 22%|████████▌                              | 1342/6100 [15:58<42:52,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.92it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:35:26,435 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1342\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:35:26,437 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1342/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:35:26,602 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1342/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:35:26,603 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1342/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:35:26,910 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1220] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.534, 'learning_rate': 1.5573770491803278e-05, 'epoch': 22.13}        \n",
      "{'loss': 0.5483, 'learning_rate': 1.554098360655738e-05, 'epoch': 22.3}         \n",
      "{'loss': 0.5507, 'learning_rate': 1.5508196721311476e-05, 'epoch': 22.46}       \n",
      "{'loss': 0.5541, 'learning_rate': 1.5475409836065577e-05, 'epoch': 22.62}       \n",
      "{'loss': 0.5716, 'learning_rate': 1.544262295081967e-05, 'epoch': 22.79}        \n",
      "{'loss': 0.5482, 'learning_rate': 1.5409836065573772e-05, 'epoch': 22.95}       \n",
      " 23%|████████▉                              | 1403/6100 [16:36<41:20,  1.89it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:36:04,245 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:36:04,245 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:36:04,245 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.46it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.40it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.09it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.92it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.85it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.81it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.77it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6331070065498352, 'eval_accuracy': 0.7854014598540145, 'eval_runtime': 6.1612, 'eval_samples_per_second': 111.179, 'eval_steps_per_second': 1.785, 'epoch': 23.0}\n",
      " 23%|████████▉                              | 1403/6100 [16:42<41:20,  1.89it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.53it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:36:10,407 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1403\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:36:10,408 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1403/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:36:10,565 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1403/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:36:10,566 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1403/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:36:10,812 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1281] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.6018, 'learning_rate': 1.537704918032787e-05, 'epoch': 23.11}        \n",
      "{'loss': 0.5509, 'learning_rate': 1.534426229508197e-05, 'epoch': 23.28}        \n",
      "{'loss': 0.5405, 'learning_rate': 1.5311475409836067e-05, 'epoch': 23.44}       \n",
      "{'loss': 0.5214, 'learning_rate': 1.5278688524590165e-05, 'epoch': 23.61}       \n",
      "{'loss': 0.5879, 'learning_rate': 1.5245901639344264e-05, 'epoch': 23.77}       \n",
      "{'loss': 0.5557, 'learning_rate': 1.5213114754098361e-05, 'epoch': 23.93}       \n",
      " 24%|█████████▎                             | 1464/6100 [17:20<40:54,  1.89it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:36:48,303 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:36:48,303 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:36:48,303 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  4.14it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.18it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.76it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.59it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.47it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.47it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.40it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.51it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.632383406162262, 'eval_accuracy': 0.7824817518248175, 'eval_runtime': 4.9098, 'eval_samples_per_second': 139.518, 'eval_steps_per_second': 2.24, 'epoch': 24.0}\n",
      " 24%|█████████▎                             | 1464/6100 [17:25<40:54,  1.89it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.24it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:36:53,213 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1464\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:36:53,213 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1464/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:36:53,312 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1464/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:36:53,312 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1464/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:36:53,486 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1342] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5953, 'learning_rate': 1.518032786885246e-05, 'epoch': 24.1}         \n",
      "{'loss': 0.5652, 'learning_rate': 1.5147540983606559e-05, 'epoch': 24.26}       \n",
      "{'loss': 0.4803, 'learning_rate': 1.5114754098360658e-05, 'epoch': 24.43}       \n",
      "{'loss': 0.5211, 'learning_rate': 1.5081967213114754e-05, 'epoch': 24.59}       \n",
      "{'loss': 0.521, 'learning_rate': 1.5049180327868853e-05, 'epoch': 24.75}        \n",
      "{'loss': 0.5356, 'learning_rate': 1.5016393442622952e-05, 'epoch': 24.92}       \n",
      " 25%|█████████▊                             | 1525/6100 [18:03<34:42,  2.20it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:37:31,334 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:37:31,334 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:37:31,334 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.28it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.80it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.57it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.48it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.38it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6504279375076294, 'eval_accuracy': 0.7693430656934307, 'eval_runtime': 4.5602, 'eval_samples_per_second': 150.211, 'eval_steps_per_second': 2.412, 'epoch': 25.0}\n",
      " 25%|█████████▊                             | 1525/6100 [18:08<34:42,  2.20it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:37:35,895 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1525\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:37:35,896 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1525/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:37:36,007 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1525/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:37:36,007 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1525/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:37:36,183 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1403] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5413, 'learning_rate': 1.498360655737705e-05, 'epoch': 25.08}        \n",
      "{'loss': 0.5453, 'learning_rate': 1.495081967213115e-05, 'epoch': 25.25}        \n",
      "{'loss': 0.4447, 'learning_rate': 1.4918032786885249e-05, 'epoch': 25.41}       \n",
      "{'loss': 0.5529, 'learning_rate': 1.4885245901639344e-05, 'epoch': 25.57}       \n",
      "{'loss': 0.541, 'learning_rate': 1.4852459016393443e-05, 'epoch': 25.74}        \n",
      "{'loss': 0.5671, 'learning_rate': 1.4819672131147543e-05, 'epoch': 25.9}        \n",
      " 26%|██████████▏                            | 1586/6100 [18:45<33:02,  2.28it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:38:13,488 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:38:13,488 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:38:13,489 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.71it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.85it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.50it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.44it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.42it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.59it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6753795146942139, 'eval_accuracy': 0.7751824817518248, 'eval_runtime': 4.4941, 'eval_samples_per_second': 152.422, 'eval_steps_per_second': 2.448, 'epoch': 26.0}\n",
      " 26%|██████████▏                            | 1586/6100 [18:50<33:02,  2.28it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.35it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:38:17,983 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1586\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:38:17,983 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1586/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:38:18,087 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1586/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:38:18,088 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1586/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:38:18,277 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1464] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5175, 'learning_rate': 1.4786885245901642e-05, 'epoch': 26.07}       \n",
      "{'loss': 0.519, 'learning_rate': 1.4754098360655739e-05, 'epoch': 26.23}        \n",
      "{'loss': 0.4932, 'learning_rate': 1.4721311475409836e-05, 'epoch': 26.39}       \n",
      "{'loss': 0.5806, 'learning_rate': 1.4688524590163935e-05, 'epoch': 26.56}       \n",
      "{'loss': 0.5231, 'learning_rate': 1.4655737704918034e-05, 'epoch': 26.72}       \n",
      "{'loss': 0.5928, 'learning_rate': 1.4622950819672133e-05, 'epoch': 26.89}       \n",
      " 27%|██████████▌                            | 1647/6100 [19:27<32:33,  2.28it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:38:55,505 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:38:55,505 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:38:55,505 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.78it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.33it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.84it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.65it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  2.45it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.39it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.41it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.42it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:03<00:00,  2.50it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6590442061424255, 'eval_accuracy': 0.7751824817518248, 'eval_runtime': 4.5711, 'eval_samples_per_second': 149.856, 'eval_steps_per_second': 2.406, 'epoch': 27.0}\n",
      " 27%|██████████▌                            | 1647/6100 [19:32<32:33,  2.28it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  3.23it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:39:00,076 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1647\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:39:00,077 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1647/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:39:00,174 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1647/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:39:00,175 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1647/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:39:00,350 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1525] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5273, 'learning_rate': 1.459016393442623e-05, 'epoch': 27.05}        \n",
      "{'loss': 0.4794, 'learning_rate': 1.455737704918033e-05, 'epoch': 27.21}        \n",
      "{'loss': 0.5489, 'learning_rate': 1.4524590163934427e-05, 'epoch': 27.38}       \n",
      "{'loss': 0.5356, 'learning_rate': 1.4491803278688526e-05, 'epoch': 27.54}       \n",
      "{'loss': 0.5008, 'learning_rate': 1.4459016393442623e-05, 'epoch': 27.7}        \n",
      "{'loss': 0.5474, 'learning_rate': 1.4426229508196722e-05, 'epoch': 27.87}       \n",
      " 28%|██████████▉                            | 1708/6100 [20:10<32:40,  2.24it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:39:38,207 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:39:38,207 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:39:38,207 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.62it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.51it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.18it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.91it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.86it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  1.79it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.79it/s]\u001b[A\n",
      " 91%|███████████████████████████████████████    | 10/11 [00:05<00:00,  1.91it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6821499466896057, 'eval_accuracy': 0.7722627737226277, 'eval_runtime': 5.823, 'eval_samples_per_second': 117.637, 'eval_steps_per_second': 1.889, 'epoch': 28.0}\n",
      " 28%|██████████▉                            | 1708/6100 [20:16<32:40,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  2.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:39:44,030 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1708\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:39:44,032 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1708/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:39:44,251 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1708/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:39:44,251 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1708/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:39:44,495 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1586] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5033, 'learning_rate': 1.4393442622950822e-05, 'epoch': 28.03}       \n",
      "{'loss': 0.4871, 'learning_rate': 1.4360655737704919e-05, 'epoch': 28.2}        \n",
      "{'loss': 0.5361, 'learning_rate': 1.4327868852459016e-05, 'epoch': 28.36}       \n",
      "{'loss': 0.506, 'learning_rate': 1.4295081967213115e-05, 'epoch': 28.52}        \n",
      "{'loss': 0.5279, 'learning_rate': 1.4262295081967214e-05, 'epoch': 28.69}       \n",
      "{'loss': 0.5209, 'learning_rate': 1.4229508196721313e-05, 'epoch': 28.85}       \n",
      " 29%|███████████▎                           | 1769/6100 [20:54<38:43,  1.86it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:40:22,099 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:40:22,099 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:40:22,099 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.63it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.47it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.99it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.82it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.75it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.74it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7165423035621643, 'eval_accuracy': 0.7489051094890511, 'eval_runtime': 6.205, 'eval_samples_per_second': 110.394, 'eval_steps_per_second': 1.773, 'epoch': 29.0}\n",
      " 29%|███████████▎                           | 1769/6100 [21:00<38:43,  1.86it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.86it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:40:28,305 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1769\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:40:28,307 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1769/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:40:28,470 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1769/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:40:28,471 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1769/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:40:28,729 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1647] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5224, 'learning_rate': 1.4196721311475412e-05, 'epoch': 29.02}       \n",
      "{'loss': 0.4978, 'learning_rate': 1.4163934426229508e-05, 'epoch': 29.18}       \n",
      "{'loss': 0.5668, 'learning_rate': 1.4131147540983607e-05, 'epoch': 29.34}       \n",
      "{'loss': 0.4677, 'learning_rate': 1.4098360655737706e-05, 'epoch': 29.51}       \n",
      "{'loss': 0.4965, 'learning_rate': 1.4065573770491805e-05, 'epoch': 29.67}       \n",
      "{'loss': 0.5271, 'learning_rate': 1.4032786885245904e-05, 'epoch': 29.84}       \n",
      "{'loss': 0.5258, 'learning_rate': 1.4e-05, 'epoch': 30.0}                       \n",
      " 30%|███████████▋                           | 1830/6100 [21:38<38:17,  1.86it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:41:06,520 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:41:06,520 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:41:06,520 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.57it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.50it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.12it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  1.95it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.90it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.84it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:01,  1.80it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6607863903045654, 'eval_accuracy': 0.781021897810219, 'eval_runtime': 6.1157, 'eval_samples_per_second': 112.006, 'eval_steps_per_second': 1.799, 'epoch': 30.0}\n",
      " 30%|███████████▋                           | 1830/6100 [21:44<38:17,  1.86it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:05<00:00,  1.90it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:41:12,637 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1830\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:41:12,638 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1830/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:41:12,798 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1830/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:41:12,799 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1830/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:41:13,040 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1708] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4978, 'learning_rate': 1.3967213114754099e-05, 'epoch': 30.16}       \n",
      "{'loss': 0.4277, 'learning_rate': 1.3934426229508198e-05, 'epoch': 30.33}       \n",
      "{'loss': 0.5063, 'learning_rate': 1.3901639344262297e-05, 'epoch': 30.49}       \n",
      "{'loss': 0.5153, 'learning_rate': 1.3868852459016396e-05, 'epoch': 30.66}       \n",
      "{'loss': 0.5049, 'learning_rate': 1.3836065573770492e-05, 'epoch': 30.82}       \n",
      "{'loss': 0.5391, 'learning_rate': 1.380327868852459e-05, 'epoch': 30.98}        \n",
      " 31%|████████████                           | 1891/6100 [22:22<37:56,  1.85it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:41:50,666 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:41:50,666 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:41:50,666 >>   Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:02,  3.53it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:01<00:03,  2.45it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:03,  2.14it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:02<00:03,  2.00it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:02,  1.87it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:03<00:02,  1.91it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.00it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:04<00:00,  2.12it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6751394271850586, 'eval_accuracy': 0.7562043795620438, 'eval_runtime': 5.7025, 'eval_samples_per_second': 120.123, 'eval_steps_per_second': 1.929, 'epoch': 31.0}\n",
      " 31%|████████████                           | 1891/6100 [22:28<37:56,  1.85it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:04<00:00,  2.28it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:41:56,368 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1891\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:41:56,369 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1891/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:41:56,467 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1891/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:41:56,468 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1891/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:41:56,641 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1769] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4523, 'learning_rate': 1.377049180327869e-05, 'epoch': 31.15}        \n",
      "{'loss': 0.5117, 'learning_rate': 1.3737704918032789e-05, 'epoch': 31.31}       \n",
      "{'loss': 0.5448, 'learning_rate': 1.3704918032786888e-05, 'epoch': 31.48}       \n",
      "{'loss': 0.4981, 'learning_rate': 1.3672131147540985e-05, 'epoch': 31.64}       \n",
      "{'loss': 0.5122, 'learning_rate': 1.3639344262295082e-05, 'epoch': 31.8}        \n",
      "{'loss': 0.4866, 'learning_rate': 1.3606557377049181e-05, 'epoch': 31.97}       \n",
      " 32%|████████████▍                          | 1952/6100 [23:05<31:03,  2.23it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:42:33,776 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:42:33,776 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:42:33,776 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.64it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.41it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.82it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.64it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.43it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:03<00:01,  2.39it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6556232571601868, 'eval_accuracy': 0.7781021897810219, 'eval_runtime': 4.5818, 'eval_samples_per_second': 149.504, 'eval_steps_per_second': 2.401, 'epoch': 32.0}\n",
      " 32%|████████████▍                          | 1952/6100 [23:10<31:03,  2.23it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.49it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:42:38,358 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1952\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:42:38,359 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1952/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:42:38,471 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1952/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:42:38,471 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1952/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:42:38,647 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1830] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.5016, 'learning_rate': 1.357377049180328e-05, 'epoch': 32.13}        \n",
      "{'loss': 0.4737, 'learning_rate': 1.3540983606557378e-05, 'epoch': 32.3}        \n",
      "{'loss': 0.4408, 'learning_rate': 1.3508196721311477e-05, 'epoch': 32.46}       \n",
      "{'loss': 0.5579, 'learning_rate': 1.3475409836065574e-05, 'epoch': 32.62}       \n",
      "{'loss': 0.4952, 'learning_rate': 1.3442622950819673e-05, 'epoch': 32.79}       \n",
      "{'loss': 0.4976, 'learning_rate': 1.340983606557377e-05, 'epoch': 32.95}        \n",
      " 33%|████████████▊                          | 2013/6100 [23:49<30:06,  2.26it/s]/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-10-05 13:43:17,112 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-10-05 13:43:17,112 >>   Num examples = 685\n",
      "[INFO|trainer.py:3079] 2023-10-05 13:43:17,112 >>   Batch size = 64\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|████████                                    | 2/11 [00:00<00:01,  4.82it/s]\u001b[A\n",
      " 27%|████████████                                | 3/11 [00:00<00:02,  3.36it/s]\u001b[A\n",
      " 36%|████████████████                            | 4/11 [00:01<00:02,  2.89it/s]\u001b[A\n",
      " 45%|████████████████████                        | 5/11 [00:01<00:02,  2.71it/s]\u001b[A\n",
      " 55%|████████████████████████                    | 6/11 [00:02<00:01,  2.58it/s]\u001b[A\n",
      " 64%|████████████████████████████                | 7/11 [00:02<00:01,  2.56it/s]\u001b[A\n",
      " 73%|████████████████████████████████            | 8/11 [00:02<00:01,  2.54it/s]\u001b[A\n",
      " 82%|████████████████████████████████████        | 9/11 [00:03<00:00,  2.48it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6649376749992371, 'eval_accuracy': 0.7503649635036497, 'eval_runtime': 4.4634, 'eval_samples_per_second': 153.471, 'eval_steps_per_second': 2.464, 'epoch': 33.0}\n",
      " 33%|████████████▊                          | 2013/6100 [23:53<30:06,  2.26it/s]\n",
      "100%|███████████████████████████████████████████| 11/11 [00:03<00:00,  2.56it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2800] 2023-10-05 13:43:21,576 >> Saving model checkpoint to outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-2013\n",
      "[INFO|configuration_utils.py:458] 2023-10-05 13:43:21,576 >> Configuration saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-2013/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:1845] 2023-10-05 13:43:21,698 >> Model weights saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-2013/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-10-05 13:43:21,699 >> Image processor saved in outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-2013/preprocessor_config.json\n",
      "[INFO|trainer.py:2887] 2023-10-05 13:43:21,882 >> Deleting older checkpoint [outputs_all/swin_combine_pseudo_30%_Fold_8/checkpoint-1891] due to args.save_total_limit\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "{'loss': 0.4785, 'learning_rate': 1.337704918032787e-05, 'epoch': 33.11}        \n",
      " 33%|████████████▉                          | 2025/6100 [24:01<40:34,  1.67it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'microsoft/swin-tiny-patch4-window7-224'\n",
    "#model_name = 'facebook/convnextv2-tiny-1k-224'\n",
    "#dataset_dir = 'cross_val_test/50%_CV/50%_Fold_'\n",
    "output_dir = 'outputs_all/swin_combine_pseudo_30%_Fold_'\n",
    "for fold_number in range(5,10):\n",
    "    fold_count = str(fold_number%10)\n",
    "    dataset_fold = 'cross_val_test/30%_CV/30%_Fold_'+fold_count+'/combine_pseudo_labeled'\n",
    "    output_fold = output_dir+fold_count\n",
    "    !python run_image_classification.py \\\n",
    "    --dataset_name {dataset_fold} \\\n",
    "    --model_name_or_path {model_name} \\\n",
    "    --output_dir {output_fold} \\\n",
    "    --remove_unused_columns False \\\n",
    "    --do_train \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_train_epochs 100 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --logging_strategy steps \\\n",
    "    --logging_steps 10 \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    --save_strategy epoch \\\n",
    "    --load_best_model_at_end True \\\n",
    "    --save_total_limit 3 \\\n",
    "    --ignore_mismatched_sizes True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142baf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/05/2023 19:45:51 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2distributed training: True, 16-bits training: False\n",
      "08/05/2023 19:45:51 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=2,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=outputs_all/conv_output_50%_Fold_9/runs/Aug05_19-45-49_thanawit-Z690-Pro-RS,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=100.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=outputs_all/conv_output_50%_Fold_9,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=outputs_all/conv_output_50%_Fold_9,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=3,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "08/05/2023 19:45:51 - INFO - __main__ - Checkpoint detected, resuming training at outputs_all/conv_output_50%_Fold_9/checkpoint-4300. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n",
      "Resolving data files: 100%|██████████████| 3167/3167 [00:00<00:00, 18140.13it/s]\n",
      "Resolving data files: 100%|███████████████| 632/632 [00:00<00:00, 449440.51it/s]\n",
      "08/05/2023 19:45:52 - WARNING - datasets.builder - Found cached dataset imagefolder (/home/thanawit/.cache/huggingface/datasets/imagefolder/50%_Fold_9-3098a88e15d5faaa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 108.40it/s]\n",
      "08/05/2023 19:45:52 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/50%_Fold_9-3098a88e15d5faaa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-b90735eda001e9a5.arrow\n",
      "08/05/2023 19:45:52 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/50%_Fold_9-3098a88e15d5faaa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-b31a91c35ee5bed1.arrow\n",
      "08/05/2023 19:45:52 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /home/thanawit/.cache/huggingface/datasets/imagefolder/50%_Fold_9-3098a88e15d5faaa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-2340e2efe7bc4c95.arrow and /home/thanawit/.cache/huggingface/datasets/imagefolder/50%_Fold_9-3098a88e15d5faaa/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-687bcca93434e74a.arrow\n",
      "[INFO|configuration_utils.py:669] 2023-08-05 19:45:54,199 >> loading configuration file config.json from cache at /home/thanawit/.cache/huggingface/hub/models--facebook--convnextv2-tiny-1k-224/snapshots/f1e3c2b67baac62241e55095c41b5df13820c0a6/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-08-05 19:45:54,202 >> Model config ConvNextV2Config {\n",
      "  \"_name_or_path\": \"facebook/convnextv2-tiny-1k-224\",\n",
      "  \"architectures\": [\n",
      "    \"ConvNextV2ForImageClassification\"\n",
      "  ],\n",
      "  \"depths\": [\n",
      "    3,\n",
      "    3,\n",
      "    9,\n",
      "    3\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.0,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_sizes\": [\n",
      "    96,\n",
      "    192,\n",
      "    384,\n",
      "    768\n",
      "  ],\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Atypical\",\n",
      "    \"1\": \"Indeterminate\",\n",
      "    \"2\": \"Negative\",\n",
      "    \"3\": \"Typical\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"Atypical\": \"0\",\n",
      "    \"Indeterminate\": \"1\",\n",
      "    \"Negative\": \"2\",\n",
      "    \"Typical\": \"3\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"convnextv2\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_stages\": 4,\n",
      "  \"out_features\": [\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"out_indices\": [\n",
      "    4\n",
      "  ],\n",
      "  \"patch_size\": 4,\n",
      "  \"stage_names\": [\n",
      "    \"stem\",\n",
      "    \"stage1\",\n",
      "    \"stage2\",\n",
      "    \"stage3\",\n",
      "    \"stage4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2575] 2023-08-05 19:45:54,207 >> loading weights file pytorch_model.bin from cache at /home/thanawit/.cache/huggingface/hub/models--facebook--convnextv2-tiny-1k-224/snapshots/f1e3c2b67baac62241e55095c41b5df13820c0a6/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:3283] 2023-08-05 19:45:54,555 >> All model checkpoint weights were used when initializing ConvNextV2ForImageClassification.\n",
      "\n",
      "[WARNING|modeling_utils.py:3304] 2023-08-05 19:45:54,555 >> Some weights of ConvNextV2ForImageClassification were not initialized from the model checkpoint at facebook/convnextv2-tiny-1k-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-08-05 19:45:54,734 >> loading configuration file preprocessor_config.json from cache at /home/thanawit/.cache/huggingface/hub/models--facebook--convnextv2-tiny-1k-224/snapshots/f1e3c2b67baac62241e55095c41b5df13820c0a6/preprocessor_config.json\n",
      "[INFO|image_processing_utils.py:359] 2023-08-05 19:45:54,738 >> Image processor ConvNextImageProcessor {\n",
      "  \"crop_pct\": 0.875,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO|trainer.py:1993] 2023-08-05 19:45:56,324 >> Loading model from outputs_all/conv_output_50%_Fold_9/checkpoint-4300.\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:1680] 2023-08-05 19:45:56,958 >> ***** Running training *****\n",
      "[INFO|trainer.py:1681] 2023-08-05 19:45:56,958 >>   Num examples = 2,691\n",
      "[INFO|trainer.py:1682] 2023-08-05 19:45:56,958 >>   Num Epochs = 100\n",
      "[INFO|trainer.py:1683] 2023-08-05 19:45:56,959 >>   Instantaneous batch size per device = 64\n",
      "[INFO|trainer.py:1684] 2023-08-05 19:45:56,959 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1685] 2023-08-05 19:45:56,959 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1686] 2023-08-05 19:45:56,959 >>   Total optimization steps = 4,300\n",
      "[INFO|trainer.py:1687] 2023-08-05 19:45:56,959 >>   Number of trainable parameters = 27,869,572\n",
      "[INFO|trainer.py:1707] 2023-08-05 19:45:56,960 >>   Continuing training from checkpoint, will skip to saved global_step\n",
      "[INFO|trainer.py:1708] 2023-08-05 19:45:56,960 >>   Continuing training from epoch 100\n",
      "[INFO|trainer.py:1709] 2023-08-05 19:45:56,960 >>   Continuing training from global step 4300\n",
      "[INFO|trainer.py:1711] 2023-08-05 19:45:56,960 >>   Will skip the first 100 epochs then the first 0 batches in the first epoch.\n",
      "  0%|                                                  | 0/4300 [00:00<?, ?it/s][INFO|trainer.py:1916] 2023-08-05 19:46:51,272 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2051] 2023-08-05 19:46:51,272 >> Loading best model from outputs_all/conv_output_50%_Fold_9/checkpoint-387 (score: 0.9540157914161682).\n",
      "{'train_runtime': 54.5044, 'train_samples_per_second': 4937.213, 'train_steps_per_second': 78.893, 'train_loss': 0.0, 'epoch': 100.0}\n",
      "  0%|                                                  | 0/4300 [00:54<?, ?it/s]\n",
      "[INFO|trainer.py:2800] 2023-08-05 19:46:51,464 >> Saving model checkpoint to outputs_all/conv_output_50%_Fold_9\n",
      "[INFO|configuration_utils.py:458] 2023-08-05 19:46:51,465 >> Configuration saved in outputs_all/conv_output_50%_Fold_9/config.json\n",
      "[INFO|modeling_utils.py:1845] 2023-08-05 19:46:51,614 >> Model weights saved in outputs_all/conv_output_50%_Fold_9/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:204] 2023-08-05 19:46:51,615 >> Image processor saved in outputs_all/conv_output_50%_Fold_9/preprocessor_config.json\n",
      "***** train metrics *****\n",
      "  epoch                    =      100.0\n",
      "  train_loss               =        0.0\n",
      "  train_runtime            = 0:00:54.50\n",
      "  train_samples_per_second =   4937.213\n",
      "  train_steps_per_second   =     78.893\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:3074] 2023-08-05 19:46:51,626 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3076] 2023-08-05 19:46:51,626 >>   Num examples = 476\n",
      "[INFO|trainer.py:3079] 2023-08-05 19:46:51,626 >>   Batch size = 64\n",
      "/home/thanawit/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:02<00:00,  2.93it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =      100.0\n",
      "  eval_accuracy           =     0.6071\n",
      "  eval_loss               =      0.954\n",
      "  eval_runtime            = 0:00:06.82\n",
      "  eval_samples_per_second =     69.767\n",
      "  eval_steps_per_second   =      1.173\n"
     ]
    }
   ],
   "source": [
    "model_name = 'microsoft/swin-tiny-patch4-window7-224'\n",
    "dataset_dir = 'cross_val_test/30%_CV/30%_Fold_0/combine_pseudo_labeled'\n",
    "output_dir = 'outputs_all/conv_output_30%_Fold_0_pseudo_labeling_model'\n",
    "\n",
    "!python run_image_classification.py \\\n",
    "    --dataset_name 'cross_val_test/50%_CV/30%_Fold_0/combine_pseudo_labeled' \\\n",
    "    --model_name_or_path 'facebook/convnextv2-tiny-1k-224' \\\n",
    "    --output_dir 'outputs_all/temp_stuff'\\\n",
    "    --remove_unused_columns False \\\n",
    "    --do_train \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_train_epochs 100 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --logging_strategy steps \\\n",
    "    --logging_steps 10 \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    --save_strategy epoch \\\n",
    "    --load_best_model_at_end True \\\n",
    "    --save_total_limit 3 \\\n",
    "    --ignore_mismatched_sizes True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcebe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_image_classification.py \\\n",
    "    --dataset_name 'cross_val_test/50%_CV/50%_Fold_0/combine_pseudo_labeled' \\\n",
    "    --model_name_or_path 'facebook/convnextv2-tiny-1k-224' \\\n",
    "    --output_dir 'outputs_all/combine_pseudo_50%_Fold_0' \\\n",
    "    --remove_unused_columns False \\\n",
    "    --do_train \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --num_train_epochs 100 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --logging_strategy steps \\\n",
    "    --logging_steps 10 \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    --save_strategy epoch \\\n",
    "    --load_best_model_at_end True \\\n",
    "    --save_total_limit 3 \\\n",
    "    --ignore_mismatched_sizes True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
