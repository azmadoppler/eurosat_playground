{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ceba0fc",
   "metadata": {},
   "source": [
    "# Pseudo-labeling Flow\n",
    "---\n",
    "0. Finish Augmentation & Create folder for testing (don't forgot to delete after train)\n",
    "1. Read a file, Augmented Them, Put them in the Run it into the ConvNext Network, Get the Label -> Write it to file\n",
    "2. Do different Augmented Here, \n",
    "\n",
    "\n",
    "\n",
    "99. output -> Save CSV that show -> Original Label, ConvNext Label, Swin Label, True Label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e89f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70287f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weak_augment(image):\n",
    "    transform = A.Compose([\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5), #both\n",
    "        A.RandomGamma(p=0.5), #weak\n",
    "        A.RandomBrightnessContrast(p=0.5), #weak\n",
    "        A.AdvancedBlur(p=0.5), #weak\n",
    "        A.Rotate (limit=10, p=0.5),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    augmented_image = transform(image=np.array(image))['image']\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    return augmented_image\n",
    "    \n",
    "def apply_strong_augment(image):\n",
    "    transform = A.Compose([\n",
    "        A.GridDropout (ratio=0.5, unit_size_min=2, unit_size_max=3, holes_number_x=None, holes_number_y=None, shift_x=0, shift_y=0, random_offset=False, fill_value=0, mask_fill_value=None, always_apply=False, p=0.2),\n",
    "#         A.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=True, p=1), # Heavy Contrast Limited Adaptive Histogram Equalization\n",
    "        A.Affine(), #heavy (shear + rotate)\n",
    "#         A.RandomSunFlare(src_radius=200), #heavy\n",
    "        A.CoarseDropout (max_holes=8, max_height=8, max_width=8, min_holes=None, min_height=None, min_width=None, fill_value=0, mask_fill_value=None, always_apply=False, p=0.5),#heavy\n",
    "        A.RandomCrop(450,450), #80% of image size, probably both\n",
    "#         A.GaussNoise (var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.5),\n",
    "        \n",
    "        A.RandomFog(), # heavy\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    augmented_image = transform(image=np.array(image))['image']\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    return augmented_image\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def display_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image: {e}\")\n",
    "\n",
    "def append_row(df, img_name, conv_results, swin_result):\n",
    "    new_row = {\n",
    "        \"img_name\": img_name,\n",
    "        \"conv_results\": conv_results,\n",
    "        \"swin_result\": swin_result\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    \n",
    "def print_rows_with_same_values(df):\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['conv_results'] == row['swin_results']:\n",
    "            #print(row['img_name'])\n",
    "            counter = counter +1\n",
    "            \n",
    "    return counter\n",
    "\n",
    "def print_rows_with_both_correct_label(df):\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['original_label'] == row['swin_results'] and row['original_label'] == row['conv_results']:\n",
    "            #print(row['img_name'])\n",
    "            counter = counter +1\n",
    "            \n",
    "    return counter\n",
    "            \n",
    "\n",
    "def print_rows_with_correct_label(df):\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['original_label'] == row['swin_results'] or row['original_label'] == row['conv_results']:\n",
    "            #print(row['img_name'])\n",
    "            counter = counter +1\n",
    "            \n",
    "    return counter\n",
    "            \n",
    "def print_rows_with_correct_swin(df):\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['original_label'] == row['swin_results']:\n",
    "            #print(row['img_name'])\n",
    "            counter = counter +1\n",
    "            \n",
    "    return counter\n",
    "\n",
    "def print_rows_with_correct_conv(df):\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['original_label'] == row['conv_results']:\n",
    "            #print(row['img_name'])\n",
    "            counter = counter +1\n",
    "            \n",
    "    return counter\n",
    "    \n",
    "def print_rows_with_correct_ensemble(df):\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if row['conv_results'] == row['original_label'] and row['swin_results'] == row['original_label'] :\n",
    "            #print(row['img_name'])\n",
    "            counter = counter +1\n",
    "            \n",
    "    return counter\n",
    "\n",
    "    \n",
    "def create_pseudo_labeling_folder(df):\n",
    "    correct_label = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['conv_results'] == row['original_label'] and row['conv_results'] == row['original_label'] :\n",
    "            #print(row['img_name'])\n",
    "            counter = counter +1\n",
    "            \n",
    "    return counter\n",
    "\n",
    "\n",
    "def copy_and_move_image(image_path, subfolder_name,destination_path):\n",
    "    try:\n",
    "        # Check if the image_path exists\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Error: Source image '{image_path}' does not exist.\")\n",
    "            return\n",
    "\n",
    "        # Check if the destination directory exists, if not, create it\n",
    "        if not os.path.exists(destination_path):\n",
    "            os.makedirs(destination_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Get the filename from the image_path\n",
    "        filename = os.path.basename(image_path)\n",
    "\n",
    "        # Create the full destination path including the filename\n",
    "        destination_file_path = os.path.join(destination_path,subfolder_name)\n",
    "        if not os.path.exists(destination_file_path):\n",
    "            os.makedirs(destination_file_path)\n",
    "        destination_file_path = os.path.join(destination_file_path, filename)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Copy the image to the destination directory\n",
    "        shutil.copy(image_path, destination_file_path)\n",
    "\n",
    "        #print(f\"Image copied and moved successfully to '{destination_file_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "def combine_folders(source_folders, destination_folder):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Iterate through each source folder\n",
    "    for source_folder in source_folders:\n",
    "        # Traverse through the source folder and its subdirectories to find all files and folders\n",
    "        for root, dirs, files in os.walk(source_folder):\n",
    "            # Create corresponding subdirectories in the destination folder\n",
    "            dest_subfolder = os.path.join(destination_folder, os.path.relpath(root, source_folder))\n",
    "            if not os.path.exists(dest_subfolder):\n",
    "                os.makedirs(dest_subfolder)\n",
    "\n",
    "            # Copy files to the destination folder\n",
    "            for file in files:\n",
    "                src_path = os.path.join(root, file)\n",
    "                dest_path = os.path.join(dest_subfolder, file)\n",
    "                shutil.copy(src_path, dest_path)\n",
    "\n",
    "        \n",
    "def show_augment(image):\n",
    "    transform = A.Compose([\n",
    "        \n",
    "        #rotate\n",
    "        #shear\n",
    "        A.HorizontalFlip(p=0.5), #both\n",
    "        #A.RandomFog(), # weak\n",
    "        #A.RandomGamma(p=0.5), #weak\n",
    "        #A.RandomBrightnessContrast(p=0.5), #weak\n",
    "        #A.AdvancedBlur(p=0.5), #weak\n",
    "        #A.Rotate (limit=10, p=0.5),\n",
    "        \n",
    "        #A.GridDropout (ratio=0.5, unit_size_min=2, unit_size_max=3, holes_number_x=None, holes_number_y=None, shift_x=0, shift_y=0, random_offset=False, fill_value=0, mask_fill_value=None, always_apply=False, p=0.2),\n",
    "        #A.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=True, p=1), # Heavy Contrast Limited Adaptive Histogram Equalization\n",
    "        #A.Affine(), heavy (shear + rotate)\n",
    "        #A.RandomRotate90(p=0.5) #heavy\n",
    "        #A.RandomSunFlare(src_radius=200), #heavy\n",
    "        #A.Cutout (num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, p=0.5),#heavy\n",
    "        #A.RandomCrop(450,450), #80% of image size, probably both\n",
    "        #A.GaussNoise (var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.5),\n",
    "    ])\n",
    "    image = Image.open(image).convert('RGB')\n",
    "    augmented_image = transform(image=np.array(image))['image']\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    augmented_image.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d550f36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thanawit/twin-pseudo\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91e78c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_formats = (\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\")  # Add more supported formats if needed\n",
    "\n",
    "result = pd.DataFrame(columns=[\"img_name\", \"conv_results\", \"swin_results\",\"original_label\"])\n",
    "\n",
    "# 30% Test\n",
    "# imagefolders = \"/home/thanawit/twin-pseudo/cross_val_test/30%_CV/30%_Fold_0/unlabeled\"\n",
    "# #Swin Model\n",
    "# swin_model_path = 'outputs_all/conv_output_30%_Fold_0/checkpoint-2600/'\n",
    "# swin_model = AutoModelForImageClassification.from_pretrained(swin_model_path).to('cuda')\n",
    "# swin_image_processor = AutoImageProcessor.from_pretrained(swin_model_path)\n",
    "\n",
    "# #ConvNext Model\n",
    "# conv_model_path = 'outputs_all/swin_output_30%_Fold_0/checkpoint-2600/'\n",
    "# conv_model = AutoModelForImageClassification.from_pretrained(conv_model_path).to('cuda')\n",
    "# conv_image_processor = AutoImageProcessor.from_pretrained(conv_model_path)\n",
    "\n",
    "\n",
    "\n",
    "# 50% Test \n",
    "imagefolders = \"/home/thanawit/twin-pseudo/cross_val_test/30%_CV/30%_Fold_0/unlabeled\"\n",
    "#imagefolders = \"/home/thanawit/twin-pseudo/datasets/original\"\n",
    "\n",
    "\n",
    "#ConvNext Model // 6\n",
    "conv_model_path = 'outputs_all/conv_output_30%_Fold_6/checkpoint-2600/'\n",
    "conv_model = AutoModelForImageClassification.from_pretrained(conv_model_path).to('cuda')\n",
    "conv_image_processor = AutoImageProcessor.from_pretrained(conv_model_path)\n",
    "\n",
    "\n",
    "\n",
    "#Swin Model //6\n",
    "swin_model_path = 'outputs_all/swin_combine_pseudo_30%_Fold_6/checkpoint-6100/'\n",
    "swin_model = AutoModelForImageClassification.from_pretrained(swin_model_path).to('cuda')\n",
    "swin_image_processor = AutoImageProcessor.from_pretrained(swin_model_path)\n",
    "\n",
    "\n",
    "for root, subfolders, files in os.walk(imagefolders):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(image_formats):\n",
    "            image_path = os.path.join(root, filename)\n",
    "            subfolder_name = os.path.basename(root)\n",
    "\n",
    "            #print(f\"Subfolder Name: {subfolder_name}\")\n",
    "            #print(image_path)\n",
    "            img_strong = apply_weak_augment(image_path)\n",
    "            #img = Image.open(image_path)\n",
    "            \n",
    "            #CONNVEXT PART\n",
    "            \n",
    "            #read model\n",
    "            conv_inputs = conv_image_processor(images=img_strong,return_tensors=\"pt\").to('cuda')\n",
    "            #run img\n",
    "            conv_output = conv_model(**conv_inputs)\n",
    "            conv_logits = conv_output.logits\n",
    "            conv_class = conv_logits.argmax(-1).item()\n",
    "            conv_classname = conv_model.config.id2label[conv_class]\n",
    "            \n",
    "            #SWIN PART\n",
    "            \n",
    "            img_weak = apply_strong_augment(image_path)\n",
    "            \n",
    "            swin_inputs = swin_image_processor(images=img_weak,return_tensors=\"pt\").to('cuda')\n",
    "            \n",
    "            swin_output = swin_model(**swin_inputs)\n",
    "            swin_logits = swin_output.logits\n",
    "            swin_class = swin_logits.argmax(-1).item()\n",
    "            swin_classname = swin_model.config.id2label[swin_class]\n",
    "            #get class\n",
    "            new_row = {\n",
    "                \"img_name\": os.path.basename(image_path),\n",
    "                \"conv_results\": conv_classname,\n",
    "                \"swin_results\": swin_classname,\n",
    "                \"original_label\":subfolder_name\n",
    "            }\n",
    "            \n",
    "            result = pd.concat([result, pd.DataFrame([new_row])],ignore_index=True)\n",
    "            #save \n",
    "            #break\n",
    "            #img.show()\n",
    "            #print(\"=\" * 30)\n",
    "        #print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f78223a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>conv_results</th>\n",
       "      <th>swin_results</th>\n",
       "      <th>original_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73e1bb826f00.png</td>\n",
       "      <td>Typical</td>\n",
       "      <td>Atypical</td>\n",
       "      <td>Atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e393f9122068.png</td>\n",
       "      <td>Indeterminate</td>\n",
       "      <td>Typical</td>\n",
       "      <td>Atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b5916a232a5c.png</td>\n",
       "      <td>Indeterminate</td>\n",
       "      <td>Atypical</td>\n",
       "      <td>Atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8bf7d61dddb4.png</td>\n",
       "      <td>Atypical</td>\n",
       "      <td>Atypical</td>\n",
       "      <td>Atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>093e5e69a2af.png</td>\n",
       "      <td>Atypical</td>\n",
       "      <td>Atypical</td>\n",
       "      <td>Atypical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>01bf68877dab.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>7a4c7eca54a7.png</td>\n",
       "      <td>Typical</td>\n",
       "      <td>Typical</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>055fc441c5e4.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>f00ddc79378d.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>1ea61cb23df6.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3802 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_name   conv_results swin_results original_label\n",
       "0     73e1bb826f00.png        Typical     Atypical       Atypical\n",
       "1     e393f9122068.png  Indeterminate      Typical       Atypical\n",
       "2     b5916a232a5c.png  Indeterminate     Atypical       Atypical\n",
       "3     8bf7d61dddb4.png       Atypical     Atypical       Atypical\n",
       "4     093e5e69a2af.png       Atypical     Atypical       Atypical\n",
       "...                ...            ...          ...            ...\n",
       "3797  01bf68877dab.png       Negative     Negative       Negative\n",
       "3798  7a4c7eca54a7.png        Typical      Typical       Negative\n",
       "3799  055fc441c5e4.png       Negative     Negative       Negative\n",
       "3800  f00ddc79378d.png       Negative     Negative       Negative\n",
       "3801  1ea61cb23df6.png       Negative     Negative       Negative\n",
       "\n",
       "[3802 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80860040",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Record 3802\n",
      "Correct Result from Convnet 2923\n",
      "Correct Result from Swinn 2451\n",
      "Correct Result from Any Correct Label 3232\n",
      "Correct Label From Both Framework 3232\n",
      "Result where both are same  2496\n",
      "Result where both are correct  2142\n"
     ]
    }
   ],
   "source": [
    "#counter = print_rows_with_correct_label(result)\n",
    "print(\"Total Record\",len(result))\n",
    "print(\"Correct Result from Convnet\",print_rows_with_correct_conv(result))\n",
    "print(\"Correct Result from Swinn\",print_rows_with_correct_swin(result))\n",
    "print(\"Correct Result from Any Correct Label\",print_rows_with_correct_label(result))\n",
    "print(\"Correct Label From Both Framework\",print_rows_with_correct_label(result))\n",
    "\n",
    "\n",
    "print(\"Result where both are same \",print_rows_with_same_values(result))\n",
    "print(\"Result where both are correct \",print_rows_with_both_correct_label(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "066e037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "basefolder_name = (os.path.dirname(imagefolders))\n",
    "fold_no = os.path.dirname(os.path.dirname(imagefolders))\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    if row['conv_results'] == row['original_label'] or row['swin_results'] == row['original_label'] :\n",
    "        temp = os.path.join(imagefolders, row['original_label'])\n",
    "        temp2 = os.path.join( temp,row['img_name'] )\n",
    "        copy_and_move_image(temp2,row['original_label'] ,os.path.join(basefolder_name, 'pseudo_labeled'  ))\n",
    "        \n",
    "# combine_folders([os.path.join(basefolder_name,'pseudo_labeled')],\n",
    "#                 os.path.join(basefolder_name,'combine_pseudo_labeled') )\n",
    "\n",
    "\n",
    "train_folder = os.path.join(basefolder_name,'train')\n",
    "pseudo_folder = os.path.join(basefolder_name,'pseudo_labeled')\n",
    "source_folders = []\n",
    "source_folders.append(train_folder)\n",
    "source_folders.append(pseudo_folder)\n",
    "#destination_folder = os.path.join(basefolder_name,'combine_pseudo_labeled')\n",
    "# for the ensemble paper\n",
    "#destination_folder = os.path.join(basefolder_name,'combine_pseudo_labeled')\n",
    "destination_folder = 'cross_val_test/ensemble/30%/ensemble_strong_weak/'                           \n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "#Iterate through each source folder\n",
    "for source_folder in source_folders:\n",
    "    # Traverse through the source folder and its subdirectories to find all files and folders\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        # Create corresponding subdirectories in the destination folder\n",
    "        dest_subfolder = os.path.join(destination_folder, os.path.relpath(root, source_folder))\n",
    "        if not os.path.exists(dest_subfolder):\n",
    "            os.makedirs(dest_subfolder)\n",
    "\n",
    "        # Copy files to the destination folder\n",
    "        for file in files:\n",
    "            src_path = os.path.join(root, file)\n",
    "            dest_path = os.path.join(dest_subfolder, file)\n",
    "            shutil.copy(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3567676b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cross_val_test/ensemble/'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cross_val_test/ensemble/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e36d3452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basefolder_name = os.path.join(os.path.dirname(os.path.dirname(imagefolders)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "69778ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thanawit/twin-pseudo/cross_val_test/30%_CV/30%_Fold_0/pseudo_labeled'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(basefolder_name, 'pseudo_labeled')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ec978",
   "metadata": {},
   "source": [
    "# CV Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9005248f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thanawit/twin-pseudo/cross_val_test/30%_CV'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e80e51c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for fold_counter in range(7,10):\n",
    "    print(fold_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "05576b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs_all/conv_output_30%_Fold_fold_counter/checkpoint-2600/'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18093885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "image_formats = (\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\")  # Add more supported formats if needed\n",
    "\n",
    "for fold_counter in range(6,10):\n",
    "    result = pd.DataFrame(columns=[\"img_name\", \"conv_results\", \"swin_results\",\"original_label\"])\n",
    "\n",
    "    imagefolders = \"/home/thanawit/twin-pseudo/cross_val_test/50%_CV/50%_Fold_\"+ str(fold_counter) +\"/unlabeled\"\n",
    "\n",
    "    #Swin Model\n",
    "\n",
    "    swin_model_path = 'outputs_all/conv_output_50%_Fold_'+ str(fold_counter) +  '/checkpoint-4300/'\n",
    "    swin_model = AutoModelForImageClassification.from_pretrained(swin_model_path).to('cuda')\n",
    "    swin_image_processor = AutoImageProcessor.from_pretrained(swin_model_path)\n",
    "\n",
    "    #ConvNext Model\n",
    "    conv_model_path = 'outputs_all/swin_output_50%_Fold_'+ str(fold_counter) +  '/checkpoint-4300/'\n",
    "    conv_model = AutoModelForImageClassification.from_pretrained(conv_model_path).to('cuda')\n",
    "    conv_image_processor = AutoImageProcessor.from_pretrained(conv_model_path)\n",
    "    \n",
    "    \n",
    "    for root, subfolders, files in os.walk(imagefolders):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith(image_formats):\n",
    "                image_path = os.path.join(root, filename)\n",
    "                subfolder_name = os.path.basename(root)\n",
    "                img_strong = apply_weak_augment(image_path)\n",
    "\n",
    "                #CONNVEXT PART\n",
    "\n",
    "                #read model\n",
    "                conv_inputs = conv_image_processor(images=img_strong,return_tensors=\"pt\").to('cuda')\n",
    "                #run img\n",
    "                conv_output = conv_model(**conv_inputs)\n",
    "                conv_logits = conv_output.logits\n",
    "                conv_class = conv_logits.argmax(-1).item()\n",
    "                conv_classname = conv_model.config.id2label[conv_class]\n",
    "\n",
    "                #SWIN PART\n",
    "\n",
    "                img_weak = apply_weak_augment(image_path)\n",
    "\n",
    "                swin_inputs = swin_image_processor(images=img_weak,return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "                swin_output = swin_model(**swin_inputs)\n",
    "                swin_logits = swin_output.logits\n",
    "                swin_class = swin_logits.argmax(-1).item()\n",
    "                swin_classname = swin_model.config.id2label[swin_class]\n",
    "                #get class\n",
    "                new_row = {\n",
    "                    \"img_name\": os.path.basename(image_path),\n",
    "                    \"conv_results\": conv_classname,\n",
    "                    \"swin_results\": swin_classname,\n",
    "                    \"original_label\":subfolder_name\n",
    "                }\n",
    "\n",
    "                result = pd.concat([result, pd.DataFrame([new_row])],ignore_index=True)\n",
    "    #END FOR\n",
    "    \n",
    "    \n",
    "    basefolder_name = (os.path.dirname(imagefolders))\n",
    "    fold_no = os.path.dirname(os.path.dirname(imagefolders))\n",
    "\n",
    "    for index, row in result.iterrows():\n",
    "        if row['conv_results'] == row['original_label'] or row['swin_results'] == row['original_label'] :\n",
    "            temp = os.path.join(imagefolders, row['original_label'])\n",
    "            temp2 = os.path.join( temp,row['img_name'] )\n",
    "            copy_and_move_image(temp2,row['original_label'] ,os.path.join(basefolder_name, 'pseudo_labeled'  ))\n",
    "\n",
    "    # combine_folders([os.path.join(basefolder_name,'pseudo_labeled')],\n",
    "    #                 os.path.join(basefolder_name,'combine_pseudo_labeled') )\n",
    "\n",
    "\n",
    "    train_folder = os.path.join(basefolder_name,'train')\n",
    "    pseudo_folder = os.path.join(basefolder_name,'pseudo_labeled')\n",
    "    source_folders = []\n",
    "    source_folders.append(train_folder)\n",
    "    source_folders.append(pseudo_folder)\n",
    "    destination_folder = os.path.join(basefolder_name,'combine_pseudo_labeled')\n",
    "\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Iterate through each source folder\n",
    "    for source_folder in source_folders:\n",
    "        # Traverse through the source folder and its subdirectories to find all files and folders\n",
    "        for root, dirs, files in os.walk(source_folder):\n",
    "            # Create corresponding subdirectories in the destination folder\n",
    "            dest_subfolder = os.path.join(destination_folder, os.path.relpath(root, source_folder))\n",
    "            if not os.path.exists(dest_subfolder):\n",
    "                os.makedirs(dest_subfolder)\n",
    "\n",
    "            # Copy files to the destination folder\n",
    "            for file in files:\n",
    "                src_path = os.path.join(root, file)\n",
    "                dest_path = os.path.join(dest_subfolder, file)\n",
    "                shutil.copy(src_path, dest_path)\n",
    "    \n",
    "    print(fold_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f3faf51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thanawit/twin-pseudo/cross_val_test/50%_CV/50%_Fold_9/unlabeled'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagefolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result = pd.DataFrame(columns=[\"img_name\", \"conv_results\", \"swin_results\",\"original_label\"])\n",
    "\n",
    "imagefolders = \"/home/thanawit/twin-pseudo/cross_val_test/30%_CV/30%_Fold_0/unlabeled\"\n",
    "\n",
    "\n",
    "def apply_weak_augment(image):\n",
    "    transform = A.Compose([\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5,always_apply=True), #both\n",
    "#         A.RandomGamma(p=0.5), #weak\n",
    "#         A.RandomBrightnessContrast(p=0.5), #weak\n",
    "#         A.AdvancedBlur(p=0.5), #weak\n",
    "#         A.Rotate (limit=10, p=0.5),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    augmented_image = transform(image=np.array(image))['image']\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    return augmented_image\n",
    "    \n",
    "    \n",
    "    \n",
    "#Swin Model\n",
    "\n",
    "swin_model_path = 'outputs_all/conv_output_30%_Fold_0/checkpoint-2600/'\n",
    "swin_model = AutoModelForImageClassification.from_pretrained(swin_model_path).to('cuda')\n",
    "swin_image_processor = AutoImageProcessor.from_pretrained(swin_model_path)\n",
    "\n",
    "#ConvNext Model\n",
    "conv_model_path = 'outputs_all/conv_output_30%_Fold_0/checkpoint-2600/'\n",
    "conv_model = AutoModelForImageClassification.from_pretrained(conv_model_path).to('cuda')\n",
    "conv_image_processor = AutoImageProcessor.from_pretrained(conv_model_path)\n",
    "\n",
    "\n",
    "for root, subfolders, files in os.walk(imagefolders):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(image_formats):\n",
    "            image_path = os.path.join(root, filename)\n",
    "            subfolder_name = os.path.basename(root)\n",
    "\n",
    "            #print(f\"Subfolder Name: {subfolder_name}\")\n",
    "            #print(image_path)\n",
    "            img_strong = apply_weak_augment(image_path)\n",
    "            #img = Image.open(image_path)\n",
    "            \n",
    "            #CONNVEXT PART\n",
    "            \n",
    "            #read model\n",
    "            conv_inputs = conv_image_processor(images=img_strong,return_tensors=\"pt\").to('cuda')\n",
    "            #run img\n",
    "            conv_output = conv_model(**conv_inputs)\n",
    "            conv_logits = conv_output.logits\n",
    "            conv_class = conv_logits.argmax(-1).item()\n",
    "            conv_classname = conv_model.config.id2label[conv_class]\n",
    "            \n",
    "            #SWIN PART\n",
    "            \n",
    "            img_weak = apply_weak_augment(image_path)\n",
    "            \n",
    "            swin_inputs = swin_image_processor(images=img_weak,return_tensors=\"pt\").to('cuda')\n",
    "            \n",
    "            swin_output = swin_model(**swin_inputs)\n",
    "            swin_logits = swin_output.logits\n",
    "            swin_class = swin_logits.argmax(-1).item()\n",
    "            swin_classname = swin_model.config.id2label[swin_class]\n",
    "            #get class\n",
    "            new_row = {\n",
    "                \"img_name\": os.path.basename(image_path),\n",
    "                \"conv_results\": conv_classname,\n",
    "                \"swin_results\": swin_classname,\n",
    "                \"original_label\":subfolder_name\n",
    "            }\n",
    "            \n",
    "            result = pd.concat([result, pd.DataFrame([new_row])],ignore_index=True)\n",
    "            #save \n",
    "            #break\n",
    "            #img.show()\n",
    "            #print(\"=\" * 30)\n",
    "        #print(filename)\n",
    "        \n",
    "basefolder_name = (os.path.dirname(imagefolders))\n",
    "fold_no = os.path.dirname(os.path.dirname(imagefolders))\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    if row['conv_results'] == row['original_label'] or row['swin_results'] == row['original_label'] :\n",
    "        temp = os.path.join(imagefolders, row['original_label'])\n",
    "        temp2 = os.path.join( temp,row['img_name'] )\n",
    "        copy_and_move_image(temp2,row['original_label'] ,os.path.join(basefolder_name, 'pseudo_labeled'  ))\n",
    "        \n",
    "# combine_folders([os.path.join(basefolder_name,'pseudo_labeled')],\n",
    "#                 os.path.join(basefolder_name,'combine_pseudo_labeled') )\n",
    "\n",
    "\n",
    "train_folder = os.path.join(basefolder_name,'train')\n",
    "pseudo_folder = os.path.join(basefolder_name,'pseudo_labeled')\n",
    "source_folders = []\n",
    "source_folders.append(train_folder)\n",
    "source_folders.append(pseudo_folder)\n",
    "destination_folder = os.path.join(basefolder_name,'combine_pseudo_labeled')\n",
    "                            \n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# Iterate through each source folder\n",
    "for source_folder in source_folders:\n",
    "    # Traverse through the source folder and its subdirectories to find all files and folders\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        # Create corresponding subdirectories in the destination folder\n",
    "        dest_subfolder = os.path.join(destination_folder, os.path.relpath(root, source_folder))\n",
    "        if not os.path.exists(dest_subfolder):\n",
    "            os.makedirs(dest_subfolder)\n",
    "\n",
    "        # Copy files to the destination folder\n",
    "        for file in files:\n",
    "            src_path = os.path.join(root, file)\n",
    "            dest_path = os.path.join(dest_subfolder, file)\n",
    "            shutil.copy(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda39a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c9f8c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff4a571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weak_augment(image):\n",
    "    transform = A.Compose([\n",
    "        A.Affine (scale=None, translate_percent=None, translate_px=None, rotate=None, shear=10, interpolation=1, mask_interpolation=0, cval=0, cval_mask=0, mode=0, fit_output=False, keep_ratio=False, rotate_method='largest_box', always_apply=False),\n",
    "        A.RandomGamma(always_apply=True,p=1), #both\n",
    "        A.RandomGamma(p=0.5), #weak\n",
    "        A.RandomBrightnessContrast(p=0.5), #weak\n",
    "        A.AdvancedBlur(p=0.5), #weak RandomRotate90\n",
    "        A.Rotate (limit=10, p=0.5),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    augmented_image = transform(image=np.array(image))['image']\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    return augmented_image\n",
    "    \n",
    "def apply_strong_augment(image):\n",
    "    transform = A.Compose([\n",
    "#         A.GridDropout (ratio=0.5, unit_size_min=2, unit_size_max=3, holes_number_x=None, holes_number_y=None, shift_x=0, shift_y=0, random_offset=False, fill_value=0, mask_fill_value=None, always_apply=False, p=0.2),\n",
    "#         A.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=True, p=1), # Heavy Contrast Limited Adaptive Histogram Equalization\n",
    "#         A.Affine(), #heavy (shear + rotate)\n",
    "#         A.RandomSunFlare(src_radius=200), #heavy\n",
    "#         A.CoarseDropout (max_holes=8, max_height=8, max_width=8, min_holes=None, min_height=None, min_width=None, fill_value=0, mask_fill_value=None, always_apply=False, p=0.5),#heavy\n",
    "#         A.RandomCrop(450,450), #80% of image size, probably both\n",
    "#         A.GaussNoise (var_limit=(10.0, 50.0), mean=0, per_channel=True, always_apply=False, p=0.5),\n",
    "        \n",
    "        #A.RandomFog(), # heavy\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    augmented_image = transform(image=np.array(image))['image']\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    return augmented_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "feb42137",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m conv_classname \u001b[38;5;241m=\u001b[39m conv_model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mid2label[conv_class]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#SWIN PART\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m img_weak \u001b[38;5;241m=\u001b[39m \u001b[43mapply_weak_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m swin_inputs \u001b[38;5;241m=\u001b[39m swin_image_processor(images\u001b[38;5;241m=\u001b[39mimg_weak,return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m swin_output \u001b[38;5;241m=\u001b[39m swin_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mswin_inputs)\n",
      "Cell \u001b[0;32mIn[39], line 11\u001b[0m, in \u001b[0;36mapply_weak_augment\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      2\u001b[0m     transform \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      3\u001b[0m         A\u001b[38;5;241m.\u001b[39mAffine (scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, translate_percent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, translate_px\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rotate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shear\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, mask_interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cval_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, fit_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rotate_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlargest_box\u001b[39m\u001b[38;5;124m'\u001b[39m, always_apply\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m#A.RandomGamma(always_apply=True,p=1), #both\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         A.Rotate (limit=10, p=0.5),\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     ])\n\u001b[1;32m     10\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     augmented_image \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     augmented_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(augmented_image)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m augmented_image\n",
      "File \u001b[0;32m~/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/albumentations/core/composition.py:210\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    207\u001b[0m     p\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transforms):\n\u001b[0;32m--> 210\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    213\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_post_transform(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/albumentations/core/transforms_interface.py:118\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             warn(\n\u001b[1;32m    114\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_class_fullname() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because its\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m params depend on targets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m             )\n\u001b[1;32m    117\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/albumentations/core/transforms_interface.py:131\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    130\u001b[0m     target_dependencies \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_dependence\u001b[38;5;241m.\u001b[39mget(key, [])}\n\u001b[0;32m--> 131\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_dependencies\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/albumentations/augmentations/geometric/transforms.py:657\u001b[0m, in \u001b[0;36mAffine.apply\u001b[0;34m(self, img, matrix, output_shape, **params)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    652\u001b[0m     img: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    656\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarp_affine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/albumentations/augmentations/utils.py:122\u001b[0m, in \u001b[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_function\u001b[39m(img: np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    121\u001b[0m     shape \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 122\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    124\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(result, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/albumentations/augmentations/geometric/functional.py:560\u001b[0m, in \u001b[0;36mwarp_affine\u001b[0;34m(image, matrix, interpolation, cval, mode, output_shape)\u001b[0m\n\u001b[1;32m    556\u001b[0m dsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(output_shape[\u001b[38;5;241m1\u001b[39m])), \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(output_shape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    557\u001b[0m warp_fn \u001b[38;5;241m=\u001b[39m _maybe_process_in_chunks(\n\u001b[1;32m    558\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwarpAffine, M\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mparams[:\u001b[38;5;241m2\u001b[39m], dsize\u001b[38;5;241m=\u001b[39mdsize, flags\u001b[38;5;241m=\u001b[39minterpolation, borderMode\u001b[38;5;241m=\u001b[39mmode, borderValue\u001b[38;5;241m=\u001b[39mcval\n\u001b[1;32m    559\u001b[0m )\n\u001b[0;32m--> 560\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mwarp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tmp\n",
      "File \u001b[0;32m~/anaconda3/envs/twin-pseudo/lib/python3.8/site-packages/albumentations/augmentations/utils.py:208\u001b[0m, in \u001b[0;36m_maybe_process_in_chunks.<locals>.__process_fn\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    206\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack(chunks)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_formats = (\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\")  # Add more supported formats if needed\n",
    "\n",
    "result = pd.DataFrame(columns=[\"img_name\", \"conv_results\", \"swin_results\",\"original_label\"])\n",
    "\n",
    "#30% Test\n",
    "imagefolders = \"/home/thanawit/twin-pseudo/cross_val_test/30%_CV/30%_Fold_0/unlabeled\"\n",
    "#Swin Model\n",
    "swin_model_path = 'outputs_all/outputs_swin/checkpoint-16900/'\n",
    "swin_model = AutoModelForImageClassification.from_pretrained(swin_model_path).to('cuda')\n",
    "swin_image_processor = AutoImageProcessor.from_pretrained(swin_model_path)\n",
    "\n",
    "#ConvNext Model\n",
    "conv_model_path = 'outputs_all/outputs_convnext/checkpoint-16900/'\n",
    "conv_model = AutoModelForImageClassification.from_pretrained(conv_model_path).to('cuda')\n",
    "conv_image_processor = AutoImageProcessor.from_pretrained(conv_model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for root, subfolders, files in os.walk(imagefolders):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(image_formats):\n",
    "            image_path = os.path.join(root, filename)\n",
    "            subfolder_name = os.path.basename(root)\n",
    "\n",
    "            #print(f\"Subfolder Name: {subfolder_name}\")\n",
    "            #print(image_path)\n",
    "            img_strong = apply_weak_augment(image_path)\n",
    "            #img = Image.open(image_path)\n",
    "            \n",
    "            #CONNVEXT PART\n",
    "            \n",
    "            #read model\n",
    "            conv_inputs = conv_image_processor(images=img_strong,return_tensors=\"pt\").to('cuda')\n",
    "            #run img\n",
    "            conv_output = conv_model(**conv_inputs)\n",
    "            conv_logits = conv_output.logits\n",
    "            conv_class = conv_logits.argmax(-1).item()\n",
    "            conv_classname = conv_model.config.id2label[conv_class]\n",
    "            \n",
    "            #SWIN PART\n",
    "            \n",
    "            img_weak = apply_weak_augment(image_path)\n",
    "            \n",
    "            swin_inputs = swin_image_processor(images=img_weak,return_tensors=\"pt\").to('cuda')\n",
    "            \n",
    "            swin_output = swin_model(**swin_inputs)\n",
    "            swin_logits = swin_output.logits\n",
    "            swin_class = swin_logits.argmax(-1).item()\n",
    "            swin_classname = swin_model.config.id2label[swin_class]\n",
    "            #get class\n",
    "            new_row = {\n",
    "                \"img_name\": os.path.basename(image_path),\n",
    "                \"conv_results\": conv_classname,\n",
    "                \"swin_results\": swin_classname,\n",
    "                \"original_label\":subfolder_name\n",
    "            }\n",
    "            \n",
    "            result = pd.concat([result, pd.DataFrame([new_row])],ignore_index=True)\n",
    "            #save \n",
    "            #break\n",
    "            #img.show()\n",
    "            #print(\"=\" * 30)\n",
    "        #print(filename)\n",
    "#counter = print_rows_with_correct_label(result)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    num_classes = len(confusion_matrix)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "    auc_scores = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        true_positives = confusion_matrix[i, i]\n",
    "        false_positives = np.sum(confusion_matrix[:, i]) - true_positives\n",
    "        false_negatives = np.sum(confusion_matrix[i, :]) - true_positives\n",
    "        true_negatives = np.sum(confusion_matrix) - true_positives - false_positives - false_negatives\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        accuracy = (true_positives + true_negatives) / np.sum(confusion_matrix[i, :])\n",
    "\n",
    "        # Calculate AUC-ROC\n",
    "        y_true = np.zeros(confusion_matrix.shape[0])\n",
    "        y_true[i] = 1\n",
    "        y_scores = confusion_matrix[:, i] / np.sum(confusion_matrix[:, i])\n",
    "        auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    average_accuracy = np.mean(accuracy_scores)\n",
    "    average_auc = np.mean(auc_scores)\n",
    "\n",
    "    return precision_scores, recall_scores, f1_scores, accuracy_scores, auc_scores, average_precision, average_recall, average_f1, average_accuracy, average_auc\n",
    "\n",
    "# Example usage\n",
    "confusion_matrix = np.array([[10, 1, 2],\n",
    "                             [3, 15, 1],\n",
    "                             [0, 2, 12]])\n",
    "\n",
    "precision_scores, recall_scores, f1_scores, accuracy_scores, auc_scores, average_precision, average_recall, average_f1, average_accuracy, average_auc = calculate_metrics(confusion_matrix)\n",
    "\n",
    "for i in range(len(precision_scores)):\n",
    "    print(f\"Metrics for class {i}:\")\n",
    "    print(f\"Precision: {precision_scores[i]}\")\n",
    "    print(f\"Recall: {recall_scores[i]}\")\n",
    "    print(f\"F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Accuracy per class: {accuracy_scores[i]}\")\n",
    "    print(f\"AUC-ROC: {auc_scores[i]}\\n\")\n",
    "\n",
    "print(f\"Average Precision: {average_precision}\")\n",
    "print(f\"Average Recall: {average_recall}\")\n",
    "print(f\"Average F1 Score: {average_f1}\")\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n",
    "print(f\"Average AUC-ROC: {average_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dbfde02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Record 3802\n",
      "Correct Result from Convnet 3471\n",
      "Correct Result from Swinn 3378\n",
      "Correct Result from Any Correct Label 3618\n",
      "Correct Result from Ensemble 3231\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Total Record\",len(result))\n",
    "print(\"Correct Result from Convnet\",print_rows_with_correct_conv(result))\n",
    "print(\"Correct Result from Swinn\",print_rows_with_correct_swin(result))\n",
    "print(\"Correct Result from Any Correct Label\",print_rows_with_correct_label(result))\n",
    "print(\"Correct Result from Ensemble\",print_rows_with_correct_ensemble(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2495bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weak_augment(image):\n",
    "    transform = A.Compose([\n",
    "        \n",
    "        A.HorizontalFlip(p=0.5,always_apply=True), #both\n",
    "#         A.RandomGamma(p=0.5), #weak\n",
    "#         A.RandomBrightnessContrast(p=0.5), #weak\n",
    "#         A.AdvancedBlur(p=0.5), #weak\n",
    "#         A.Rotate (limit=10, p=0.5),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    augmented_image = transform(image=np.array(image))['image']\n",
    "    augmented_image = Image.fromarray(augmented_image)\n",
    "    return augmented_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b0cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
